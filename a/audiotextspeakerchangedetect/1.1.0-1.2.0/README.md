# Comparing `tmp/audiotextspeakerchangedetect-1.1.0-py3-none-any.whl.zip` & `tmp/audiotextspeakerchangedetect-1.2.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,12 +1,12 @@
-Zip file size: 23446 bytes, number of entries: 28
+Zip file size: 23731 bytes, number of entries: 28
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-26 17:21 audiotextspeakerchangedetect/__init__.py
--rw-r--r--  2.0 unx     3946 b- defN 24-Feb-23 19:55 audiotextspeakerchangedetect/main.py
--rw-r--r--  2.0 unx     1728 b- defN 24-Feb-23 22:50 audiotextspeakerchangedetect/sample_run.py
--rw-r--r--  2.0 unx     1869 b- defN 24-Feb-23 20:16 audiotextspeakerchangedetect/sample_run_existingllama2output.py
+-rw-r--r--  2.0 unx     3919 b- defN 24-Apr-24 18:28 audiotextspeakerchangedetect/main.py
+-rw-r--r--  2.0 unx     1708 b- defN 24-Apr-24 18:21 audiotextspeakerchangedetect/sample_run.py
+-rw-r--r--  2.0 unx     1849 b- defN 24-Apr-24 18:21 audiotextspeakerchangedetect/sample_run_existingllama2output.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-26 17:21 audiotextspeakerchangedetect/EnsembleSpeakerChangeDetection/__init__.py
 -rw-r--r--  2.0 unx     5643 b- defN 24-Feb-23 18:39 audiotextspeakerchangedetect/EnsembleSpeakerChangeDetection/ensemble_detection.py
 -rw-r--r--  2.0 unx     1035 b- defN 24-Feb-23 18:36 audiotextspeakerchangedetect/EnsembleSpeakerChangeDetection/helpers.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-26 17:21 audiotextspeakerchangedetect/SpeakerChangeDetection/__init__.py
 -rw-r--r--  2.0 unx      889 b- defN 24-Feb-23 18:37 audiotextspeakerchangedetect/SpeakerChangeDetection/helpers.py
 -rw-r--r--  2.0 unx     6775 b- defN 24-Mar-04 18:18 audiotextspeakerchangedetect/SpeakerChangeDetection/speaker_change_detection_main_function.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-26 17:21 audiotextspeakerchangedetect/SpeakerChangeDetection/Llama2/__init__.py
@@ -17,14 +17,14 @@
 -rw-r--r--  2.0 unx     3976 b- defN 24-Feb-23 17:55 audiotextspeakerchangedetect/SpeakerChangeDetection/Llama2/prompts/prompt1.py
 -rw-r--r--  2.0 unx     1037 b- defN 24-Feb-23 17:55 audiotextspeakerchangedetect/SpeakerChangeDetection/Llama2/prompts/prompt1_template.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-26 17:21 audiotextspeakerchangedetect/SpeakerChangeDetection/NLP/__init__.py
 -rw-r--r--  2.0 unx     1288 b- defN 24-Feb-23 17:55 audiotextspeakerchangedetect/SpeakerChangeDetection/NLP/speaker_change_detection_nlp.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-26 17:21 audiotextspeakerchangedetect/SpeakerChangeDetection/PyAnnote/__init__.py
 -rw-r--r--  2.0 unx     1179 b- defN 24-Jan-30 21:58 audiotextspeakerchangedetect/SpeakerChangeDetection/PyAnnote/speaker_change_detection_pyannote.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-26 17:21 audiotextspeakerchangedetect/SpeakerChangeDetection/SpectralClustering/__init__.py
--rw-r--r--  2.0 unx     1407 b- defN 24-Mar-02 04:13 audiotextspeakerchangedetect/SpeakerChangeDetection/SpectralClustering/speaker_change_detection_clustering.py
--rw-r--r--  2.0 unx     1092 b- defN 24-Apr-24 16:02 audiotextspeakerchangedetect-1.1.0.dist-info/LICENSE
--rw-r--r--  2.0 unx    10355 b- defN 24-Apr-24 16:02 audiotextspeakerchangedetect-1.1.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-24 16:02 audiotextspeakerchangedetect-1.1.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       29 b- defN 24-Apr-24 16:02 audiotextspeakerchangedetect-1.1.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3511 b- defN 24-Apr-24 16:02 audiotextspeakerchangedetect-1.1.0.dist-info/RECORD
-28 files, 53950 bytes uncompressed, 17296 bytes compressed:  67.9%
+-rw-r--r--  2.0 unx     1407 b- defN 24-Apr-25 14:44 audiotextspeakerchangedetect/SpeakerChangeDetection/SpectralClustering/speaker_change_detection_clustering.py
+-rw-r--r--  2.0 unx     1092 b- defN 24-Apr-25 14:47 audiotextspeakerchangedetect-1.2.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx    11600 b- defN 24-Apr-25 14:47 audiotextspeakerchangedetect-1.2.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-25 14:47 audiotextspeakerchangedetect-1.2.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       29 b- defN 24-Apr-25 14:47 audiotextspeakerchangedetect-1.2.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3511 b- defN 24-Apr-25 14:47 audiotextspeakerchangedetect-1.2.0.dist-info/RECORD
+28 files, 55128 bytes uncompressed, 17581 bytes compressed:  68.1%
```

## zipnote {}

```diff
@@ -63,23 +63,23 @@
 
 Filename: audiotextspeakerchangedetect/SpeakerChangeDetection/SpectralClustering/__init__.py
 Comment: 
 
 Filename: audiotextspeakerchangedetect/SpeakerChangeDetection/SpectralClustering/speaker_change_detection_clustering.py
 Comment: 
 
-Filename: audiotextspeakerchangedetect-1.1.0.dist-info/LICENSE
+Filename: audiotextspeakerchangedetect-1.2.0.dist-info/LICENSE
 Comment: 
 
-Filename: audiotextspeakerchangedetect-1.1.0.dist-info/METADATA
+Filename: audiotextspeakerchangedetect-1.2.0.dist-info/METADATA
 Comment: 
 
-Filename: audiotextspeakerchangedetect-1.1.0.dist-info/WHEEL
+Filename: audiotextspeakerchangedetect-1.2.0.dist-info/WHEEL
 Comment: 
 
-Filename: audiotextspeakerchangedetect-1.1.0.dist-info/top_level.txt
+Filename: audiotextspeakerchangedetect-1.2.0.dist-info/top_level.txt
 Comment: 
 
-Filename: audiotextspeakerchangedetect-1.1.0.dist-info/RECORD
+Filename: audiotextspeakerchangedetect-1.2.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## audiotextspeakerchangedetect/main.py

```diff
@@ -29,16 +29,16 @@
     :type: transcription_file_input_name: str
     :param detection_output_path: A path to save the speaker change detection output in csv file
     :type detection_output_path: str
     :param hf_access_token: Access token to HuggingFace
     :type hf_access_token: str
     :param llama2_model_path: A path where the Llama2 model files are saved
     :type llama2_model_path: str
-    :param pyannote_model_path: A path where the Pyannote model files are saved, default to None
-    :type pyannote_model_path: str, optional
+    :param pyannote_model_path: A path where the Pyannote model files are saved
+    :type pyannote_model_path: str
     :param device:Device type to run the model, defaults to None so GPU would be automatically
     used if it is available
     :type: str or torch.device, optional
     :param detection_llama2_output_path: A path where the pre-run Llama2 speaker change detection output in csv file
     is saved if exists, default to None
     :type detection_llama2_output_path: str, optional
     :param temp_output_path: A path to save the current run of Llama2 speaker change detection output
```

## audiotextspeakerchangedetect/sample_run.py

```diff
@@ -9,15 +9,15 @@
 min_speakers = 2
 max_speakers = 10
 audio_file_input_path = '/scratch/gpfs/jf3375/test/input'
 audio_file_input_name =  'bvyvm.wav'
 transcription_input_path = '/scratch/gpfs/jf3375/test/input'
 transcription_file_input_name = audio_file_input_name.split('.')[0] + '.csv'
 detection_output_path =  '/scratch/gpfs/jf3375/test/output'
-hf_access_token = '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'
+hf_access_token = '<hf_access_token>'
 llama2_model_path = '/scratch/gpfs/jf3375/models/llama'
 pyannote_model_path = "/scratch/gpfs/jf3375/models/pyannote3.1/Diarization"
 device = None  # if set device = None, by default would use gpu if cuda is available, otherwise use gpu
 detection_llama2_output_path =  None # No existing llama2 output
 temp_output_path = '/scratch/gpfs/jf3375/test/temp'
 ensemble_voting = ['majority', 'unanimity']
```

## audiotextspeakerchangedetect/sample_run_existingllama2output.py

```diff
@@ -9,15 +9,15 @@
 min_speakers = 2
 max_speakers = 10
 audio_file_input_path = '/scratch/gpfs/jf3375/modern_family/audio/sample_data'
 audio_file_input_name =  'sample_data.WAV'
 transcription_input_path = '/scratch/gpfs/jf3375/modern_family/output/Whispertimestamped'
 transcription_file_input_name = audio_file_input_name.split('.')[0] + '.csv'
 detection_output_path =  '/scratch/gpfs/jf3375/modern_family/output/detection'
-hf_access_token = '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'
+hf_access_token = '<hf_access_token>'
 llama2_model_path = None
 pyannote_model_path = "/scratch/gpfs/jf3375/models/pyannote3.1/Diarization"
 device = None  # if set device = None, by default would use gpu if cuda is available, otherwise use gpu
 detection_llama2_output_path =  '/scratch/gpfs/jf3375/modern_family/output/detection/Llama2/70b' # Existing llama2 output
 temp_output_path = '/scratch/gpfs/jf3375/modern_family/temp'
 ensemble_voting = ['majority', 'unanimity']
```

## audiotextspeakerchangedetect/SpeakerChangeDetection/SpectralClustering/speaker_change_detection_clustering.py

```diff
@@ -16,15 +16,15 @@
             timestamp_speaker[start_time] = 'speaker' + str(labels[i - 1])
             start_time = time
         if i == len(times) - 1:
             timestamp_speaker[start_time] = 'speaker' + str(labels[i])
     return timestamp_speaker
 
 def spectralclustering_speakerchangedetection(audio_file_input_path, audio_file_input_name,
-                                           min_speakers, max_speakers, device: Union[str, torch.device]='cpu'):
+                                           min_speakers, max_speakers, device: Union[str, torch.device]='gpu'):
     wav = preprocess_wav(os.path.join(audio_file_input_path, audio_file_input_name))
 
     encoder = VoiceEncoder(device)
     _, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16)
 
     # Clustering of Speakers based on Embedding
     clusterer = SpectralClusterer(
```

## Comparing `audiotextspeakerchangedetect-1.1.0.dist-info/LICENSE` & `audiotextspeakerchangedetect-1.2.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `audiotextspeakerchangedetect-1.1.0.dist-info/METADATA` & `audiotextspeakerchangedetect-1.2.0.dist-info/METADATA`

 * *Files 17% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: audiotextspeakerchangedetect
-Version: 1.1.0
+Version: 1.2.0
 Summary: A Package to Detect Speaker Change based on Textual Features via LLMs & Rule-Based NLP and Audio Features via Pyannote & Spectral Clustering
 Author-email: "Junying (Alice) Fang" <jf3375@princeton.edu>
 Project-URL: Homepage, https://github.com/princeton-ddss/AudioAndTextBasedSpeakerChangeDetection
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Operating System :: OS Independent
 Requires-Python: >=3.7
@@ -23,15 +23,15 @@
 Requires-Dist: pyannote.database ==5.0.1
 Requires-Dist: pyannote.metrics ==3.2.1
 Requires-Dist: pyannote.pipeline ==3.0.1
 
 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10712695.svg)](https://doi.org/10.5281/zenodo.10712695)
 
 ## Audiotextspeakerchangedetect ##
-**[Audiotextspeakerchangedetect](https://pypi.org/project/audiotextspeakerchangedetect/)** is a Python package to detect speaker change by analyzing both audio and textual features.
+**[Audiotextspeakerchangedetect](https://github.com/princeton-ddss/AudioAndTextBasedSpeakerChangeDetection)** is a Python package to detect speaker change by analyzing both audio and textual features.
 
 The package develops and applies Large Language Models and the Rule-based NLP Model to detect speaker change based on textual features. 
 
 Currently, the package provides the main function so users could directly pass transcriptions to apply Llama2-70b to detect speaker change. The prompt of speaker change detection 
 is developed meticulously to ensure that Llama2 could understand its role of detecting speaker change, perform the speaker change detection for almost every segment, and return the answer in a standardized JSON format. 
 Specifically, two texts of the current segment and the next segment would be shown to ask Llama2 if the speaker changes across these two segments by understanding the interrelationships 
 between these two texts. The codes are developed to parse input csv files to prompts and parse the returned answers into csv files
@@ -57,20 +57,23 @@
 
 ## Create New Python Environment to Avoid Packages Versions Conflict If Needed
 ```
 python -m venv <envname>
 source <envname>/bin/activate
 ```
 
-## Install **Audiotextspeakerchangedetect** using Pypi
+## Install the Package
+The package **Audiotextspeakerchangedetect** could be installed either via Pypi or Github.
+
+### Pypi
 ```
 pip install audiotextspeakerchangedetect
 ```
 
-## Install **Audiotextspeakerchangedetect** using Github
+### Github
 ```
 git lfs install
 git clone https://github.com/princeton-ddss/AudioAndTextBasedSpeakerChangeDetection
 cd <.../AudioAndTextBasedSpeakerChangeDetection>
 pip install .
 ```
 
@@ -89,45 +92,62 @@
 ```
 from huggingface_hub import snapshot_download, login
 
 login(token=<hf_access_token>)
 snapshot_download(repo_id ='meta-llama/Llama-2-70b-chat-hf',  cache_dir= <download_model_path>)
 ```
 
-### Download PyAnnotate Models using Git Large File Storage (LFS)
-
-PyAnnotate models are already in the **models** folder of the current repo. 
+### Download PyAnnote Models using Dropbox Link
 
-Please download the models using ```git lfs pull```.
-To use the PyAnnotate models, please replace <local_path> with the local parent folder of the downloaded AudioAndTextBasedSpeakerChangeDetection repo in **models/pyannote3.1/Diarization/config.yaml** and
-**models/pyannote3.1/Segmentation/config.yaml**.
+To download PyAnnotate models, please download pyannote3.1 folder in this [Dropbox Link](https://www.dropbox.com/scl/fo/tp2uryaq81sze2l0yuxb9/ACgXWOr7Be1ZZovz7xNSuTs?rlkey=9c2z50pjbjhoo3vz4dbxlmlcf&st=fukejg4l&dl=0).
 
+To use the PyAnnotate models, please replace <local_path> with the local parent folder of the downloaded pyannote3.1 folder in **pyannote3.1/Diarization/config.yaml** and
+**pyannote3.1/Segmentation/config.yaml**.
 
 ## Usage
 The audio-and-text-based ensemble speaker change detection model could be applied to get speaker change detection results by running only one function.
 The function is **run_ensemble_audio_text_based_speaker_change_detection_model** in src/audiotextspeakerchangedetect/main.py.
-
-Please view the sample codes to run the function in sample_run.py and sample_run_existingllama2output.py in the src/audiotextspeakerchangedetect.
-
-Specifically, detection_models input could be set as a list or sublist of 
-['pyannote', 'clustering', 'nlp', 'llama2-70b']. Device input could be set as None or 'gpu' or 'cpu'. If device is set as None,
-gpu would be used if it is available. Running llama2-70b requires at least 2 gpus and 250GB memory. If the computing resources is not available
-for running llama2-70b, please exclude llama2-70b from detection_models input or replace llama2-70b with llama2-7b.
-
-Please view the detailed function description and its inputs descriptions inside the Python file **src/audiotextspeakerchangedetect/main.py**. 
 ```
 from audiotextspeakerchangedetect.main import run_ensemble_audio_text_based_speaker_change_detection_model
 
 run_ensemble_audio_text_based_speaker_change_detection_model(detection_models, min_speakers, max_speakers,
                                                            audio_file_input_path, audio_file_input_name,
                                                            transcription_input_path, transcription_file_input_name,
                                                            detection_output_path,  hf_access_token,
                                                            llama2_model_path, pyannote_model_path, device,
                                                            detection_llama2_output_path, temp_output_path, ensemble_voting)
 ```
+Please view the descriptions of the function inputs:
+* detection_models: A list of names of speaker change detection models to be run
+* min_speakers: The minimal number of speakers in the input audio file
+* max_speakers: The maximal number of speakers in the input audio file
+* audio_file_input_path: A path which contains an input audio file
+* audio_file_input_name: A audio file name containing the file type
+* transcription_input_path: A path where a transcription output csv file is saved
+* transcription_file_input_name: A transcription output csv file name ending with .csv
+* detection_output_path: A path to save the speaker change detection output in csv file
+* hf_access_token: Access token to HuggingFace
+* llama2_model_path: A path where the Llama2 model files are saved
+* pyannote_model_path: A path where the Pyannote model files are saved
+* device: Torch device type to run the model, defaults to None so GPU would be automatically
+used if it is available
+* detection_llama2_output_path: A path where the pre-run Llama2 speaker change detection output in csv file
+is saved if exists, default to None
+* temp_output_path: A path to save the current run of Llama2 speaker change detection output
+to avoid future rerunning, default to None
+* ensemble_output_path: A path to save the ensemble detection output in csv file
+* ensemble_voting: A list of voting methods to be used to build the final ensemble model
+
+Please view sample codes to run the function in **sample_run.py** and **sample_run_existingllama2output.py** in the **src/audiotextspeakerchangedetect** folder.
+Please view the detailed function description and its inputs descriptions inside the Python file **src/audiotextspeakerchangedetect/main.py**. 
+
+Please note that running llama2-70b requires at least 2 gpus and 250GB memory. If the computing resources is not available
+for running llama2-70b, please exclude llama2-70b from detection_models input.
+
+
 
 
 ## Evaluation
 [VoxConverse Dataset v0.3](https://github.com/joonson/voxconverse?tab=readme-ov-file)
 
 VoxConverse is an only audio-visual diarization dataset consisting of over 50 hours of multispeaker clips of human speech, extracted from YouTube videos, usually in a political debate or news segment context to ensure multi-speaker dialogue.
 The audio files in the dataset have lots of variations of the proportion of speaker changes, which indicates the effectiveness of the dataset as the evaluation dataset to evaluate the models robustness.
```

## Comparing `audiotextspeakerchangedetect-1.1.0.dist-info/RECORD` & `audiotextspeakerchangedetect-1.2.0.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 audiotextspeakerchangedetect/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-audiotextspeakerchangedetect/main.py,sha256=BjnzlDKlX_z49zytqKrGn1LjBsOmWboJ3bBlXfHCtZY,3946
-audiotextspeakerchangedetect/sample_run.py,sha256=VAVBTrkZAInn62cQ-ybMy7mFWlbI1aAnbhCfH0Qi44A,1728
-audiotextspeakerchangedetect/sample_run_existingllama2output.py,sha256=KQRewWhpiMqhHtqMK91wi-6vktrG2FANbbgSNrz0hK8,1869
+audiotextspeakerchangedetect/main.py,sha256=dL8iVbw59sGwTyaMTaAU9CWOp8a1J94K4zkAjw22_-k,3919
+audiotextspeakerchangedetect/sample_run.py,sha256=A-Lgks7mIs6Q5n5CeG6flKyV_AlpYwdxgSyft6DgqH8,1708
+audiotextspeakerchangedetect/sample_run_existingllama2output.py,sha256=HVn7Gl4ADTvf5q1Pe3Wq1iK4BPnFNWyHR2L1-UKWniU,1849
 audiotextspeakerchangedetect/EnsembleSpeakerChangeDetection/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 audiotextspeakerchangedetect/EnsembleSpeakerChangeDetection/ensemble_detection.py,sha256=lLFRqC9edjEL1uo7k9AmO0t6nhKLXWN5fjAW16KJO-U,5643
 audiotextspeakerchangedetect/EnsembleSpeakerChangeDetection/helpers.py,sha256=zVbA2t47_p3fTqEckyBRhEyLD07dykXzF4mUOhl-9FY,1035
 audiotextspeakerchangedetect/SpeakerChangeDetection/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 audiotextspeakerchangedetect/SpeakerChangeDetection/helpers.py,sha256=OHf1VGNJecRL-rUKhJYiEuHOfeh8fCVyPVOgUb5M3Gk,889
 audiotextspeakerchangedetect/SpeakerChangeDetection/speaker_change_detection_main_function.py,sha256=7dYqu36Sk9pz_g85k_XjayJUfokGQ-ZKFyV0yTgo7j0,6775
 audiotextspeakerchangedetect/SpeakerChangeDetection/Llama2/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
@@ -16,13 +16,13 @@
 audiotextspeakerchangedetect/SpeakerChangeDetection/Llama2/prompts/prompt1.py,sha256=urcSMuJN38AA-EXz3I16_Lm50uCExxgoXvnQ6PPQNEM,3976
 audiotextspeakerchangedetect/SpeakerChangeDetection/Llama2/prompts/prompt1_template.py,sha256=iHhOoUo9qhz7K46TAnBp9AfNzY-IT66zGTAC1nv9vWc,1037
 audiotextspeakerchangedetect/SpeakerChangeDetection/NLP/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 audiotextspeakerchangedetect/SpeakerChangeDetection/NLP/speaker_change_detection_nlp.py,sha256=7F9PseQfNSei6jqIDjPm6x-IrkVQxMlzXMS6gcvIXrY,1288
 audiotextspeakerchangedetect/SpeakerChangeDetection/PyAnnote/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 audiotextspeakerchangedetect/SpeakerChangeDetection/PyAnnote/speaker_change_detection_pyannote.py,sha256=xG33J7qqL-8XDr1HJdN9XhLwu3WBymMHIuPMkkyyOU0,1179
 audiotextspeakerchangedetect/SpeakerChangeDetection/SpectralClustering/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-audiotextspeakerchangedetect/SpeakerChangeDetection/SpectralClustering/speaker_change_detection_clustering.py,sha256=mFOgfAw8KbIR2j-_XczTldhWuwfyl029RgxTCB_XEYQ,1407
-audiotextspeakerchangedetect-1.1.0.dist-info/LICENSE,sha256=y0FxS72Yc01R5i36fN2g0JCldQzKCdCZ_H6h3RtttGw,1092
-audiotextspeakerchangedetect-1.1.0.dist-info/METADATA,sha256=aZdAZcPQus5jXMN8hMenpT9qdelleBKBI4DP8Z7Z3Bc,10355
-audiotextspeakerchangedetect-1.1.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-audiotextspeakerchangedetect-1.1.0.dist-info/top_level.txt,sha256=j9RMny-GPUpx1KTFzsA8p4moG8nJgNRtiLqZORjUDXs,29
-audiotextspeakerchangedetect-1.1.0.dist-info/RECORD,,
+audiotextspeakerchangedetect/SpeakerChangeDetection/SpectralClustering/speaker_change_detection_clustering.py,sha256=4QqhNHYOvIGdFttGzsj56c8bcx4QoimAgHxSXReSC2k,1407
+audiotextspeakerchangedetect-1.2.0.dist-info/LICENSE,sha256=y0FxS72Yc01R5i36fN2g0JCldQzKCdCZ_H6h3RtttGw,1092
+audiotextspeakerchangedetect-1.2.0.dist-info/METADATA,sha256=vMFMBGN8Nwkkq15MIQrqMiF5Pyr45qzdJyRbhxAchVY,11600
+audiotextspeakerchangedetect-1.2.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+audiotextspeakerchangedetect-1.2.0.dist-info/top_level.txt,sha256=j9RMny-GPUpx1KTFzsA8p4moG8nJgNRtiLqZORjUDXs,29
+audiotextspeakerchangedetect-1.2.0.dist-info/RECORD,,
```

