# Comparing `tmp/mugicli-0.0.8-py3-none-any.whl.zip` & `tmp/mugicli-0.0.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,45 +1,45 @@
-Zip file size: 35602 bytes, number of entries: 43
--rw-rw-rw-  2.0 fat     4405 b- defN 22-Mar-14 14:10 mugicli/__init__.py
--rw-rw-rw-  2.0 fat     1334 b- defN 22-Feb-22 16:20 mugicli/headtail.py
--rw-rw-rw-  2.0 fat      629 b- defN 22-Feb-26 15:45 mugicli/pycat.py
--rw-rw-rw-  2.0 fat      825 b- defN 22-Feb-26 15:45 mugicli/pycol.py
--rw-rw-rw-  2.0 fat      395 b- defN 22-Mar-12 07:50 mugicli/pycwd.py
--rw-rw-rw-  2.0 fat      127 b- defN 22-Feb-28 13:31 mugicli/pydos2unix.py
--rw-rw-rw-  2.0 fat     5304 b- defN 22-Feb-22 15:25 mugicli/pydu.py
--rw-rw-rw-  2.0 fat     1960 b- defN 22-Feb-28 09:33 mugicli/pyecho.py
--rw-rw-rw-  2.0 fat     1457 b- defN 22-Feb-26 15:45 mugicli/pyextstat.py
--rw-rw-rw-  2.0 fat    24579 b- defN 22-Mar-10 19:31 mugicli/pyfind.py
--rw-rw-rw-  2.0 fat     2196 b- defN 22-Mar-07 20:13 mugicli/pygrep.py
--rw-rw-rw-  2.0 fat      119 b- defN 22-Mar-01 13:46 mugicli/pyhead.py
--rw-rw-rw-  2.0 fat      870 b- defN 22-Mar-07 20:08 mugicli/pyls.py
--rw-rw-rw-  2.0 fat      112 b- defN 22-Feb-28 14:40 mugicli/pymd5sum.py
--rw-rw-rw-  2.0 fat      712 b- defN 22-Feb-26 15:45 mugicli/pymtime.py
--rw-rw-rw-  2.0 fat     4131 b- defN 22-Mar-12 07:18 mugicli/pymtimestat.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-Mar-01 09:49 mugicli/pypathjoin.py
--rw-rw-rw-  2.0 fat     1487 b- defN 22-Feb-22 17:31 mugicli/pysed.py
--rw-rw-rw-  2.0 fat     1304 b- defN 22-Feb-28 13:41 mugicli/pyseq.py
--rw-rw-rw-  2.0 fat      113 b- defN 22-Feb-28 14:40 mugicli/pysha1sum.py
--rw-rw-rw-  2.0 fat      115 b- defN 22-Feb-28 14:40 mugicli/pysha224sum.py
--rw-rw-rw-  2.0 fat      115 b- defN 22-Feb-28 14:40 mugicli/pysha256sum.py
--rw-rw-rw-  2.0 fat      115 b- defN 22-Feb-28 14:40 mugicli/pysha384sum.py
--rw-rw-rw-  2.0 fat      115 b- defN 22-Feb-28 14:40 mugicli/pysha512sum.py
--rw-rw-rw-  2.0 fat     1705 b- defN 22-Feb-26 15:45 mugicli/pysort.py
--rw-rw-rw-  2.0 fat     1129 b- defN 22-Mar-07 20:14 mugicli/pystart.py
--rw-rw-rw-  2.0 fat      119 b- defN 22-Mar-01 13:46 mugicli/pytail.py
--rw-rw-rw-  2.0 fat      499 b- defN 22-Feb-22 16:23 mugicli/pytime.py
--rw-rw-rw-  2.0 fat     1818 b- defN 22-Feb-28 13:57 mugicli/pytmp.py
--rw-rw-rw-  2.0 fat     1372 b- defN 22-Mar-12 07:29 mugicli/pytouch.py
--rw-rw-rw-  2.0 fat     1233 b- defN 22-Feb-28 14:54 mugicli/pyuniq.py
--rw-rw-rw-  2.0 fat      125 b- defN 22-Feb-28 13:31 mugicli/pyunix2dos.py
--rw-rw-rw-  2.0 fat     2150 b- defN 22-Feb-15 19:10 mugicli/pywc.py
--rw-rw-rw-  2.0 fat     1274 b- defN 22-Mar-08 21:30 mugicli/pyxargs.py
--rw-rw-rw-  2.0 fat     1595 b- defN 22-Feb-28 09:09 mugicli/pyxxd.py
--rw-rw-rw-  2.0 fat     3665 b- defN 22-Mar-14 20:22 mugicli/pyzip.py
--rw-rw-rw-  2.0 fat     5385 b- defN 22-Mar-07 20:13 mugicli/shared.py
--rw-rw-rw-  2.0 fat     1070 b- defN 22-Mar-14 21:00 mugicli-0.0.8.dist-info/LICENSE
--rw-rw-rw-  2.0 fat    12225 b- defN 22-Mar-14 21:00 mugicli-0.0.8.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 22-Mar-14 21:00 mugicli-0.0.8.dist-info/WHEEL
--rw-rw-rw-  2.0 fat     1038 b- defN 22-Mar-14 21:00 mugicli-0.0.8.dist-info/entry_points.txt
--rw-rw-rw-  2.0 fat        8 b- defN 22-Mar-14 21:00 mugicli-0.0.8.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     3242 b- defN 22-Mar-14 21:00 mugicli-0.0.8.dist-info/RECORD
-43 files, 92263 bytes uncompressed, 30578 bytes compressed:  66.9%
+Zip file size: 37840 bytes, number of entries: 43
+-rw-rw-rw-  2.0 fat     7152 b- defN 22-Mar-17 15:52 mugicli/__init__.py
+-rw-rw-rw-  2.0 fat     1378 b- defN 22-Feb-24 10:48 mugicli/headtail.py
+-rw-rw-rw-  2.0 fat      655 b- defN 22-Feb-26 18:04 mugicli/pycat.py
+-rw-rw-rw-  2.0 fat      850 b- defN 22-Feb-26 18:08 mugicli/pycol.py
+-rw-rw-rw-  2.0 fat      395 b- defN 22-Mar-15 08:18 mugicli/pycwd.py
+-rw-rw-rw-  2.0 fat      127 b- defN 22-Mar-01 08:05 mugicli/pydos2unix.py
+-rw-rw-rw-  2.0 fat     5500 b- defN 22-Feb-24 10:48 mugicli/pydu.py
+-rw-rw-rw-  2.0 fat     2050 b- defN 22-Mar-01 08:05 mugicli/pyecho.py
+-rw-rw-rw-  2.0 fat     1504 b- defN 22-Feb-26 18:09 mugicli/pyextstat.py
+-rw-rw-rw-  2.0 fat    23449 b- defN 22-Mar-17 09:11 mugicli/pyfind.py
+-rw-rw-rw-  2.0 fat     2265 b- defN 22-Mar-09 07:41 mugicli/pygrep.py
+-rw-rw-rw-  2.0 fat      125 b- defN 22-Mar-04 15:10 mugicli/pyhead.py
+-rw-rw-rw-  2.0 fat     2110 b- defN 22-Mar-17 10:53 mugicli/pyls.py
+-rw-rw-rw-  2.0 fat      112 b- defN 22-Mar-01 08:05 mugicli/pymd5sum.py
+-rw-rw-rw-  2.0 fat      738 b- defN 22-Feb-26 18:05 mugicli/pymtime.py
+-rw-rw-rw-  2.0 fat     3779 b- defN 22-Mar-17 09:35 mugicli/pymtimestat.py
+-rw-rw-rw-  2.0 fat     1548 b- defN 22-Feb-24 10:51 mugicli/pysed.py
+-rw-rw-rw-  2.0 fat     1364 b- defN 22-Mar-01 08:05 mugicli/pyseq.py
+-rw-rw-rw-  2.0 fat      113 b- defN 22-Mar-01 08:05 mugicli/pysha1sum.py
+-rw-rw-rw-  2.0 fat      115 b- defN 22-Mar-01 08:05 mugicli/pysha224sum.py
+-rw-rw-rw-  2.0 fat      115 b- defN 22-Mar-01 08:05 mugicli/pysha256sum.py
+-rw-rw-rw-  2.0 fat      115 b- defN 22-Mar-01 08:05 mugicli/pysha384sum.py
+-rw-rw-rw-  2.0 fat      115 b- defN 22-Mar-01 08:05 mugicli/pysha512sum.py
+-rw-rw-rw-  2.0 fat     1771 b- defN 22-Feb-26 18:06 mugicli/pysort.py
+-rw-rw-rw-  2.0 fat     1129 b- defN 22-Mar-09 07:41 mugicli/pystart.py
+-rw-rw-rw-  2.0 fat      125 b- defN 22-Mar-04 15:10 mugicli/pytail.py
+-rw-rw-rw-  2.0 fat      528 b- defN 22-Feb-24 10:50 mugicli/pytime.py
+-rw-rw-rw-  2.0 fat     1883 b- defN 22-Mar-01 08:05 mugicli/pytmp.py
+-rw-rw-rw-  2.0 fat     1419 b- defN 22-Mar-15 08:18 mugicli/pytouch.py
+-rw-rw-rw-  2.0 fat     4609 b- defN 22-Mar-17 15:50 mugicli/pytree.py
+-rw-rw-rw-  2.0 fat     1274 b- defN 22-Mar-01 08:05 mugicli/pyuniq.py
+-rw-rw-rw-  2.0 fat      125 b- defN 22-Mar-01 08:05 mugicli/pyunix2dos.py
+-rw-rw-rw-  2.0 fat     2225 b- defN 22-Feb-24 10:45 mugicli/pywc.py
+-rw-rw-rw-  2.0 fat     1325 b- defN 22-Mar-09 07:41 mugicli/pyxargs.py
+-rw-rw-rw-  2.0 fat     1595 b- defN 22-Mar-01 08:05 mugicli/pyxxd.py
+-rw-rw-rw-  2.0 fat     3889 b- defN 22-Mar-17 15:08 mugicli/pyzip.py
+-rw-rw-rw-  2.0 fat     5576 b- defN 22-Mar-09 07:41 mugicli/shared.py
+-rw-rw-rw-  2.0 fat     1091 b- defN 22-Mar-21 21:55 mugicli-0.0.9.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat    12738 b- defN 22-Mar-21 21:55 mugicli-0.0.9.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 22-Mar-21 21:55 mugicli-0.0.9.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat     1067 b- defN 22-Mar-21 21:55 mugicli-0.0.9.dist-info/entry_points.txt
+-rw-rw-rw-  2.0 fat        8 b- defN 22-Mar-21 21:55 mugicli-0.0.9.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     3242 b- defN 22-Mar-21 21:55 mugicli-0.0.9.dist-info/RECORD
+43 files, 101385 bytes uncompressed, 32824 bytes compressed:  67.6%
```

## zipnote {}

```diff
@@ -42,17 +42,14 @@
 
 Filename: mugicli/pymtime.py
 Comment: 
 
 Filename: mugicli/pymtimestat.py
 Comment: 
 
-Filename: mugicli/pypathjoin.py
-Comment: 
-
 Filename: mugicli/pysed.py
 Comment: 
 
 Filename: mugicli/pyseq.py
 Comment: 
 
 Filename: mugicli/pysha1sum.py
@@ -84,14 +81,17 @@
 
 Filename: mugicli/pytmp.py
 Comment: 
 
 Filename: mugicli/pytouch.py
 Comment: 
 
+Filename: mugicli/pytree.py
+Comment: 
+
 Filename: mugicli/pyuniq.py
 Comment: 
 
 Filename: mugicli/pyunix2dos.py
 Comment: 
 
 Filename: mugicli/pywc.py
@@ -105,26 +105,26 @@
 
 Filename: mugicli/pyzip.py
 Comment: 
 
 Filename: mugicli/shared.py
 Comment: 
 
-Filename: mugicli-0.0.8.dist-info/LICENSE
+Filename: mugicli-0.0.9.dist-info/LICENSE
 Comment: 
 
-Filename: mugicli-0.0.8.dist-info/METADATA
+Filename: mugicli-0.0.9.dist-info/METADATA
 Comment: 
 
-Filename: mugicli-0.0.8.dist-info/WHEEL
+Filename: mugicli-0.0.9.dist-info/WHEEL
 Comment: 
 
-Filename: mugicli-0.0.8.dist-info/entry_points.txt
+Filename: mugicli-0.0.9.dist-info/entry_points.txt
 Comment: 
 
-Filename: mugicli-0.0.8.dist-info/top_level.txt
+Filename: mugicli-0.0.9.dist-info/top_level.txt
 Comment: 
 
-Filename: mugicli-0.0.8.dist-info/RECORD
+Filename: mugicli-0.0.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mugicli/__init__.py

```diff
@@ -1,161 +1,252 @@
-import sys
-import re
-from .shared import glob_paths, glob_paths_files, read_bytes, print_bytes
-import argparse
-import hashlib
-import argparse
-import sys
-from .shared import glob_paths_files, print_utf8, drop_last_empty_line, index_of_int
-
-def decode_bytes(data):
-    try:
-        text = data.decode('utf-8')
-    except UnicodeDecodeError:
-        text = data.decode(sys.stdin.encoding)
-    return text
-
-def read_file_bin(path):
-    with open(path, 'rb') as f:
-        return f.read()
-
-def read_stdin_bin():
-    return sys.stdin.buffer.read()
-
-def read_stdin_text():
-    data = sys.stdin.buffer.read()
-    return decode_bytes(data)
-
-def read_file_text(path):
-    data = read_file_bin(path)
-    return decode_bytes(data)
-
-def chunks(lst, n):
-    """Yield successive n-sized chunks from lst."""
-    for i in range(0, len(lst), n):
-        yield lst[i:i + n]
-
-def parse_size(arg):
-    m = re.match('^([-+]?[0-9.e]+)+([cwbkmg]?)$', arg, re.IGNORECASE)
-    if m is None:
-        return None
-    size = float(m.group(1))
-    prefix = m.group(2)
-    return int(size * {'k': 1024, 'm': 1024 * 1024, 'g': 1024 * 1024 * 1024, 'c': 1, 'b': 512, '': 1}[prefix.lower()])
-
-import argparse
-
-(
-    TO_UNIX,
-    TO_DOS
-) = range(2)
-
-def convertlineterm(to_what):
-
-    description = {
-        TO_UNIX: 'converts line endings from dos to unix (\\r\\n -> \\n)',
-        TO_DOS: 'converts line endings from unix to dos (\\n -> \\r\\n)'
-    }[to_what]
-
-    parser = argparse.ArgumentParser(description=description)
-    parser.add_argument('path', nargs='*')
-    args = parser.parse_args()
-    paths = glob_paths_files(args.path)
-
-    stdin_mode = len(args.path) == 0
-
-    if to_what == TO_UNIX:
-        subj = b'\r\n'
-        repl = b'\n'
-    else:
-        subj = b'\n'
-        repl = b'\r\n'
-
-    if stdin_mode:
-        bytes_ = read_bytes(None)
-        print_bytes(bytes_.replace(subj, repl))
-    else:
-        for path in paths:
-            bytes_ = read_bytes(path)
-            with open(path, 'wb') as f:
-                f.write(bytes_.replace(subj, repl))
-
-
-def files_hash(paths, from_stdin, alg):
-    if from_stdin:
-        hash = hashlib.new(alg)
-        hash.update(sys.stdin.buffer.read())
-        print(" ".join([hash.hexdigest(), "-"]))
-    else:
-        for path in paths:
-            with open(path, 'rb') as f:
-                hash = hashlib.new(alg)
-                hash.update(f.read())
-                print(" ".join([hash.hexdigest(), path]))
-
-def files_hash_main(alg):
-    parser = argparse.ArgumentParser(description='prints {} hashsum of file'.format(alg))
-    parser.add_argument('path', nargs='*')
-    args = parser.parse_args()
-    from_stdin = len(args.path) == 0
-    paths = glob_paths_files(args.path)
-    files_hash(paths, from_stdin, alg)
-    
-(
-    T_HEAD,
-    T_TAIL
-) = range(2)
-
-def print_lines_utf8(lines):
-    for line in lines:
-        print_utf8(line, end='')
-
-def head_tail_print_lines(lines, n, t):
-    if t == T_HEAD:
-        print_lines_utf8(lines[:n])
-    else:
-        print_lines_utf8(lines[-n:])
-
-def bytes_to_lines(data):
-    text = decode_bytes(data)
-    lines = [line + '\n' for line in text.split('\n')]
-    drop_last_empty_line(lines)
-    return lines
-
-def head_tail_main(t):
-
-    args_ = sys.argv[1:]
-
-    while True:
-        i = index_of_int(args_)
-        #print(i)
-        if i is None:
-            break
-        args_ = args_[:i] + ['-n', str(abs(int(args_[i])))] + args_[i+1:]
-
-    description = 'prints n lines from {} of file'.format('head' if t == T_HEAD else 'tail')
-
-    parser = argparse.ArgumentParser(description=description)
-    parser.add_argument('-n', type=int, default=10, help='number of lines to print')
-    parser.add_argument('path', nargs="*")
-    args = parser.parse_args(args_)
-    
-    if len(args.path) == 0:
-        data = read_stdin_bin()
-        lines = bytes_to_lines(data)
-        head_tail_print_lines(lines, args.n, t)
-    else:
-        paths = glob_paths_files(args.path)
-        for path in paths:
-            data = read_file_bin(path)
-            lines = bytes_to_lines(data)
-            head_tail_print_lines(lines, args.n, t)
-
-def parse_time_arg(text):
-    m = re.match('([+-]?)([0-9.e-]+)(d|h|m|s|)', text)
-    if m is None:
-        return
-    sign = -1 if m.group(1) == '-' else 1
-    value = float(m.group(2))
-    suffix = m.group(3)
-    mul = {"d": 3600 * 24, "h": 3600, "m": 60, "s": 1, "": 1}[suffix]
-    return sign * mul * value
+import sys
+import re
+from .shared import glob_paths, glob_paths_files, read_bytes, print_bytes
+import argparse
+import hashlib
+import argparse
+import sys
+from .shared import glob_paths_files, print_utf8, drop_last_empty_line, index_of_int
+import os
+import fnmatch
+
+def decode_bytes(data):
+    try:
+        text = data.decode('utf-8')
+    except UnicodeDecodeError:
+        text = data.decode(sys.stdin.encoding)
+    return text
+
+def read_file_bin(path):
+    with open(path, 'rb') as f:
+        return f.read()
+
+def read_stdin_bin():
+    return sys.stdin.buffer.read()
+
+def read_stdin_text():
+    data = sys.stdin.buffer.read()
+    return decode_bytes(data)
+
+def read_file_text(path):
+    data = read_file_bin(path)
+    return decode_bytes(data)
+
+def chunks(lst, n):
+    """Yield successive n-sized chunks from lst."""
+    for i in range(0, len(lst), n):
+        yield lst[i:i + n]
+
+def parse_size(arg):
+    m = re.match('^([-+]?[0-9.e]+)+([cwbkmg]?)$', arg, re.IGNORECASE)
+    if m is None:
+        return None
+    size = float(m.group(1))
+    prefix = m.group(2)
+    return int(size * {'k': 1024, 'm': 1024 * 1024, 'g': 1024 * 1024 * 1024, 'c': 1, 'b': 512, '': 1}[prefix.lower()])
+
+import argparse
+
+(
+    TO_UNIX,
+    TO_DOS
+) = range(2)
+
+def convertlineterm(to_what):
+
+    description = {
+        TO_UNIX: 'converts line endings from dos to unix (\\r\\n -> \\n)',
+        TO_DOS: 'converts line endings from unix to dos (\\n -> \\r\\n)'
+    }[to_what]
+
+    parser = argparse.ArgumentParser(description=description)
+    parser.add_argument('path', nargs='*')
+    args = parser.parse_args()
+    paths = glob_paths_files(args.path)
+
+    stdin_mode = len(args.path) == 0
+
+    if to_what == TO_UNIX:
+        subj = b'\r\n'
+        repl = b'\n'
+    else:
+        subj = b'\n'
+        repl = b'\r\n'
+
+    if stdin_mode:
+        bytes_ = read_bytes(None)
+        print_bytes(bytes_.replace(subj, repl))
+    else:
+        for path in paths:
+            bytes_ = read_bytes(path)
+            with open(path, 'wb') as f:
+                f.write(bytes_.replace(subj, repl))
+
+
+def files_hash(paths, from_stdin, alg):
+    if from_stdin:
+        hash = hashlib.new(alg)
+        hash.update(sys.stdin.buffer.read())
+        print(" ".join([hash.hexdigest(), "-"]))
+    else:
+        for path in paths:
+            with open(path, 'rb') as f:
+                hash = hashlib.new(alg)
+                hash.update(f.read())
+                print(" ".join([hash.hexdigest(), path]))
+
+def files_hash_main(alg):
+    parser = argparse.ArgumentParser(description='prints {} hashsum of file'.format(alg))
+    parser.add_argument('path', nargs='*')
+    args = parser.parse_args()
+    from_stdin = len(args.path) == 0
+    paths = glob_paths_files(args.path)
+    files_hash(paths, from_stdin, alg)
+    
+(
+    T_HEAD,
+    T_TAIL
+) = range(2)
+
+def print_lines_utf8(lines):
+    for line in lines:
+        print_utf8(line, end='')
+
+def head_tail_print_lines(lines, n, t):
+    if t == T_HEAD:
+        print_lines_utf8(lines[:n])
+    else:
+        print_lines_utf8(lines[-n:])
+
+def bytes_to_lines(data):
+    text = decode_bytes(data)
+    lines = [line + '\n' for line in text.split('\n')]
+    drop_last_empty_line(lines)
+    return lines
+
+# todo bytes, chars
+
+def head_tail_main(t):
+
+    args_ = sys.argv[1:]
+
+    while True:
+        i = index_of_int(args_)
+        #print(i)
+        if i is None:
+            break
+        args_ = args_[:i] + ['-n', str(abs(int(args_[i])))] + args_[i+1:]
+
+    description = 'prints n lines from {} of file'.format('head' if t == T_HEAD else 'tail')
+
+    parser = argparse.ArgumentParser(description=description)
+    parser.add_argument('-n', type=int, default=10, help='number of lines to print')
+    parser.add_argument('path', nargs="*")
+    args = parser.parse_args(args_)
+    
+    if len(args.path) == 0:
+        data = read_stdin_bin()
+        lines = bytes_to_lines(data)
+        head_tail_print_lines(lines, args.n, t)
+    else:
+        paths = glob_paths_files(args.path)
+        for path in paths:
+            data = read_file_bin(path)
+            lines = bytes_to_lines(data)
+            head_tail_print_lines(lines, args.n, t)
+
+def parse_time_arg(text):
+    m = re.match('([+-]?)([0-9.e-]+)(d|h|m|s|)', text)
+    if m is None:
+        return
+    sign = -1 if m.group(1) == '-' else 1
+    value = float(m.group(2))
+    suffix = m.group(3)
+    mul = {"d": 3600 * 24, "h": 3600, "m": 60, "s": 1, "": 1}[suffix]
+    return sign * mul * value
+
+def walk(top, topdown=True, onerror=None, followlinks=False, maxdepth=0):
+    return _walk(os.fspath(top), topdown, onerror, followlinks, maxdepth)
+
+def _walk(top, topdown, onerror, followlinks, maxdepth):
+    dirs = []
+    nondirs = []
+    walk_dirs = []
+    try:
+        scandir_it = os.scandir(top)
+    except OSError as error:
+        if onerror is not None:
+            onerror(error)
+        return
+
+    with scandir_it:
+        while True:
+            try:
+                try:
+                    entry = next(scandir_it)
+                except StopIteration:
+                    break
+            except OSError as error:
+                if onerror is not None:
+                    onerror(error)
+                return
+
+            try:
+                is_dir = entry.is_dir()
+            except OSError:
+                is_dir = False
+
+            if is_dir:
+                dirs.append(entry.name)
+            else:
+                nondirs.append(entry.name)
+
+            if not topdown and is_dir:
+                if followlinks:
+                    walk_into = True
+                else:
+                    try:
+                        is_symlink = entry.is_symlink()
+                    except OSError:
+                        is_symlink = False
+                    walk_into = not is_symlink
+
+                if walk_into:
+                    walk_dirs.append(entry.path)
+
+    maxdepth -= 1
+    if maxdepth == 0:
+        walk_dirs = []
+
+    if topdown:
+        yield top, dirs, nondirs
+        if maxdepth == 0:
+            return
+        islink, join = os.path.islink, os.path.join
+        for dirname in dirs:
+            new_path = join(top, dirname)
+            if followlinks or not islink(new_path):
+                yield from _walk(new_path, topdown, onerror, followlinks, maxdepth)
+    else:
+        for new_path in walk_dirs:
+            yield from _walk(new_path, topdown, onerror, followlinks, maxdepth)
+        yield top, dirs, nondirs
+
+def include_exclude(include, exclude, name):
+    if include is None and exclude is None:
+        return True
+    if include is None:
+        ok = True
+    else:
+        ok = False
+        for pat in include:
+            if fnmatch.fnmatch(name, pat):
+                ok = True
+    if not ok:
+        return False
+    if exclude is None:
+        return True
+    else:
+        for pat in exclude:
+            if fnmatch.fnmatch(name, pat):
+                return False
+    return True
```

## mugicli/headtail.py

 * *Ordering differences only*

```diff
@@ -1,45 +1,45 @@
-import argparse
-import sys
-from .shared import glob_paths, read_bytes, print_lines, drop_last_empty_line, index_of_int
-import re
-
-def _print_lines(lines, n, is_head):
-    if is_head:
-        print_lines(lines[:n])
-    else:
-        print_lines(lines[-n:])
-
-def bytes_to_lines(bytes_):
-    lines = [line + '\n' for line in bytes_.decode('utf-8').split('\n')]
-    drop_last_empty_line(lines)
-    return lines
-
-def head_tail(is_head = True):
-
-    args_ = sys.argv[1:]
-
-    while True:
-        i = index_of_int(args_)
-        #print(i)
-        if i is None:
-            break
-        args_ = args_[:i] + ['-n', str(abs(int(args_[i])))] + args_[i+1:]
-
-    description = 'prints n lines from {} of file'.format('head' if is_head else 'tail')
-
-    parser = argparse.ArgumentParser(description=description)
-    parser.add_argument('-n', type=int, default=10, help='number of lines to print')
-    parser.add_argument('path', nargs="*")
-    args = parser.parse_args(args_)
-    paths = glob_paths(args.path)
-    stdin_mode = len(paths) == 0
-
-    if stdin_mode:
-        bytes_ = read_bytes([])
-        lines = bytes_to_lines(bytes_)
-        _print_lines(lines, args.n, is_head)
-    else:
-        for path in paths:
-            bytes_ = read_bytes([path])
-            lines = bytes_to_lines(bytes_)
+import argparse
+import sys
+from .shared import glob_paths, read_bytes, print_lines, drop_last_empty_line, index_of_int
+import re
+
+def _print_lines(lines, n, is_head):
+    if is_head:
+        print_lines(lines[:n])
+    else:
+        print_lines(lines[-n:])
+
+def bytes_to_lines(bytes_):
+    lines = [line + '\n' for line in bytes_.decode('utf-8').split('\n')]
+    drop_last_empty_line(lines)
+    return lines
+
+def head_tail(is_head = True):
+
+    args_ = sys.argv[1:]
+
+    while True:
+        i = index_of_int(args_)
+        #print(i)
+        if i is None:
+            break
+        args_ = args_[:i] + ['-n', str(abs(int(args_[i])))] + args_[i+1:]
+
+    description = 'prints n lines from {} of file'.format('head' if is_head else 'tail')
+
+    parser = argparse.ArgumentParser(description=description)
+    parser.add_argument('-n', type=int, default=10, help='number of lines to print')
+    parser.add_argument('path', nargs="*")
+    args = parser.parse_args(args_)
+    paths = glob_paths(args.path)
+    stdin_mode = len(paths) == 0
+
+    if stdin_mode:
+        bytes_ = read_bytes([])
+        lines = bytes_to_lines(bytes_)
+        _print_lines(lines, args.n, is_head)
+    else:
+        for path in paths:
+            bytes_ = read_bytes([path])
+            lines = bytes_to_lines(bytes_)
             _print_lines(lines, args.n, is_head)
```

## mugicli/pycat.py

 * *Ordering differences only*

```diff
@@ -1,27 +1,27 @@
-import argparse
-from datetime import date
-import datetime
-import dateutil.parser
-import glob
-import os
-import sys
-from .shared import glob_paths, eprint
-
-def main():
-    parser = argparse.ArgumentParser(description='prints file to stdout')
-    parser.add_argument('path', nargs='+')
-    parser.add_argument('--text', '-t', action='store_true')
-
-    args = parser.parse_args()
-
-    paths = glob_paths(args.path)
-
-    for path in paths:
-        try:
-            with open(path, 'rb') as f:
-                sys.stdout.buffer.write(f.read())
-        except Exception as e:
-            eprint(e)
-
-if __name__ == "__main__":
+import argparse
+from datetime import date
+import datetime
+import dateutil.parser
+import glob
+import os
+import sys
+from .shared import glob_paths, eprint
+
+def main():
+    parser = argparse.ArgumentParser(description='prints file to stdout')
+    parser.add_argument('path', nargs='+')
+    parser.add_argument('--text', '-t', action='store_true')
+
+    args = parser.parse_args()
+
+    paths = glob_paths(args.path)
+
+    for path in paths:
+        try:
+            with open(path, 'rb') as f:
+                sys.stdout.buffer.write(f.read())
+        except Exception as e:
+            eprint(e)
+
+if __name__ == "__main__":
     main()
```

## mugicli/pycol.py

 * *Ordering differences only*

```diff
@@ -1,25 +1,25 @@
-import os
-import argparse
-from . import read_stdin_text
-from .shared import glob_paths_files, print_utf8
-import re
-
-def print_cols(line, col_numbers):
-    cols = re.split('\\s+', line)
-    cols_ = [cols[i-1] if i-1 < len(cols) else '' for i in col_numbers]
-    print_utf8(" ".join(cols_))
-
-def main():
-    parser = argparse.ArgumentParser(description='extracts and prints specific columns') # todo separators
-    parser.add_argument('path', nargs='*')
-    parser.add_argument('-n', type=int, nargs='+', help='column number') # todo range expr
-    args = parser.parse_args()
-    if len(args.path) == 0:
-        for line in read_stdin_text().split('\n'):
-            print_cols(line, args.n)
-    else:
-        for path in glob_paths_files(args.path):
-            print_cols(path, args.n)
-
-if __name__ == "__main__":
-    main()
+import os
+import argparse
+from . import read_stdin_text
+from .shared import glob_paths_files, print_utf8
+import re
+
+def print_cols(line, col_numbers):
+    cols = re.split('\\s+', line)
+    cols_ = [cols[i-1] if i-1 < len(cols) else '' for i in col_numbers]
+    print_utf8(" ".join(cols_))
+
+def main():
+    parser = argparse.ArgumentParser(description='extracts and prints specific columns') # todo separators
+    parser.add_argument('path', nargs='*')
+    parser.add_argument('-n', type=int, nargs='+', help='column number') # todo range expr
+    args = parser.parse_args()
+    if len(args.path) == 0:
+        for line in read_stdin_text().split('\n'):
+            print_cols(line, args.n)
+    else:
+        for path in glob_paths_files(args.path):
+            print_cols(path, args.n)
+
+if __name__ == "__main__":
+    main()
```

## mugicli/pydu.py

 * *Ordering differences only*

```diff
@@ -1,197 +1,197 @@
-import argparse
-import os
-
-from collections import defaultdict
-from itertools import count, zip_longest
-import re
-from .shared import glob_paths
-
-# todo cleanup unused code
-# todo human readible
-# todo summary
-# todo --files
-
-def int_ceil(num, den):
-    return (num + den - 1) // den
-
-def is_path_in(path1, path2):
-    if len(path1) < len(path2):
-        return False
-    for n1, n2 in zip(path1, path2):
-        if n1 != n2:
-            return False
-    return True
-
-def count_equal(it1, it2):
-    for i, v1, v2 in zip(count(), it1, it2):
-        if v1 != v2:
-            return i-1
-    return i-1
-
-def path_split_(path):
-    path_ = re.split('[/\\\\]', path)
-    if re.match('^[a-z]:$',path_[0], re.IGNORECASE):
-        path_[0] = path_[0] + '\\'
-    return path_
-
-def path_split(path):
-    res = []
-    rx = re.compile('^([a-z]:\\\\|\\/)$', re.IGNORECASE)
-    while True:
-        head, tail = os.path.split(path)
-        res.append(tail)
-        path = head
-        if head == '':
-            return list(reversed(res))
-        if rx.match(head):
-            res.append(head)
-            return list(reversed(res))
-
-def without_none(items):
-    return [v for v in items if v is not None]
-
-def path_diff(path1, path2):
-    
-    comm = []
-    res1 = []
-    res2 = []
-
-    is_comm = True
-    for n1, n2 in zip_longest(path_split(path1), path_split(path2), fillvalue=None):
-        if is_comm:
-            if None in [n1, n2]:
-                is_comm = False
-            else:
-                is_comm = n1 == n2
-        if is_comm:
-            comm.append(n1)
-        else:
-            res1.append(n1)
-            res2.append(n2)
-    
-    return comm, without_none(res1), without_none(res2)
-
-class Printer:
-    def print(self, size, path):
-        print("{:10d} {}".format(int_ceil(size, 1024), path))
-        pass
-
-class DirStat:
-    def __init__(self, printer):
-        self._flushed = set()
-        self._stat = defaultdict(int)
-        self._printer = printer
-        self._prev = None
-
-        self._queue = []
-
-    def add_file(self, root, f):
-        path = os.path.join(root, f)
-        size = os.path.getsize(path)
-        path_ = path_split(path)
-        for n in range(1, len(path_)):
-            self._stat[os.path.join(*path_[:n])] += size
-        #self._printer.print(size, path)
-
-    def add_dir(self, root, d):
-        path = os.path.join(root, d)
-        self._stat[path] = 0
-
-    def begin(self, path):
-        self._root = path
-
-    def end(self):
-        self.add_root(os.path.dirname(self._root))
-        self._queue = []
-
-    def add_root(self, root):
-
-        def pop_queue():
-            for i, path in enumerate(self._queue):
-                if not root.startswith(path):
-                    return self._queue.pop(i)
-        
-        while True:
-            path = pop_queue()
-            if path is None:
-                break
-            #print("flush {}".format(path))
-            self._printer.print(self._stat[path], path)
-        
-        self._queue = [root] + self._queue
-
-    def add_root_(self, root):
-        if self._prev is None:
-            self._prev = root
-            return
-
-        #print(root)
-
-        #print(*path_diff(self._prev, root))
-        comm, prev, root_ = path_diff(self._prev, root)
-
-        if len(prev) > 1:
-            """
-            for i in range(1,len(prev)+1):
-                path_ = comm + prev[:i]
-                #print(path_)
-                print("flush " + os.path.join(*path_))
-            """
-            path_ = os.path.join(*(comm + [prev[0]]))
-            for path, size in self._stat.items():
-                if path in self._flushed:
-                    continue
-                if path.startswith(path_):
-                    #print("flush " + path)
-                    self._printer.print(size, path)
-                self._flushed.add(path)
-
-        self._prev = root
-
-        #print('add_root', root)
-        """
-        root_ = os.path.split(root)
-        for root2, size in self._stat.items():
-            if root2 == self._root:
-                continue
-            if root2 in self._flushed:
-                continue
-            root2_ = os.path.split(root2)
-            if not is_path_in(root2_, root_):
-                #print('{} not in {}'.format(root2, root))
-                self._flushed.add(root2)
-                self._printer.print(size, root2)
-        """
-
-def main():
-    parser = argparse.ArgumentParser(add_help=False, description='prints directories sizes')
-    parser.add_argument('-s',action='store_true', help='print only summary')
-    parser.add_argument('-h',action='store_true', help='print in human readible units')
-    parser.add_argument('path', nargs='*', help='path to calculate')
-    parser.add_argument('--help', action='help')
-
-    args = parser.parse_args()
-
-    paths = glob_paths(args.path)
-    if len(paths) == 0:
-        paths.append(os.getcwd())
-
-    #print(paths); exit(0)
-
-    printer = Printer()
-
-    stat = DirStat(printer)
-
-    for path in paths:
-        #print('os.walk(path)', path)
-        stat.begin(path)
-        for root, dirs, files in os.walk(path):
-            stat.add_root(root)
-            for d in dirs:
-                stat.add_dir(root, d)
-            for f in files:
-                stat.add_file(root, f)
-        stat.end()
-
-if __name__ == "__main__":
+import argparse
+import os
+
+from collections import defaultdict
+from itertools import count, zip_longest
+import re
+from .shared import glob_paths
+
+# todo cleanup unused code
+# todo human readible
+# todo summary
+# todo --files
+
+def int_ceil(num, den):
+    return (num + den - 1) // den
+
+def is_path_in(path1, path2):
+    if len(path1) < len(path2):
+        return False
+    for n1, n2 in zip(path1, path2):
+        if n1 != n2:
+            return False
+    return True
+
+def count_equal(it1, it2):
+    for i, v1, v2 in zip(count(), it1, it2):
+        if v1 != v2:
+            return i-1
+    return i-1
+
+def path_split_(path):
+    path_ = re.split('[/\\\\]', path)
+    if re.match('^[a-z]:$',path_[0], re.IGNORECASE):
+        path_[0] = path_[0] + '\\'
+    return path_
+
+def path_split(path):
+    res = []
+    rx = re.compile('^([a-z]:\\\\|\\/)$', re.IGNORECASE)
+    while True:
+        head, tail = os.path.split(path)
+        res.append(tail)
+        path = head
+        if head == '':
+            return list(reversed(res))
+        if rx.match(head):
+            res.append(head)
+            return list(reversed(res))
+
+def without_none(items):
+    return [v for v in items if v is not None]
+
+def path_diff(path1, path2):
+    
+    comm = []
+    res1 = []
+    res2 = []
+
+    is_comm = True
+    for n1, n2 in zip_longest(path_split(path1), path_split(path2), fillvalue=None):
+        if is_comm:
+            if None in [n1, n2]:
+                is_comm = False
+            else:
+                is_comm = n1 == n2
+        if is_comm:
+            comm.append(n1)
+        else:
+            res1.append(n1)
+            res2.append(n2)
+    
+    return comm, without_none(res1), without_none(res2)
+
+class Printer:
+    def print(self, size, path):
+        print("{:10d} {}".format(int_ceil(size, 1024), path))
+        pass
+
+class DirStat:
+    def __init__(self, printer):
+        self._flushed = set()
+        self._stat = defaultdict(int)
+        self._printer = printer
+        self._prev = None
+
+        self._queue = []
+
+    def add_file(self, root, f):
+        path = os.path.join(root, f)
+        size = os.path.getsize(path)
+        path_ = path_split(path)
+        for n in range(1, len(path_)):
+            self._stat[os.path.join(*path_[:n])] += size
+        #self._printer.print(size, path)
+
+    def add_dir(self, root, d):
+        path = os.path.join(root, d)
+        self._stat[path] = 0
+
+    def begin(self, path):
+        self._root = path
+
+    def end(self):
+        self.add_root(os.path.dirname(self._root))
+        self._queue = []
+
+    def add_root(self, root):
+
+        def pop_queue():
+            for i, path in enumerate(self._queue):
+                if not root.startswith(path):
+                    return self._queue.pop(i)
+        
+        while True:
+            path = pop_queue()
+            if path is None:
+                break
+            #print("flush {}".format(path))
+            self._printer.print(self._stat[path], path)
+        
+        self._queue = [root] + self._queue
+
+    def add_root_(self, root):
+        if self._prev is None:
+            self._prev = root
+            return
+
+        #print(root)
+
+        #print(*path_diff(self._prev, root))
+        comm, prev, root_ = path_diff(self._prev, root)
+
+        if len(prev) > 1:
+            """
+            for i in range(1,len(prev)+1):
+                path_ = comm + prev[:i]
+                #print(path_)
+                print("flush " + os.path.join(*path_))
+            """
+            path_ = os.path.join(*(comm + [prev[0]]))
+            for path, size in self._stat.items():
+                if path in self._flushed:
+                    continue
+                if path.startswith(path_):
+                    #print("flush " + path)
+                    self._printer.print(size, path)
+                self._flushed.add(path)
+
+        self._prev = root
+
+        #print('add_root', root)
+        """
+        root_ = os.path.split(root)
+        for root2, size in self._stat.items():
+            if root2 == self._root:
+                continue
+            if root2 in self._flushed:
+                continue
+            root2_ = os.path.split(root2)
+            if not is_path_in(root2_, root_):
+                #print('{} not in {}'.format(root2, root))
+                self._flushed.add(root2)
+                self._printer.print(size, root2)
+        """
+
+def main():
+    parser = argparse.ArgumentParser(add_help=False, description='prints directories sizes')
+    parser.add_argument('-s',action='store_true', help='print only summary')
+    parser.add_argument('-h',action='store_true', help='print in human readible units')
+    parser.add_argument('path', nargs='*', help='path to calculate')
+    parser.add_argument('--help', action='help')
+
+    args = parser.parse_args()
+
+    paths = glob_paths(args.path)
+    if len(paths) == 0:
+        paths.append(os.getcwd())
+
+    #print(paths); exit(0)
+
+    printer = Printer()
+
+    stat = DirStat(printer)
+
+    for path in paths:
+        #print('os.walk(path)', path)
+        stat.begin(path)
+        for root, dirs, files in os.walk(path):
+            stat.add_root(root)
+            for d in dirs:
+                stat.add_dir(root, d)
+            for f in files:
+                stat.add_file(root, f)
+        stat.end()
+
+if __name__ == "__main__":
     main()
```

## mugicli/pyecho.py

 * *Ordering differences only*

```diff
@@ -1,91 +1,91 @@
-import re
-import os
-import sys
-from .shared import parse_args
-
-"""
-def parse_args(args):
-    opts = {
-        '-e': False,
-        '-n': False,
-        '-ne': False,
-        '-en': False
-    }
-    while args[0] in opts.keys():
-        opt = args.pop(0)
-        opts[opt] = True
-    if opts['-ne'] or opts['-en']:
-        opts['-n'] = True
-        opts['-e'] = True
-    return opts, args
-"""
-
-def print_help():
-    print("""usage: pyecho [-e] [-n] [args...]
-
-prints text to stdout
-
-optional arguments:
--h --help  show this message and exit
--e         decode escape sequences
--n         do not print newline
-""")
-    
-def main():
-    """
-    def env_vars(m):
-        n = m.group(1)
-        if n in os.environ:
-            return os.environ[n]
-        return '%' + n + '%'
-    def expand_vars(arg):
-        return re.sub("%([^%]*)%", env_vars, arg)
-    """
-
-    def unescape(arg):
-        return arg.encode('utf-8').decode('unicode_escape')
-
-    #print(sys.argv)
-
-    opts, args = parse_args(['e','n','h'],['help'],[],[],sys.argv[1:])
-
-    if opts['h'] or opts['help']:
-        print_help()
-        return
-
-    def transform(queue, res):
-
-        if len(queue) == 0:
-            return False
-
-        arg = queue.pop(0)
-
-        if opts['e']:
-            arg = unescape(arg)
-        m = re.search("\\{([0-9]+)..([0-9]+)\\}", arg)
-        if m:
-            head, tail = arg.split(m.group(0), 1)
-            start = int(m.group(1))
-            end = int(m.group(2))
-            for i in reversed(range(start, end+1)):
-                queue.insert(0, "{}{}{}".format(head, i, tail))
-        else:
-            res.append(arg)
-        
-        return True
-        
-    #args = [transform(arg) for arg in args]
-    
-    queue = args
-    res = []
-
-    while(transform(queue, res)):
-        pass
-
-    text = " ".join(res)
-    sys.stdout.buffer.write(text.encode('utf-8'))
-    if not opts['n']:
-        sys.stdout.buffer.write(b'\n')
-
-if __name__ == "__main__":
+import re
+import os
+import sys
+from .shared import parse_args
+
+"""
+def parse_args(args):
+    opts = {
+        '-e': False,
+        '-n': False,
+        '-ne': False,
+        '-en': False
+    }
+    while args[0] in opts.keys():
+        opt = args.pop(0)
+        opts[opt] = True
+    if opts['-ne'] or opts['-en']:
+        opts['-n'] = True
+        opts['-e'] = True
+    return opts, args
+"""
+
+def print_help():
+    print("""usage: pyecho [-e] [-n] [args...]
+
+prints text to stdout
+
+optional arguments:
+-h --help  show this message and exit
+-e         decode escape sequences
+-n         do not print newline
+""")
+    
+def main():
+    """
+    def env_vars(m):
+        n = m.group(1)
+        if n in os.environ:
+            return os.environ[n]
+        return '%' + n + '%'
+    def expand_vars(arg):
+        return re.sub("%([^%]*)%", env_vars, arg)
+    """
+
+    def unescape(arg):
+        return arg.encode('utf-8').decode('unicode_escape')
+
+    #print(sys.argv)
+
+    opts, args = parse_args(['e','n','h'],['help'],[],[],sys.argv[1:])
+
+    if opts['h'] or opts['help']:
+        print_help()
+        return
+
+    def transform(queue, res):
+
+        if len(queue) == 0:
+            return False
+
+        arg = queue.pop(0)
+
+        if opts['e']:
+            arg = unescape(arg)
+        m = re.search("\\{([0-9]+)..([0-9]+)\\}", arg)
+        if m:
+            head, tail = arg.split(m.group(0), 1)
+            start = int(m.group(1))
+            end = int(m.group(2))
+            for i in reversed(range(start, end+1)):
+                queue.insert(0, "{}{}{}".format(head, i, tail))
+        else:
+            res.append(arg)
+        
+        return True
+        
+    #args = [transform(arg) for arg in args]
+    
+    queue = args
+    res = []
+
+    while(transform(queue, res)):
+        pass
+
+    text = " ".join(res)
+    sys.stdout.buffer.write(text.encode('utf-8'))
+    if not opts['n']:
+        sys.stdout.buffer.write(b'\n')
+
+if __name__ == "__main__":
     main()
```

## mugicli/pyextstat.py

 * *Ordering differences only*

```diff
@@ -1,48 +1,48 @@
-import os
-import argparse
-from .shared import glob_paths_dirs
-from . import read_stdin_text
-
-def main():
-    parser = argparse.ArgumentParser(description='prints file extension statistics')
-    parser.add_argument("path", nargs="*", help="paths")
-    parser.add_argument('-s', '--short', action='store_true')
-
-    args = parser.parse_args()
-    
-    stat = dict()
-    if len(args.path) == 0:
-        # read paths from stdin
-        text = read_stdin_text()
-        for line in text.split('\n'):
-            line = line.rstrip()
-            ext = os.path.splitext(line)[1]
-            if ext not in stat:
-                stat[ext] = 0
-            stat[ext] += 1
-    else:
-        # walk paths
-        paths = glob_paths_dirs(args.path)
-        for path in paths:
-            for root, dirs, files in os.walk(path):
-                for f in files:
-                    ext = os.path.splitext(f)[1]
-                    if ext not in stat:
-                        stat[ext] = 0
-                    stat[ext] += 1
-
-    total = sum(stat.values())
-    stat_ = [(ext, count) for ext, count in stat.items()]
-    stat_.sort(key= lambda item: item[1], reverse=True)
-
-    t = 0
-    for ext, count in stat_:
-        print("{:7d} {}".format(count, ext))
-        t += count
-        if args.short and t / total > 0.9:
-            print("{:7d} {}".format(total-t, "other"))
-            break
-    print("{:7d} {}".format(total, "total"))
-
-if __name__ == "__main__":
+import os
+import argparse
+from .shared import glob_paths_dirs
+from . import read_stdin_text
+
+def main():
+    parser = argparse.ArgumentParser(description='prints file extension statistics')
+    parser.add_argument("path", nargs="*", help="paths")
+    parser.add_argument('-s', '--short', action='store_true')
+
+    args = parser.parse_args()
+    
+    stat = dict()
+    if len(args.path) == 0:
+        # read paths from stdin
+        text = read_stdin_text()
+        for line in text.split('\n'):
+            line = line.rstrip()
+            ext = os.path.splitext(line)[1]
+            if ext not in stat:
+                stat[ext] = 0
+            stat[ext] += 1
+    else:
+        # walk paths
+        paths = glob_paths_dirs(args.path)
+        for path in paths:
+            for root, dirs, files in os.walk(path):
+                for f in files:
+                    ext = os.path.splitext(f)[1]
+                    if ext not in stat:
+                        stat[ext] = 0
+                    stat[ext] += 1
+
+    total = sum(stat.values())
+    stat_ = [(ext, count) for ext, count in stat.items()]
+    stat_.sort(key= lambda item: item[1], reverse=True)
+
+    t = 0
+    for ext, count in stat_:
+        print("{:7d} {}".format(count, ext))
+        t += count
+        if args.short and t / total > 0.9:
+            print("{:7d} {}".format(total-t, "other"))
+            break
+    print("{:7d} {}".format(total, "total"))
+
+if __name__ == "__main__":
     main()
```

## mugicli/pyfind.py

```diff
@@ -1,884 +1,818 @@
-import argparse
-import os
-import datetime
-import sys
-import re
-from .shared import eprint, glob_paths_dirs, has_magic, run, print_utf8
-import sys
-from dataclasses import dataclass
-from itertools import count
-import subprocess
-import shutil
-import fnmatch
-from . import parse_size
-
-try:
-    import dateutil.parser
-except ImportError as e:
-    eprint("{}, -newermt -newerct is limited to yyyy-mm-dd format".format(str(e)))
-    def parse_date(value):
-        m = re.match('([0-9]{4})-([0-9]{2})-([0-9]{2})', value)
-        if m:
-            year = int(m.group(1))
-            month = int(m.group(2))
-            day = int(m.group(3))
-            return datetime.datetime(year, month, day)
-    class dateutil:
-        class parser:
-            parse = parse_date
-
-class Tok:
-    (
-        und,
-        op_par,
-        cl_par,
-        not_,
-        and_,
-        or_,
-        mmin,
-        iname,
-        name,
-        type,
-        f,
-        d,
-        newer,
-        newermt,
-        newerct,
-        arg,
-        path,
-        ipath,
-        mtime,
-        ctime,
-        size,
-        exec,
-        delete,
-        semicolon,
-        pathbind,
-        icont,
-        cont,
-        bcont,
-        maxdepth,
-        cdup,
-        first,
-        last,
-    ) = range(32)
-    
-m = {
-    "(": Tok.op_par,
-    ")": Tok.cl_par,
-    "!": Tok.not_,
-    "-not": Tok.not_,
-    "-a": Tok.and_,
-    "-and": Tok.and_,
-    "-o": Tok.or_,
-    "-or": Tok.or_,
-    "-mmin": Tok.mmin,
-    "-iname": Tok.iname,
-    "-name": Tok.name,
-    "-type": Tok.type,
-    "f": Tok.f,
-    "d": Tok.d,
-    "-newer": Tok.newer,
-    "-newermt": Tok.newermt,
-    "-newerct": Tok.newerct,
-    "-mtime": Tok.mtime,
-    "-ctime": Tok.ctime,
-    "-size": Tok.size,
-    "-exec": Tok.exec,
-    "-delete": Tok.delete,
-    ";": Tok.semicolon,
-    "{}": Tok.pathbind,
-    "-icont": Tok.icont,
-    "-cont": Tok.cont,
-    "-bcont": Tok.bcont,
-    "-path": Tok.path,
-    "-ipath": Tok.ipath,
-    "-maxdepth": Tok.maxdepth,
-    "-cdup": Tok.cdup,
-    "-first": Tok.first,
-    "-last": Tok.last,
-}
-
-inv_m = {v:k for k,v in m.items()}
-
-@dataclass
-class T:
-    type: int
-    cont: str
-
-tok_pred = [Tok.mmin, Tok.iname, Tok.name, Tok.type, Tok.newer, 
-    Tok.newerct, Tok.newermt, Tok.mtime, Tok.ctime,  Tok.size, Tok.cont, Tok.icont, Tok.bcont, Tok.path, Tok.ipath]
-
-def cdup_path(path, cdup):
-    for i in range(cdup):
-        path = os.path.dirname(path)
-    return path
-
-def split_list(vs, sep):
-    res = []
-    for v in vs:
-        if v == sep:
-            yield res
-            res = []
-        else:
-            res.append(v)
-    yield res
-    res = []
-
-class ActionExec:
-    def __init__(self, tokens, cdup):
-        self._tokens = tokens
-        self._cdup = cdup
-
-    def exec(self, root, name, path, is_dir):
-        path = cdup_path(path, self._cdup)
-        exprs = [t.cont.replace('{}', path) for t in self._tokens]
-        for expr in split_list(exprs, '&&'):
-            run(expr)
-
-class ActionDelete:
-
-    def __init__(self, cdup):
-        self._cdup = cdup
-
-    def exec(self, root, name, path, is_dir):
-        path = cdup_path(path, self._cdup)
-        if is_dir:
-            eprint("Removing directory {}".format(path))
-            shutil.rmtree(path)
-        else:
-            eprint("Removing file {}".format(path))
-            os.remove(path)
-
-
-class ActionPrint:
-
-    def __init__(self, cdup):
-        self._cdup = cdup
-
-    def exec(self, root, name, path, is_dir):
-        path = cdup_path(path, self._cdup)
-        if os.path.isabs(root):
-            print_utf8(path)
-        else:
-            print_utf8(os.path.relpath(path, os.getcwd()))
-
-def index_of_token(tokens, type):
-    for i, tok in enumerate(tokens):
-        if tok.type == type:
-            return i
-
-@dataclass
-class ExtraArgs:
-    maxdepth: int
-    first: int
-    last: int
-
-def pop_named_token_and_value(tokens, t):
-    ix = index_of_token(tokens, t)
-    if ix is None:
-        return None
-    if ix is not None:
-        token_key = tokens.pop(ix)
-        token_value = tokens.pop(ix)
-        return token_value.cont
-
-def to_int(v):
-    if v is None:
-        return v
-    return int(v)
-
-def to_int_or_zero(v):
-    if v is None:
-        return 0
-    return int(v)
-
-def parse_args(args = None):
-    if args is None:
-        args = sys.argv[1:]
-    tokens = [T(m[t], t) if t in m else T(Tok.und, t) for t in args]
-    for i, tok in enumerate(tokens):
-        if tok.type in tok_pred:
-            token = tokens[i+1]
-            tokens[i+1] = T(Tok.arg, token.cont)
-
-    """
-    maxdepth = 0
-    ix_maxdepth = index_of_token(tokens, Tok.maxdepth)
-    if ix_maxdepth is not None:
-        tokens.pop(ix_maxdepth)
-        token = tokens.pop(ix_maxdepth)
-        maxdepth = int(token.cont)
-    """
-
-    maxdepth = to_int_or_zero(pop_named_token_and_value(tokens, Tok.maxdepth))
-    
-    first = to_int(pop_named_token_and_value(tokens, Tok.first))
-
-    last = to_int(pop_named_token_and_value(tokens, Tok.last))
-    
-    """
-    cdup = 0
-    ix = index_of_token(tokens, Tok.cdup)
-    if ix is not None:
-        tokens.pop(ix)
-        token = tokens.pop(ix)
-        cdup = int(token.cont)
-    """
-    cdup = to_int_or_zero(pop_named_token_and_value(tokens, Tok.cdup))
-    
-    action = ActionPrint(cdup)
-
-    ix = index_of_token(tokens, Tok.delete)
-    if ix is not None:
-        tokens.pop(ix)
-        action = ActionDelete(cdup)
-    
-    ix_exec = index_of_token(tokens, Tok.exec)
-    ix_semicolon = index_of_token(tokens, Tok.semicolon)
-
-    if ix_exec is not None:
-        if ix_semicolon is None:
-            raise ValueError("Invalid exec expression: semicolon not found")
-        exec_tokens = tokens[ix_exec+1:ix_semicolon]
-        action = ActionExec(exec_tokens, cdup)
-        tokens = tokens[:ix_exec] + tokens[ix_semicolon+1:]
-
-    paths = []
-    pop_paths(tokens, paths, 0)
-    pop_paths(tokens, paths, -1)
-
-    """
-    i = len(tokens)-1
-    while i > -1 and tokens[i].type == Tok.und:
-        i -= 1
-    tokens, paths1 = tokens[:i+1], tokens[i+1:]
-    i = 0
-    while i < len(tokens) and tokens[i].type == Tok.und:
-        i += 1
-    paths2 = []
-    if i > 0:
-        paths2, tokens = tokens[:i], tokens[i:]
-    """
-
-    #expr = tokens
-    #paths = [e.cont for e in paths1 + paths2]
-
-    #print('expr, paths', expr, paths)
-
-    extraArgs = ExtraArgs(maxdepth=maxdepth, first=first, last=last)
-
-    return tokens, paths, action, extraArgs
-
-def pop_paths(tokens, paths, index):
-    while len(tokens) > 0 and tokens[index].type == Tok.und:
-        path = tokens[index].cont
-        if has_magic(path):
-            paths_ = glob_paths_dirs([path])
-            if len(paths_):
-                raise ValueError("no such path {}".format(path))
-            for p in paths_:
-                paths.append(p)
-        else:
-            if os.path.isdir(path):
-                paths.append(path)
-            else:
-                raise ValueError("no such path {}".format(path))
-        tokens.pop(index)
-
-class Cache:
-
-    # todo optimize cache for perfomance and memory (do dictionary lookups become costly for huge dictionaries?)
-
-    def __init__(self):
-        self._mtime = dict()
-        self._ctime = dict()
-        self._size = dict()
-        self._parse_size = dict()
-        self._now = datetime.datetime.now()
-        self._parse_date = dict()
-
-    def mtime(self, path):
-        if path not in self._mtime:
-            self._mtime[path] = None
-            try:
-                self._mtime[path] = datetime.datetime.fromtimestamp(os.path.getmtime(path))
-            except Exception as e:
-                eprint(e)
-        return self._mtime[path]
-
-    def ctime(self, path):
-        if path not in self._ctime:
-            self._ctime[path] = None
-            try:
-                self._ctime[path] = datetime.datetime.fromtimestamp(os.path.getctime(path))
-            except Exception as e:
-                eprint(e)
-        return self._ctime[path]
-
-    def size(self, path):
-        if path not in self._size:
-            self._size[path] = None
-            try:
-                self._size[path] = os.path.getsize(path)
-            except Exception as e:
-                eprint(e)
-        return self._size[path]
-
-    def parse_date(self, date):
-        if date not in self._parse_date:
-            self._parse_date[date] = None
-            try:
-                self._parse_date[date] = dateutil.parser.parse(date)
-            except Exception as e:
-                eprint("Invalid datetime format {}".format(date))
-        return self._parse_date[date]
-
-    def parse_size(self, arg):
-        if arg not in self._parse_size:
-            self._parse_size[arg] = None
-            parsed = parse_size(arg)
-            if parsed is None:
-                eprint("Invalid size format {}".format(arg))
-            else:
-                self._parse_size[arg] = parsed
-        return self._parse_size[arg]
-
-    def now(self):
-        return self._now
-
-def pred_mmin(name, path, is_dir, arg, cache):
-    mtime = cache.mtime(path)
-    if mtime is None:
-        return None
-    total_min = (cache.now() - mtime).total_seconds() / 60
-    arg = float(arg)
-    if arg < 0:
-        return total_min < abs(arg)
-    return total_min > arg
-
-def pred_iname(name, path, is_dir, arg, cache):
-    return fnmatch.fnmatch(name, arg)
-
-def pred_ipath(name, path, is_dir, arg, cache):
-    return fnmatch.fnmatch(path, arg)
-
-def pred_path(name, path, is_dir, arg, cache):
-    return fnmatch.fnmatchcase(path, arg)
-
-def pred_type(name, path, is_dir, arg, cache):
-    # todo validate type arg
-    return is_dir == (arg == 'd')
-
-def greater(d1, d2):
-    if None in [d1, d2]:
-        return None
-    return d1 > d2
-
-def pred_newer(name, path, is_dir, arg, cache):
-    #print([cache.mtime(path), cache.mtime(arg), cache.mtime(path) > cache.mtime(arg), arg])
-    return greater(cache.mtime(path), cache.mtime(arg))
-    
-def pred_newermt(name, path, is_dir, arg, cache):
-    return greater(cache.mtime(path), cache.parse_date(arg))
-
-def pred_newerct(name, path, is_dir, arg, cache):
-    return greater(cache.ctime(path), cache.parse_date(arg))
-
-def pred_xtime(arg, cache, xtime):
-    if xtime is None:
-        return None
-    total_days = (cache.now() - xtime).total_seconds() / 60 / 60 / 24
-    arg = float(arg)
-    if arg < 0:
-        return total_days < abs(arg)
-    return total_days > arg
-
-def pred_mtime(name, path, is_dir, arg, cache):
-    return pred_xtime(arg, cache, cache.mtime(path))
-
-def pred_ctime(name, path, is_dir, arg, cache):
-    return pred_xtime(arg, cache, cache.ctime(path))
-
-def pred_size(name, path, is_dir, arg, cache):
-    if is_dir:
-        return None
-    size_arg = cache.parse_size(arg)
-    size_path = cache.size(path)
-    if None in [size_arg, size_path]:
-        return None
-    if size_arg < 0:
-        return size_path < abs(size_arg)
-    return size_path > size_arg
-
-def pred_xcont(name, path, is_dir, arg, cache, flags, bin):
-    if is_dir:
-        return None
-    try:
-        with open(path, 'rb') as f:
-            data = f.read()
-        if bin:
-            arg = arg.encode("utf-8").decode('unicode_escape').encode("utf-8")
-        else:
-            arg = arg.encode("utf-8")
-        return re.search(arg, data, flags) is not None
-
-    except Exception as e:
-        eprint(e)
-    return None
-
-def pred_icont(name, path, is_dir, arg, cache):
-    return pred_xcont(name, path, is_dir, arg, cache, re.IGNORECASE, False)
-
-def pred_cont(name, path, is_dir, arg, cache):
-    return pred_xcont(name, path, is_dir, arg, cache, 0, False)
-
-def pred_bcont(name, path, is_dir, arg, cache):
-    return pred_xcont(name, path, is_dir, arg, cache, 0, True)
-
-def max_level(tree):
-    level = -1
-    for e in tree:
-        if isinstance(e, tuple):
-            level = max(level, e[1])
-    return level
-
-def index_op_par(tree, level):
-    for i, e in enumerate(tree):
-        if isinstance(e, tuple):
-            if isinstance(e[0], NodeOpPar) and e[1] == level:
-                return i
-
-def index_cl_par(tree, level, ix_op):
-    for i in range(ix_op + 1, len(tree)):
-        e = tree[i]
-        if isinstance(e, tuple):
-            if isinstance(e[0], NodeClPar) and e[1] == level:
-                return i
-
-def find_level(tree, level):
-    ix_op = index_op_par(tree, level)
-    if ix_op is None:
-        return None, None
-    ix_cl = index_cl_par(tree, level, ix_op)
-    if ix_cl is None:
-        # unbalanced parenthesis
-        return None, None
-    return ix_op, ix_cl + 1
-
-def group_tail(tokens):
-    i = 0
-    if len(tokens) < 1:
-        return -1
-    if tokens[i][0] == Tok.not_:
-        i += 1
-    if i > len(tokens):
-        return -1
-    if tokens[i][0] in tok_pred:
-        i += 2
-    if i > len(tokens):
-        return -1
-    if i == 0:
-        return -1
-    return i
-
-def normalize(nodes):
-    res = []
-    for node in nodes:
-        if isinstance(node, list) and len(node) == 1:
-            res.append(node[0])
-        else:
-            res.append(node)
-    return res
-
-class NodeGroupAnd:
-    def __init__(self, nodes):
-        self._children = normalize(nodes)
-
-    def eval(self, name, path, is_dir, cache):
-        for child in self._children:
-            res = child.eval(name, path, is_dir, cache)
-            if res in [None, False]:
-                return res
-        # all True
-        return True
-
-    def __repr__(self):
-        return "NodeGroupAnd({})".format(repr(self._children))
-
-class NodeGroupOr:
-    def __init__(self, nodes):
-        self._children = normalize(nodes)
-    
-    def eval(self, name, path, is_dir, cache):
-        for child in self._children:
-            res = child.eval(name, path, is_dir, cache)
-            if res in [None, True]:
-                return res
-        # all False
-        return False
-
-    def __repr__(self):
-        return "NodeGroupOr({})".format(repr(self._children))
-
-class NodeGroupNot:
-    def __init__(self, children):
-        if len(children) != 1:
-            raise ValueError("NodeGroupNot unexpected child count {}".format(repr(children)))
-        self._child = children[0]
-
-    def eval(self, name, path, is_dir, cache):
-        res = self._child.eval(name, path, is_dir, cache)
-        if res is None:
-            return None
-        return not res
-
-    def __repr__(self):
-        return "NodeGroupNot({})".format(repr(self._child))
-
-def strip_level(tokens):
-    return [e[0] if isinstance(e, tuple) else e for e in tokens]
-
-def pred_token_index(tokens):
-    for i, token in enumerate(tokens):
-        if not isinstance(token, T):
-            continue
-        if token.type in tok_pred:
-            return i
-    return -1
-
-# todo single instance (NodeOr in self._children)
-
-class NodeOpPar:
-    def __repr__(self) -> str:
-        return '('
-
-class NodeClPar:
-    def __repr__(self) -> str:
-        return ')'
-
-class NodeNot:
-    def __repr__(self) -> str:
-        return 'Not'
-
-class NodeAnd:
-    def __repr__(self) -> str:
-        return 'And'
-
-class NodeOr:
-    def __repr__(self) -> str:
-        return 'Or'
-
-class NodePred:
-    def __init__(self, tokens):
-        self._tokens = tokens
-        type_, arg = self._type_and_arg()
-
-    def __repr__(self) -> str:
-        type_, arg = self._type_and_arg()
-        type_str = inv_m[type_]
-        if len(self._tokens) == 2:
-            return 'NodePred({} {})'.format(type_str, arg)
-        else:
-            return 'NodePred(-not {} {})'.format(type_str, arg)
-
-    def _type_and_arg(self):
-        return self._tokens[-2].type, self._tokens[-1].cont
-
-    def eval(self, name, path, is_dir, cache):
-
-        exp = False if self._tokens[0].type == Tok.not_ else True
-        type_, arg = self._type_and_arg()
-        
-        if arg is None:
-            return None
-
-        res = {
-            Tok.type: pred_type,
-            Tok.mmin: pred_mmin,
-            Tok.iname: pred_iname,
-            Tok.newer: pred_newer,
-            Tok.newermt: pred_newermt,
-            Tok.newerct: pred_newerct,
-            Tok.ctime: pred_ctime,
-            Tok.mtime: pred_mtime,
-            Tok.size: pred_size,
-            Tok.cont: pred_cont,
-            Tok.icont: pred_icont,
-            Tok.bcont: pred_bcont,
-            Tok.path: pred_path,
-            Tok.ipath: pred_ipath,
-        }[type_](name, path, is_dir, arg, cache)
-
-        if res is None:
-            return None
-        return res == exp
-
-def index_of_two(items, pred):
-    res = []
-    for i, item in enumerate(items):
-        res.append(pred(item))
-        if res[-2:] == [True, True]:
-            return i-1
-
-def indexes_of_two_plus(items, pred):
-    b = index_of_two(items, pred)
-    if b is None:
-        return None, None
-    for i in range(b+2, len(items)):
-        if not pred(items[i]):
-            return b, i
-    return b, len(items)
-
-def to_children(nodes):
-    #print("to_children({})".format(repr(nodes)))
-    if isinstance(nodes[-1], NodeClPar):
-        if isinstance(nodes[0], NodeNot):
-            return [NodeGroupNot(to_children(nodes[2:-1]))]
-        else:
-            return to_children(nodes[1:-1])
-    else:
-        if len(nodes) == 1:
-            return nodes
-
-        i = 0
-        while True:
-            i += 1
-            if i > 100:
-                t = 1
-            b, e = indexes_of_two_plus(nodes, lambda node: not isinstance(node, NodeOr))
-            if b is None:
-                return [NodeGroupOr(without_or(nodes))]
-            nodes = nodes[:b] + [NodeGroupAnd(nodes[b:e])] + nodes[e:]
-            if len(nodes) == 1:
-                return nodes
-
-def without_or(nodes):
-    return [node for node in nodes if not isinstance(node, NodeOr)]
-
-def expr_to_pred(expr):
-
-    level = 0
-    
-    while True:
-        i = pred_token_index(expr)
-        if i > -1:
-            if i > 0 and isinstance(expr[i-1], T) and expr[i-1].type == Tok.not_:
-                head = i-1
-            else:
-                head = i
-            expr = expr[:head] + [NodePred(expr[head: i+2])] + expr[i+2:]
-            t = 1
-            #print(expr)
-        else:
-            break
-
-    for i, tok in enumerate(expr):
-        if isinstance(tok, T):
-            expr[i] = {
-                Tok.op_par: NodeOpPar,
-                Tok.cl_par: NodeClPar,
-                Tok.and_: NodeAnd,
-                Tok.or_: NodeOr,
-                Tok.not_: NodeNot,
-            }[tok.type]()
-
-    expr = [e for e in expr if not isinstance(e, NodeAnd)]
-
-    tree = []
-
-    for i, tok in enumerate(expr):
-        
-        if isinstance(tok, NodeOpPar):
-            level += 1
-            tree.append((tok, level))
-        elif isinstance(tok, NodeClPar):
-            tree.append((tok, level))
-            level -= 1
-        else:
-            tree.append((tok, level))
-
-    if len(tree) == 0:
-        return tree, lambda name, path, is_dir: True
-    
-    while (True):
-        level = max_level(tree)
-        if level < 0:
-            children = strip_level(tree)
-            tree = to_children(children)
-            break
-        h, t = find_level(tree, level)
-
-        if h is None:
-            children = strip_level(tree)
-            tree = to_children(children)
-            break
-        else:
-            if h > 0 and isinstance(tree[h-1][0], NodeNot):
-                h = h-1
-            children = strip_level(tree[h:t])
-            tree = tree[:h] + [to_children(children)] + tree[t:]
-
-    if len(tree) != 1:
-        raise ValueError("Unexpected tree size {}".format(repr(tree)))
-    
-    tree = tree[0]
-
-    #print(tree)
-
-    cache = Cache()
-
-    return tree, lambda name, path, is_dir: tree.eval(name, path, is_dir, cache)
-
-def walk(top, topdown=True, onerror=None, followlinks=False, maxdepth=0):
-    return _walk(os.fspath(top), topdown, onerror, followlinks, maxdepth)
-
-def _walk(top, topdown, onerror, followlinks, maxdepth):
-    dirs = []
-    nondirs = []
-    walk_dirs = []
-    try:
-        scandir_it = os.scandir(top)
-    except OSError as error:
-        if onerror is not None:
-            onerror(error)
-        return
-
-    with scandir_it:
-        while True:
-            try:
-                try:
-                    entry = next(scandir_it)
-                except StopIteration:
-                    break
-            except OSError as error:
-                if onerror is not None:
-                    onerror(error)
-                return
-
-            try:
-                is_dir = entry.is_dir()
-            except OSError:
-                is_dir = False
-
-            if is_dir:
-                dirs.append(entry.name)
-            else:
-                nondirs.append(entry.name)
-
-            if not topdown and is_dir:
-                if followlinks:
-                    walk_into = True
-                else:
-                    try:
-                        is_symlink = entry.is_symlink()
-                    except OSError:
-                        is_symlink = False
-                    walk_into = not is_symlink
-
-                if walk_into:
-                    walk_dirs.append(entry.path)
-
-    maxdepth -= 1
-    if maxdepth == 0:
-        walk_dirs = []
-
-    if topdown:
-        yield top, dirs, nondirs
-        if maxdepth == 0:
-            return
-        islink, join = os.path.islink, os.path.join
-        for dirname in dirs:
-            new_path = join(top, dirname)
-            if followlinks or not islink(new_path):
-                yield from _walk(new_path, topdown, onerror, followlinks, maxdepth)
-    else:
-        for new_path in walk_dirs:
-            yield from _walk(new_path, topdown, onerror, followlinks, maxdepth)
-        yield top, dirs, nondirs
-
-def print_help():
-    print("""usage: pyfind [conditions] [-exec cmd args {} ;] [-delete]
-
-finds files and dirs that satisfy conditions (predicates)
-
-predicates:
-  -mtime DAYS          if DAYS is negative: modified within DAYS days, 
-                       if positive modified more than DAYS days ago
-  -ctime DAYS          same as -mtime, but when modified metadata not content
-  -mmin MINUTES        if MINUTES is negative: modified within MINUTES minutes, 
-                       if positive modified more than MINUTES minutes ago
-  -cmin MINUTES        same as -mmin, but when modified metadata not content
-  -newer PATH/TO/FILE  modified later than PATH/TO/FILE
-  -newermt DATETIME    modified later than DATETIME
-  -newerct DATETIME    same as -newermt but when modified metadata not content
-  -name PATTERN        filename matches PATTERN (wildcard)
-  -iname PATTERN       same as -name but case insensitive
-  -path PATTERN        file path matches PATTERN
-  -ipath PATTERN       same as -path but case insensitive
-  -cont PATTERN        file contains PATTERN
-  -icont PATTERN       same as -cont but case insensitive
-  -bcont PATTERN       same as -cont but PATTERN is binary expression
-  -type d              is directory
-  -type f              is file
-  -cdup N              print (or take action) parent path (strip N trailing components from path)
-  -first N             print (or take action) on first N found items
-  -last N              print (or take action) on last N found items
-
-predicates can be inverted using -not, can be grouped together in boolean expressions 
-using -or and -and and parenthesis
-
-examples:
-  pyfind -iname *.py -mmin -10
-  pyfind -iname *.cpp -or -iname *.h -not ( -iname moc_* -or -iname ui_* )
-  pyfind -iname *.h -exec pygrep -H class {} ;
-  pyfind -iname *.o -delete
-  pyfind -iname *.py | pyxargs pywc -l
-  pyfind D:\\dev -iname .git -type d -cdup 1
-""")
-
-def main():
-
-    args = sys.argv[1:]
-    if '-h' in args or '--help' in args:
-        print_help()
-        return
-
-    expr, paths, action, extraArgs = parse_args()
-    tree, pred = expr_to_pred(expr)
-    if len(paths) == 0:
-        paths.append(".")
-
-    collect = extraArgs.last is not None
-
-    collected = []
-
-    executed = 0
-
-    for path in paths:
-        for root, dirs, files in walk(path, maxdepth=extraArgs.maxdepth):
-            for name in dirs:
-                p = os.path.join(root, name)
-                if pred(name, p, True):
-                    action.exec(path, name, p, True)
-            for name in files:
-                p = os.path.join(root, name)
-                if pred(name, p, False):
-                    if collect:
-                        collected.append((path, name, p, False))
-                    else:
-                        action.exec(path, name, p, False)
-                        executed += 1
-                        if extraArgs.first == executed:
-                            return 
-    if collect:
-        for item in collected[-extraArgs.last:]:
-            action.exec(*item)
-
-def unquote(s):
-    if s[0] == '"' and s[-1] == '"':
-        return s[1:-1]
-    return s
-
-if __name__ == "__main__":
+import argparse
+import os
+import datetime
+import sys
+import re
+from .shared import eprint, glob_paths_dirs, has_magic, run, print_utf8
+import sys
+from dataclasses import dataclass
+from itertools import count
+import subprocess
+import shutil
+import fnmatch
+from . import parse_size
+from . import walk
+
+try:
+    import dateutil.parser
+except ImportError as e:
+    eprint("{}, -newermt -newerct is limited to yyyy-mm-dd format".format(str(e)))
+    def parse_date(value):
+        m = re.match('([0-9]{4})-([0-9]{2})-([0-9]{2})', value)
+        if m:
+            year = int(m.group(1))
+            month = int(m.group(2))
+            day = int(m.group(3))
+            return datetime.datetime(year, month, day)
+    class dateutil:
+        class parser:
+            parse = parse_date
+
+class Tok:
+    (
+        und,
+        op_par,
+        cl_par,
+        not_,
+        and_,
+        or_,
+        mmin,
+        iname,
+        name,
+        type,
+        f,
+        d,
+        newer,
+        newermt,
+        newerct,
+        arg,
+        path,
+        ipath,
+        mtime,
+        ctime,
+        size,
+        exec,
+        delete,
+        semicolon,
+        pathbind,
+        icont,
+        cont,
+        bcont,
+        maxdepth,
+        cdup,
+        first,
+        last,
+    ) = range(32)
+    
+m = {
+    "(": Tok.op_par,
+    ")": Tok.cl_par,
+    "!": Tok.not_,
+    "-not": Tok.not_,
+    "-a": Tok.and_,
+    "-and": Tok.and_,
+    "-o": Tok.or_,
+    "-or": Tok.or_,
+    "-mmin": Tok.mmin,
+    "-iname": Tok.iname,
+    "-name": Tok.name,
+    "-type": Tok.type,
+    "f": Tok.f,
+    "d": Tok.d,
+    "-newer": Tok.newer,
+    "-newermt": Tok.newermt,
+    "-newerct": Tok.newerct,
+    "-mtime": Tok.mtime,
+    "-ctime": Tok.ctime,
+    "-size": Tok.size,
+    "-exec": Tok.exec,
+    "-delete": Tok.delete,
+    ";": Tok.semicolon,
+    "{}": Tok.pathbind,
+    "-icont": Tok.icont,
+    "-cont": Tok.cont,
+    "-bcont": Tok.bcont,
+    "-path": Tok.path,
+    "-ipath": Tok.ipath,
+    "-maxdepth": Tok.maxdepth,
+    "-cdup": Tok.cdup,
+    "-first": Tok.first,
+    "-last": Tok.last,
+}
+
+inv_m = {v:k for k,v in m.items()}
+
+@dataclass
+class T:
+    type: int
+    cont: str
+
+tok_pred = [Tok.mmin, Tok.iname, Tok.name, Tok.type, Tok.newer, 
+    Tok.newerct, Tok.newermt, Tok.mtime, Tok.ctime,  Tok.size, Tok.cont, Tok.icont, Tok.bcont, Tok.path, Tok.ipath]
+
+def cdup_path(path, cdup):
+    for i in range(cdup):
+        path = os.path.dirname(path)
+    return path
+
+def split_list(vs, sep):
+    res = []
+    for v in vs:
+        if v == sep:
+            yield res
+            res = []
+        else:
+            res.append(v)
+    yield res
+    res = []
+
+class ActionExec:
+    def __init__(self, tokens, cdup):
+        self._tokens = tokens
+        self._cdup = cdup
+
+    def exec(self, root, name, path, is_dir):
+        path = cdup_path(path, self._cdup)
+        exprs = [t.cont.replace('{}', path) for t in self._tokens]
+        for expr in split_list(exprs, '&&'):
+            run(expr)
+
+class ActionDelete:
+
+    def __init__(self, cdup):
+        self._cdup = cdup
+
+    def exec(self, root, name, path, is_dir):
+        path = cdup_path(path, self._cdup)
+        if is_dir:
+            eprint("Removing directory {}".format(path))
+            shutil.rmtree(path)
+        else:
+            eprint("Removing file {}".format(path))
+            os.remove(path)
+
+
+class ActionPrint:
+
+    def __init__(self, cdup):
+        self._cdup = cdup
+
+    def exec(self, root, name, path, is_dir):
+        path = cdup_path(path, self._cdup)
+        if os.path.isabs(root):
+            print_utf8(path)
+        else:
+            print_utf8(os.path.relpath(path, os.getcwd()))
+
+def index_of_token(tokens, type):
+    for i, tok in enumerate(tokens):
+        if tok.type == type:
+            return i
+
+@dataclass
+class ExtraArgs:
+    maxdepth: int
+    first: int
+    last: int
+
+def pop_named_token_and_value(tokens, t):
+    ix = index_of_token(tokens, t)
+    if ix is None:
+        return None
+    if ix is not None:
+        token_key = tokens.pop(ix)
+        token_value = tokens.pop(ix)
+        return token_value.cont
+
+def to_int(v):
+    if v is None:
+        return v
+    return int(v)
+
+def to_int_or_zero(v):
+    if v is None:
+        return 0
+    return int(v)
+
+def parse_args(args = None):
+    if args is None:
+        args = sys.argv[1:]
+    tokens = [T(m[t], t) if t in m else T(Tok.und, t) for t in args]
+    for i, tok in enumerate(tokens):
+        if tok.type in tok_pred:
+            token = tokens[i+1]
+            tokens[i+1] = T(Tok.arg, token.cont)
+
+    """
+    maxdepth = 0
+    ix_maxdepth = index_of_token(tokens, Tok.maxdepth)
+    if ix_maxdepth is not None:
+        tokens.pop(ix_maxdepth)
+        token = tokens.pop(ix_maxdepth)
+        maxdepth = int(token.cont)
+    """
+
+    maxdepth = to_int_or_zero(pop_named_token_and_value(tokens, Tok.maxdepth))
+    
+    first = to_int(pop_named_token_and_value(tokens, Tok.first))
+
+    last = to_int(pop_named_token_and_value(tokens, Tok.last))
+    
+    """
+    cdup = 0
+    ix = index_of_token(tokens, Tok.cdup)
+    if ix is not None:
+        tokens.pop(ix)
+        token = tokens.pop(ix)
+        cdup = int(token.cont)
+    """
+    cdup = to_int_or_zero(pop_named_token_and_value(tokens, Tok.cdup))
+    
+    action = ActionPrint(cdup)
+
+    ix = index_of_token(tokens, Tok.delete)
+    if ix is not None:
+        tokens.pop(ix)
+        action = ActionDelete(cdup)
+    
+    ix_exec = index_of_token(tokens, Tok.exec)
+    ix_semicolon = index_of_token(tokens, Tok.semicolon)
+
+    if ix_exec is not None:
+        if ix_semicolon is None:
+            raise ValueError("Invalid exec expression: semicolon not found")
+        exec_tokens = tokens[ix_exec+1:ix_semicolon]
+        action = ActionExec(exec_tokens, cdup)
+        tokens = tokens[:ix_exec] + tokens[ix_semicolon+1:]
+
+    paths = []
+    pop_paths(tokens, paths, 0)
+    pop_paths(tokens, paths, -1)
+
+    """
+    i = len(tokens)-1
+    while i > -1 and tokens[i].type == Tok.und:
+        i -= 1
+    tokens, paths1 = tokens[:i+1], tokens[i+1:]
+    i = 0
+    while i < len(tokens) and tokens[i].type == Tok.und:
+        i += 1
+    paths2 = []
+    if i > 0:
+        paths2, tokens = tokens[:i], tokens[i:]
+    """
+
+    #expr = tokens
+    #paths = [e.cont for e in paths1 + paths2]
+
+    #print('expr, paths', expr, paths)
+
+    extraArgs = ExtraArgs(maxdepth=maxdepth, first=first, last=last)
+
+    return tokens, paths, action, extraArgs
+
+def pop_paths(tokens, paths, index):
+    while len(tokens) > 0 and tokens[index].type == Tok.und:
+        path = tokens[index].cont
+        if has_magic(path):
+            paths_ = glob_paths_dirs([path])
+            if len(paths_):
+                raise ValueError("no such path {}".format(path))
+            for p in paths_:
+                paths.append(p)
+        else:
+            if os.path.isdir(path):
+                paths.append(path)
+            else:
+                raise ValueError("no such path {}".format(path))
+        tokens.pop(index)
+
+class Cache:
+
+    # todo optimize cache for perfomance and memory (do dictionary lookups become costly for huge dictionaries?)
+
+    def __init__(self):
+        self._mtime = dict()
+        self._ctime = dict()
+        self._size = dict()
+        self._parse_size = dict()
+        self._now = datetime.datetime.now()
+        self._parse_date = dict()
+
+    def mtime(self, path):
+        if path not in self._mtime:
+            self._mtime[path] = None
+            try:
+                self._mtime[path] = datetime.datetime.fromtimestamp(os.path.getmtime(path))
+            except Exception as e:
+                eprint(e)
+        return self._mtime[path]
+
+    def ctime(self, path):
+        if path not in self._ctime:
+            self._ctime[path] = None
+            try:
+                self._ctime[path] = datetime.datetime.fromtimestamp(os.path.getctime(path))
+            except Exception as e:
+                eprint(e)
+        return self._ctime[path]
+
+    def size(self, path):
+        if path not in self._size:
+            self._size[path] = None
+            try:
+                self._size[path] = os.path.getsize(path)
+            except Exception as e:
+                eprint(e)
+        return self._size[path]
+
+    def parse_date(self, date):
+        if date not in self._parse_date:
+            self._parse_date[date] = None
+            try:
+                self._parse_date[date] = dateutil.parser.parse(date)
+            except Exception as e:
+                eprint("Invalid datetime format {}".format(date))
+        return self._parse_date[date]
+
+    def parse_size(self, arg):
+        if arg not in self._parse_size:
+            self._parse_size[arg] = None
+            parsed = parse_size(arg)
+            if parsed is None:
+                eprint("Invalid size format {}".format(arg))
+            else:
+                self._parse_size[arg] = parsed
+        return self._parse_size[arg]
+
+    def now(self):
+        return self._now
+
+def pred_mmin(name, path, is_dir, arg, cache):
+    mtime = cache.mtime(path)
+    if mtime is None:
+        return None
+    total_min = (cache.now() - mtime).total_seconds() / 60
+    arg = float(arg)
+    if arg < 0:
+        return total_min < abs(arg)
+    return total_min > arg
+
+def pred_iname(name, path, is_dir, arg, cache):
+    return fnmatch.fnmatch(name, arg)
+
+def pred_ipath(name, path, is_dir, arg, cache):
+    return fnmatch.fnmatch(path, arg)
+
+def pred_path(name, path, is_dir, arg, cache):
+    return fnmatch.fnmatchcase(path, arg)
+
+def pred_type(name, path, is_dir, arg, cache):
+    # todo validate type arg
+    return is_dir == (arg == 'd')
+
+def greater(d1, d2):
+    if None in [d1, d2]:
+        return None
+    return d1 > d2
+
+def pred_newer(name, path, is_dir, arg, cache):
+    #print([cache.mtime(path), cache.mtime(arg), cache.mtime(path) > cache.mtime(arg), arg])
+    return greater(cache.mtime(path), cache.mtime(arg))
+    
+def pred_newermt(name, path, is_dir, arg, cache):
+    return greater(cache.mtime(path), cache.parse_date(arg))
+
+def pred_newerct(name, path, is_dir, arg, cache):
+    return greater(cache.ctime(path), cache.parse_date(arg))
+
+def pred_xtime(arg, cache, xtime):
+    if xtime is None:
+        return None
+    total_days = (cache.now() - xtime).total_seconds() / 60 / 60 / 24
+    arg = float(arg)
+    if arg < 0:
+        return total_days < abs(arg)
+    return total_days > arg
+
+def pred_mtime(name, path, is_dir, arg, cache):
+    return pred_xtime(arg, cache, cache.mtime(path))
+
+def pred_ctime(name, path, is_dir, arg, cache):
+    return pred_xtime(arg, cache, cache.ctime(path))
+
+def pred_size(name, path, is_dir, arg, cache):
+    if is_dir:
+        return None
+    size_arg = cache.parse_size(arg)
+    size_path = cache.size(path)
+    if None in [size_arg, size_path]:
+        return None
+    if size_arg < 0:
+        return size_path < abs(size_arg)
+    return size_path > size_arg
+
+def pred_xcont(name, path, is_dir, arg, cache, flags, bin):
+    if is_dir:
+        return None
+    try:
+        with open(path, 'rb') as f:
+            data = f.read()
+        if bin:
+            arg = arg.encode("utf-8").decode('unicode_escape').encode("utf-8")
+        else:
+            arg = arg.encode("utf-8")
+        return re.search(arg, data, flags) is not None
+
+    except Exception as e:
+        eprint(e)
+    return None
+
+def pred_icont(name, path, is_dir, arg, cache):
+    return pred_xcont(name, path, is_dir, arg, cache, re.IGNORECASE, False)
+
+def pred_cont(name, path, is_dir, arg, cache):
+    return pred_xcont(name, path, is_dir, arg, cache, 0, False)
+
+def pred_bcont(name, path, is_dir, arg, cache):
+    return pred_xcont(name, path, is_dir, arg, cache, 0, True)
+
+def max_level(tree):
+    level = -1
+    for e in tree:
+        if isinstance(e, tuple):
+            level = max(level, e[1])
+    return level
+
+def index_op_par(tree, level):
+    for i, e in enumerate(tree):
+        if isinstance(e, tuple):
+            if isinstance(e[0], NodeOpPar) and e[1] == level:
+                return i
+
+def index_cl_par(tree, level, ix_op):
+    for i in range(ix_op + 1, len(tree)):
+        e = tree[i]
+        if isinstance(e, tuple):
+            if isinstance(e[0], NodeClPar) and e[1] == level:
+                return i
+
+def find_level(tree, level):
+    ix_op = index_op_par(tree, level)
+    if ix_op is None:
+        return None, None
+    ix_cl = index_cl_par(tree, level, ix_op)
+    if ix_cl is None:
+        # unbalanced parenthesis
+        return None, None
+    return ix_op, ix_cl + 1
+
+def group_tail(tokens):
+    i = 0
+    if len(tokens) < 1:
+        return -1
+    if tokens[i][0] == Tok.not_:
+        i += 1
+    if i > len(tokens):
+        return -1
+    if tokens[i][0] in tok_pred:
+        i += 2
+    if i > len(tokens):
+        return -1
+    if i == 0:
+        return -1
+    return i
+
+def normalize(nodes):
+    res = []
+    for node in nodes:
+        if isinstance(node, list) and len(node) == 1:
+            res.append(node[0])
+        else:
+            res.append(node)
+    return res
+
+class NodeGroupAnd:
+    def __init__(self, nodes):
+        self._children = normalize(nodes)
+
+    def eval(self, name, path, is_dir, cache):
+        for child in self._children:
+            res = child.eval(name, path, is_dir, cache)
+            if res in [None, False]:
+                return res
+        # all True
+        return True
+
+    def __repr__(self):
+        return "NodeGroupAnd({})".format(repr(self._children))
+
+class NodeGroupOr:
+    def __init__(self, nodes):
+        self._children = normalize(nodes)
+    
+    def eval(self, name, path, is_dir, cache):
+        for child in self._children:
+            res = child.eval(name, path, is_dir, cache)
+            if res in [None, True]:
+                return res
+        # all False
+        return False
+
+    def __repr__(self):
+        return "NodeGroupOr({})".format(repr(self._children))
+
+class NodeGroupNot:
+    def __init__(self, children):
+        if len(children) != 1:
+            raise ValueError("NodeGroupNot unexpected child count {}".format(repr(children)))
+        self._child = children[0]
+
+    def eval(self, name, path, is_dir, cache):
+        res = self._child.eval(name, path, is_dir, cache)
+        if res is None:
+            return None
+        return not res
+
+    def __repr__(self):
+        return "NodeGroupNot({})".format(repr(self._child))
+
+def strip_level(tokens):
+    return [e[0] if isinstance(e, tuple) else e for e in tokens]
+
+def pred_token_index(tokens):
+    for i, token in enumerate(tokens):
+        if not isinstance(token, T):
+            continue
+        if token.type in tok_pred:
+            return i
+    return -1
+
+# todo single instance (NodeOr in self._children)
+
+class NodeOpPar:
+    def __repr__(self) -> str:
+        return '('
+
+class NodeClPar:
+    def __repr__(self) -> str:
+        return ')'
+
+class NodeNot:
+    def __repr__(self) -> str:
+        return 'Not'
+
+class NodeAnd:
+    def __repr__(self) -> str:
+        return 'And'
+
+class NodeOr:
+    def __repr__(self) -> str:
+        return 'Or'
+
+class NodePred:
+    def __init__(self, tokens):
+        self._tokens = tokens
+        type_, arg = self._type_and_arg()
+
+    def __repr__(self) -> str:
+        type_, arg = self._type_and_arg()
+        type_str = inv_m[type_]
+        if len(self._tokens) == 2:
+            return 'NodePred({} {})'.format(type_str, arg)
+        else:
+            return 'NodePred(-not {} {})'.format(type_str, arg)
+
+    def _type_and_arg(self):
+        return self._tokens[-2].type, self._tokens[-1].cont
+
+    def eval(self, name, path, is_dir, cache):
+
+        exp = False if self._tokens[0].type == Tok.not_ else True
+        type_, arg = self._type_and_arg()
+        
+        if arg is None:
+            return None
+
+        res = {
+            Tok.type: pred_type,
+            Tok.mmin: pred_mmin,
+            Tok.iname: pred_iname,
+            Tok.newer: pred_newer,
+            Tok.newermt: pred_newermt,
+            Tok.newerct: pred_newerct,
+            Tok.ctime: pred_ctime,
+            Tok.mtime: pred_mtime,
+            Tok.size: pred_size,
+            Tok.cont: pred_cont,
+            Tok.icont: pred_icont,
+            Tok.bcont: pred_bcont,
+            Tok.path: pred_path,
+            Tok.ipath: pred_ipath,
+        }[type_](name, path, is_dir, arg, cache)
+
+        if res is None:
+            return None
+        return res == exp
+
+def index_of_two(items, pred):
+    res = []
+    for i, item in enumerate(items):
+        res.append(pred(item))
+        if res[-2:] == [True, True]:
+            return i-1
+
+def indexes_of_two_plus(items, pred):
+    b = index_of_two(items, pred)
+    if b is None:
+        return None, None
+    for i in range(b+2, len(items)):
+        if not pred(items[i]):
+            return b, i
+    return b, len(items)
+
+def to_children(nodes):
+    #print("to_children({})".format(repr(nodes)))
+    if isinstance(nodes[-1], NodeClPar):
+        if isinstance(nodes[0], NodeNot):
+            return [NodeGroupNot(to_children(nodes[2:-1]))]
+        else:
+            return to_children(nodes[1:-1])
+    else:
+        if len(nodes) == 1:
+            return nodes
+
+        i = 0
+        while True:
+            i += 1
+            if i > 100:
+                t = 1
+            b, e = indexes_of_two_plus(nodes, lambda node: not isinstance(node, NodeOr))
+            if b is None:
+                return [NodeGroupOr(without_or(nodes))]
+            nodes = nodes[:b] + [NodeGroupAnd(nodes[b:e])] + nodes[e:]
+            if len(nodes) == 1:
+                return nodes
+
+def without_or(nodes):
+    return [node for node in nodes if not isinstance(node, NodeOr)]
+
+def expr_to_pred(expr):
+
+    level = 0
+    
+    while True:
+        i = pred_token_index(expr)
+        if i > -1:
+            if i > 0 and isinstance(expr[i-1], T) and expr[i-1].type == Tok.not_:
+                head = i-1
+            else:
+                head = i
+            expr = expr[:head] + [NodePred(expr[head: i+2])] + expr[i+2:]
+            t = 1
+            #print(expr)
+        else:
+            break
+
+    for i, tok in enumerate(expr):
+        if isinstance(tok, T):
+            expr[i] = {
+                Tok.op_par: NodeOpPar,
+                Tok.cl_par: NodeClPar,
+                Tok.and_: NodeAnd,
+                Tok.or_: NodeOr,
+                Tok.not_: NodeNot,
+            }[tok.type]()
+
+    expr = [e for e in expr if not isinstance(e, NodeAnd)]
+
+    tree = []
+
+    for i, tok in enumerate(expr):
+        
+        if isinstance(tok, NodeOpPar):
+            level += 1
+            tree.append((tok, level))
+        elif isinstance(tok, NodeClPar):
+            tree.append((tok, level))
+            level -= 1
+        else:
+            tree.append((tok, level))
+
+    if len(tree) == 0:
+        return tree, lambda name, path, is_dir: True
+    
+    while (True):
+        level = max_level(tree)
+        if level < 0:
+            children = strip_level(tree)
+            tree = to_children(children)
+            break
+        h, t = find_level(tree, level)
+
+        if h is None:
+            children = strip_level(tree)
+            tree = to_children(children)
+            break
+        else:
+            if h > 0 and isinstance(tree[h-1][0], NodeNot):
+                h = h-1
+            children = strip_level(tree[h:t])
+            tree = tree[:h] + [to_children(children)] + tree[t:]
+
+    if len(tree) != 1:
+        raise ValueError("Unexpected tree size {}".format(repr(tree)))
+    
+    tree = tree[0]
+
+    #print(tree)
+
+    cache = Cache()
+
+    return tree, lambda name, path, is_dir: tree.eval(name, path, is_dir, cache)
+
+def print_help():
+    print("""usage: pyfind [conditions] [-exec cmd args {} ;] [-delete]
+
+finds files and dirs that satisfy conditions (predicates)
+
+predicates:
+  -mtime DAYS          if DAYS is negative: modified within DAYS days, 
+                       if positive modified more than DAYS days ago
+  -ctime DAYS          same as -mtime, but when modified metadata not content
+  -mmin MINUTES        if MINUTES is negative: modified within MINUTES minutes, 
+                       if positive modified more than MINUTES minutes ago
+  -cmin MINUTES        same as -mmin, but when modified metadata not content
+  -newer PATH/TO/FILE  modified later than PATH/TO/FILE
+  -newermt DATETIME    modified later than DATETIME
+  -newerct DATETIME    same as -newermt but when modified metadata not content
+  -name PATTERN        filename matches PATTERN (wildcard)
+  -iname PATTERN       same as -name but case insensitive
+  -path PATTERN        file path matches PATTERN
+  -ipath PATTERN       same as -path but case insensitive
+  -cont PATTERN        file contains PATTERN
+  -icont PATTERN       same as -cont but case insensitive
+  -bcont PATTERN       same as -cont but PATTERN is binary expression
+  -type d              is directory
+  -type f              is file
+  -cdup N              print (or take action) parent path (strip N trailing components from path)
+  -first N             print (or take action) on first N found items
+  -last N              print (or take action) on last N found items
+
+predicates can be inverted using -not, can be grouped together in boolean expressions 
+using -or and -and and parenthesis
+
+examples:
+  pyfind -iname *.py -mmin -10
+  pyfind -iname *.cpp -or -iname *.h -not ( -iname moc_* -or -iname ui_* )
+  pyfind -iname *.h -exec pygrep -H class {} ;
+  pyfind -iname *.o -delete
+  pyfind -iname *.py | pyxargs pywc -l
+  pyfind D:\\dev -iname .git -type d -cdup 1
+""")
+
+def main():
+
+    args = sys.argv[1:]
+    if '-h' in args or '--help' in args:
+        print_help()
+        return
+
+    expr, paths, action, extraArgs = parse_args()
+    tree, pred = expr_to_pred(expr)
+    if len(paths) == 0:
+        paths.append(".")
+
+    collect = extraArgs.last is not None
+
+    collected = []
+
+    executed = 0
+
+    for path in paths:
+        for root, dirs, files in walk(path, maxdepth=extraArgs.maxdepth):
+            for name in dirs:
+                p = os.path.join(root, name)
+                if pred(name, p, True):
+                    action.exec(path, name, p, True)
+            for name in files:
+                p = os.path.join(root, name)
+                if pred(name, p, False):
+                    if collect:
+                        collected.append((path, name, p, False))
+                    else:
+                        action.exec(path, name, p, False)
+                        executed += 1
+                        if extraArgs.first == executed:
+                            return 
+    if collect:
+        for item in collected[-extraArgs.last:]:
+            action.exec(*item)
+
+def unquote(s):
+    if s[0] == '"' and s[-1] == '"':
+        return s[1:-1]
+    return s
+
+if __name__ == "__main__":
     main()
```

## mugicli/pygrep.py

 * *Ordering differences only*

```diff
@@ -1,70 +1,70 @@
-from .shared import glob_paths_files, line_reader, print_lines, has_magic
-import sys
-import argparse
-import re
-import glob
-
-# todo binary files
-
-def main():
-    
-    parser = argparse.ArgumentParser(add_help=False, description='prints matching lines')
-    parser.add_argument('expr')
-    parser.add_argument('-i', '--ignore-case', action='store_true', help='ignore case')
-    parser.add_argument('-o', '--only-matching', action='store_true')
-    parser.add_argument('-v', '--invert-match', action='store_true', help='select non-matching lines')
-    parser.add_argument('-H', '--with-filename', action='store_true', help='print file name')
-    parser.add_argument('-h', '--without-filename', action='store_true', help='do not print file name')
-    parser.add_argument('-n', '--line-number', action='store_true', help='print line number')
-    parser.add_argument('--help', action='help')
-    parser.add_argument('path', nargs='*')
-
-    args = parser.parse_args()
-
-    paths = glob_paths_files(args.path)
-
-    if args.with_filename:
-        print_filename = True
-    elif args.without_filename:
-        print_filename = False
-    else:
-        many_inputs = len(args.path) > 1 or (len(args.path) > 0 and has_magic(args.path[0]))
-        print_filename = many_inputs
-
-    flags = re.IGNORECASE if args.ignore_case else 0
-    rx = re.compile(args.expr, flags)
-
-    def formatter(path, i, m, line):
-        cols = []
-        if print_filename:
-            cols.append(path)
-        if args.line_number:
-            cols.append(str(i+1))
-        if args.only_matching:
-            cols.append(m.group(0))
-        else:
-            cols.append(line)
-        return ':'.join(cols) + '\n'
-
-    def pred_match(line):
-        m = rx.search(line)
-        return m, m is not None
-
-    def pred_not_match(line):
-        m = rx.search(line)
-        return m, m is None
-
-    if args.invert_match:
-        pred = pred_not_match
-    else:
-        pred = pred_match
-
-    for i, line, path in line_reader(paths, len(args.path) == 0):
-        line = line.rstrip('\n')
-        m, matched = pred(line)
-        if matched:
-            print_lines([formatter(path, i, m, line)])
-
-if __name__ == "__main__":
-    main()
+from .shared import glob_paths_files, line_reader, print_lines, has_magic
+import sys
+import argparse
+import re
+import glob
+
+# todo binary files
+
+def main():
+    
+    parser = argparse.ArgumentParser(add_help=False, description='prints matching lines')
+    parser.add_argument('expr')
+    parser.add_argument('-i', '--ignore-case', action='store_true', help='ignore case')
+    parser.add_argument('-o', '--only-matching', action='store_true')
+    parser.add_argument('-v', '--invert-match', action='store_true', help='select non-matching lines')
+    parser.add_argument('-H', '--with-filename', action='store_true', help='print file name')
+    parser.add_argument('-h', '--without-filename', action='store_true', help='do not print file name')
+    parser.add_argument('-n', '--line-number', action='store_true', help='print line number')
+    parser.add_argument('--help', action='help')
+    parser.add_argument('path', nargs='*')
+
+    args = parser.parse_args()
+
+    paths = glob_paths_files(args.path)
+
+    if args.with_filename:
+        print_filename = True
+    elif args.without_filename:
+        print_filename = False
+    else:
+        many_inputs = len(args.path) > 1 or (len(args.path) > 0 and has_magic(args.path[0]))
+        print_filename = many_inputs
+
+    flags = re.IGNORECASE if args.ignore_case else 0
+    rx = re.compile(args.expr, flags)
+
+    def formatter(path, i, m, line):
+        cols = []
+        if print_filename:
+            cols.append(path)
+        if args.line_number:
+            cols.append(str(i+1))
+        if args.only_matching:
+            cols.append(m.group(0))
+        else:
+            cols.append(line)
+        return ':'.join(cols) + '\n'
+
+    def pred_match(line):
+        m = rx.search(line)
+        return m, m is not None
+
+    def pred_not_match(line):
+        m = rx.search(line)
+        return m, m is None
+
+    if args.invert_match:
+        pred = pred_not_match
+    else:
+        pred = pred_match
+
+    for i, line, path in line_reader(paths, len(args.path) == 0):
+        line = line.rstrip('\n')
+        m, matched = pred(line)
+        if matched:
+            print_lines([formatter(path, i, m, line)])
+
+if __name__ == "__main__":
+    main()
```

## mugicli/pyhead.py

 * *Ordering differences only*

```diff
@@ -1,7 +1,7 @@
-from . import head_tail_main, T_HEAD
-
-def main():
-    head_tail_main(T_HEAD)
-    
-if __name__ == "__main__":
+from . import head_tail_main, T_HEAD
+
+def main():
+    head_tail_main(T_HEAD)
+    
+if __name__ == "__main__":
     main()
```

## mugicli/pyls.py

```diff
@@ -1,33 +1,72 @@
 import argparse
 from .shared import glob_paths, print_utf8, has_magic
 import glob
 import os
+import sys
+from . import chunks
+import math
+from itertools import count
+
+def tabulate(lens, rows, columns):
+    data = []
+    sizes = []
+    for chunk in chunks(lens, rows):
+        size = max(chunk) + 1
+        sizes.append(size)
+        data.append(chunk)
+        if sum(sizes) > columns:
+            return False, []
+    if sum(sizes) > columns:
+        return False, []
+    return True, sizes
+    
+def print_group(items, isatty):
+    if isatty:
+        lens = [len(item) for item in items]
+        area = sum(lens)
+        columns = os.get_terminal_size().columns
+        rows = int(math.ceil(area / columns))
+        if max(lens) + 1 >= columns:
+            for line in items:
+                print_utf8(line)
+            return
+        while True:
+            ok, sizes = tabulate(lens, rows, columns)
+            if ok:
+                lines = ["" for _ in range(rows)]
+                for chunk, size in zip(chunks(items, rows), sizes):
+                    for j, item in enumerate(chunk):
+                        lines[j] = lines[j] + str.ljust(item, size)
+                for line in lines:
+                    print_utf8(line)
+                return
+            rows += 1
+    else:
+        for item in items:
+            print_utf8(item)
 
 def main():
     parser = argparse.ArgumentParser(description='lists directory')
     parser.add_argument('path', nargs='*')
     args = parser.parse_args()
 
     if len(args.path) == 0:
         paths = ['.']
     else:
         paths = args.path
 
+    isatty = sys.stdout.isatty()
+
     for path in paths:
         if has_magic(path):
-            for f in glob.glob(path):
-                print_utf8(f)
+            print_group(list(glob.glob(path)), isatty)
         else:
             if len(paths) > 1:
                 print_utf8(path + ":")
             for root, dirs, files in os.walk(path):
-                for d in dirs:
-                    print_utf8(d + "/")
-                for f in files:
-                    print_utf8(f)
+                print_group([d + "/" for d in dirs] + files, isatty)
                 while len(dirs) > 0:
                     dirs.pop()
     
-
 if __name__ == "__main__":
     main()
```

## mugicli/pymtime.py

 * *Ordering differences only*

```diff
@@ -1,27 +1,27 @@
-import os
-import argparse
-from .shared import glob_paths, print_utf8
-from . import read_stdin_text
-import datetime
-
-def print_mtime(path):
-    try:
-        print_utf8("{} {}".format(datetime.datetime.fromtimestamp(os.path.getmtime(path)), path))
-    except Exception as e:
-        pass
-
-def main():
-    parser = argparse.ArgumentParser(description='prints mtime of file')
-    parser.add_argument('path', nargs='*')
-    args = parser.parse_args()
-    
-    if len(args.path) == 0:
-        for line in read_stdin_text().split('\n'):
-            print_mtime(line.rstrip())
-    else:
-        paths = glob_paths(args.path)
-        for path in paths:
-            print_mtime(path)
-
-if __name__ == "__main__":
+import os
+import argparse
+from .shared import glob_paths, print_utf8
+from . import read_stdin_text
+import datetime
+
+def print_mtime(path):
+    try:
+        print_utf8("{} {}".format(datetime.datetime.fromtimestamp(os.path.getmtime(path)), path))
+    except Exception as e:
+        pass
+
+def main():
+    parser = argparse.ArgumentParser(description='prints mtime of file')
+    parser.add_argument('path', nargs='*')
+    args = parser.parse_args()
+    
+    if len(args.path) == 0:
+        for line in read_stdin_text().split('\n'):
+            print_mtime(line.rstrip())
+    else:
+        paths = glob_paths(args.path)
+        for path in paths:
+            print_mtime(path)
+
+if __name__ == "__main__":
     main()
```

## mugicli/pymtimestat.py

```diff
@@ -1,138 +1,117 @@
-import re
-import os
-import argparse
-
-from .shared import glob_paths, glob_paths_dirs
-import datetime
-import json
-import fnmatch
-from . import parse_time_arg
-
-def median(vs):
-    if len(vs) % 2:
-        return vs[len(vs) // 2]
-    else:
-        return (vs[len(vs) // 2 - 1] + vs[len(vs) // 2]) / 2
-
-def average(vs):
-    return sum(vs) / len(vs)
-
-
-def include_exclude(include, exclude, name):
-    if include is None and exclude is None:
-        return True
-    if include is None:
-        ok = True
-    else:
-        ok = False
-        for pat in include:
-            if fnmatch.fnmatch(name, pat):
-                ok = True
-    if not ok:
-        return False
-    if exclude is None:
-        return True
-    else:
-        for pat in exclude:
-            if fnmatch.fnmatch(name, pat):
-                return False
-    return True
-
-def main():
-    parser = argparse.ArgumentParser(description='prints mtime statistics')
-    parser.add_argument('path', nargs='*')
-
-    parser.add_argument('-r', '--recent', help='print recently changed files (max(mtime) - mtime <= N)')
-    parser.add_argument('-o', '--old', help='print long ago changed files (mtime - min(mtime) <= N)')
-    parser.add_argument('-a', '--average', help='print files changed within N seconds around average (abs(average(mtime) - mtime) <= N)')
-    parser.add_argument('-i', '--include', nargs='+', help='include files glob')
-    parser.add_argument('-e', '--exclude', nargs='+', help='include files glob')
-
-    args = parser.parse_args()
-
-    #print(args)
-
-    stat = []
-
-    if len(args.path) == 0:
-        paths = ["."]
-    else:
-        paths = glob_paths_dirs(args.path)
-    mtime = []
-    for path in paths:
-        for root, dirs, files in os.walk(path):
-            for f in files + dirs:
-                if not include_exclude(args.include, args.exclude, f):
-                    continue
-                p = os.path.join(root, f)
-                t = os.path.getmtime(p)
-                stat.append({"t":t, "p": p})
-                mtime.append(t)
-
-    if len(mtime) == 0:
-        print("No files")
-        exit(1)
-
-    mtime.sort()
-
-    names = ['min', 'max', 'average', 'median']
-
-    min_mtime = min(mtime)
-    max_mtime = max(mtime)
-    avg_mtime = average(mtime)
-
-    values = [min_mtime, max_mtime, avg_mtime, median(mtime)]
-
-    if args.recent or args.old or args.average:
-        
-        if args.recent:
-            arg_recent = parse_time_arg(args.recent)
-        else:
-            arg_recent = None
-
-        if args.old:
-            arg_old = parse_time_arg(args.old)
-        else:
-            arg_old = None
-        
-        if args.average:
-            arg_average = parse_time_arg(args.average)
-        else:
-            arg_average = None
-
-        #print("arg_recent {}, arg_old {}, arg_average {}".format(arg_recent, arg_old, arg_average))
-
-        for path in paths:
-            for root, dirs, files in os.walk(path):
-                for f in files + dirs:
-
-                    if not include_exclude(args.include, args.exclude, f):
-                        continue
-
-                    p = os.path.join(root, f)
-                    t = os.path.getmtime(p)
-
-                    do_print = False
-                    if arg_recent is not None:
-                        if max_mtime - t <= arg_recent:
-                            do_print = True
-                    if arg_old is not None:
-                        if t - min_mtime <= arg_old:
-                            do_print = True
-                    if arg_average is not None:
-                        if abs(t - avg_mtime) <= arg_average:
-                            do_print = True
-                    
-                    if do_print:
-                        if os.path.isabs(path):
-                            p_ = p
-                        else:
-                            p_ = os.path.relpath(p, os.getcwd())
-                        print("{} {}".format(datetime.datetime.fromtimestamp(t), p_))
-
-    print("{:8} files".format(len(mtime)))
-    for n,v in zip(names, values):
-        print("{:8} {}".format(n, datetime.datetime.fromtimestamp(v)))
-
-if __name__ == "__main__":
+import re
+import os
+import argparse
+
+from .shared import glob_paths, glob_paths_dirs
+import datetime
+import json
+import fnmatch
+from . import parse_time_arg, include_exclude
+
+def median(vs):
+    if len(vs) % 2:
+        return vs[len(vs) // 2]
+    else:
+        return (vs[len(vs) // 2 - 1] + vs[len(vs) // 2]) / 2
+
+def average(vs):
+    return sum(vs) / len(vs)
+
+def main():
+    parser = argparse.ArgumentParser(description='prints mtime statistics')
+    parser.add_argument('path', nargs='*')
+
+    parser.add_argument('-r', '--recent', help='print recently changed files (max(mtime) - mtime <= N)')
+    parser.add_argument('-o', '--old', help='print long ago changed files (mtime - min(mtime) <= N)')
+    parser.add_argument('-a', '--average', help='print files changed within N seconds around average (abs(average(mtime) - mtime) <= N)')
+    parser.add_argument('-i', '--include', nargs='+', help='include files glob')
+    parser.add_argument('-e', '--exclude', nargs='+', help='include files glob')
+
+    args = parser.parse_args()
+
+    #print(args)
+
+    stat = []
+
+    if len(args.path) == 0:
+        paths = ["."]
+    else:
+        paths = glob_paths_dirs(args.path)
+    mtime = []
+    for path in paths:
+        for root, dirs, files in os.walk(path):
+            for f in files + dirs:
+                if not include_exclude(args.include, args.exclude, f):
+                    continue
+                p = os.path.join(root, f)
+                t = os.path.getmtime(p)
+                stat.append({"t":t, "p": p})
+                mtime.append(t)
+
+    if len(mtime) == 0:
+        print("No files")
+        exit(1)
+
+    mtime.sort()
+
+    names = ['min', 'max', 'average', 'median']
+
+    min_mtime = min(mtime)
+    max_mtime = max(mtime)
+    avg_mtime = average(mtime)
+
+    values = [min_mtime, max_mtime, avg_mtime, median(mtime)]
+
+    if args.recent or args.old or args.average:
+        
+        if args.recent:
+            arg_recent = parse_time_arg(args.recent)
+        else:
+            arg_recent = None
+
+        if args.old:
+            arg_old = parse_time_arg(args.old)
+        else:
+            arg_old = None
+        
+        if args.average:
+            arg_average = parse_time_arg(args.average)
+        else:
+            arg_average = None
+
+        #print("arg_recent {}, arg_old {}, arg_average {}".format(arg_recent, arg_old, arg_average))
+
+        for path in paths:
+            for root, dirs, files in os.walk(path):
+                for f in files + dirs:
+
+                    if not include_exclude(args.include, args.exclude, f):
+                        continue
+
+                    p = os.path.join(root, f)
+                    t = os.path.getmtime(p)
+
+                    do_print = False
+                    if arg_recent is not None:
+                        if max_mtime - t <= arg_recent:
+                            do_print = True
+                    if arg_old is not None:
+                        if t - min_mtime <= arg_old:
+                            do_print = True
+                    if arg_average is not None:
+                        if abs(t - avg_mtime) <= arg_average:
+                            do_print = True
+                    
+                    if do_print:
+                        if os.path.isabs(path):
+                            p_ = p
+                        else:
+                            p_ = os.path.relpath(p, os.getcwd())
+                        print("{} {}".format(datetime.datetime.fromtimestamp(t), p_))
+
+    print("{:8} files".format(len(mtime)))
+    for n,v in zip(names, values):
+        print("{:8} {}".format(n, datetime.datetime.fromtimestamp(v)))
+
+if __name__ == "__main__":
     main()
```

## mugicli/pysed.py

 * *Ordering differences only*

```diff
@@ -1,61 +1,61 @@
-import sys
-from .shared import print_lines, glob_paths, read_lines
-import re
-import argparse
-
-# todo backreferences
-# todo -i
-
-def main():
-    pass
-
-def parse_exprs(exprs):
-    res = []
-    for arg in exprs:
-        if not arg.startswith("s"):
-            raise ValueError("Unexpected expression {}".format(arg))
-        sep = arg[1]
-        exp = arg.split(sep)
-        flags = ""
-        if len(exp) == 3: # allow unterminated regexp
-            s, subj, repl = exp
-        elif len(exp) == 4:
-            s, subj, repl, flags = exp
-        else:
-            raise ValueError("invalid expr {}".format(exp))
-        res.append((subj, repl, flags))
-    return res
-
-def main():
-    
-    one_expr = '-e' not in sys.argv[1:]
-
-    parser = argparse.ArgumentParser(description='replaces text')
-    if one_expr:
-        parser.add_argument('expr')
-    parser.add_argument('-e', action='append', help='expression')
-    parser.add_argument('path', nargs='*')
-    
-    args = parser.parse_args()
-
-    if one_expr:
-        exprs = parse_exprs([args.expr])
-    else:
-        exprs = parse_exprs(args.e)
-
-    #print(args); exit(0)
-
-    paths = glob_paths(args.path)
-    lines = read_lines(paths)
-
-    def replace(line):
-        for subj, repl, flags in exprs:
-            flags_ = re.IGNORECASE if 'i' in flags else 0
-            line = re.sub(subj, repl, line, flags=flags_)
-        return line
-
-    lines = map(replace, lines)
-    print_lines(lines)
-
-if __name__ == "__main__":
-    main()        
+import sys
+from .shared import print_lines, glob_paths, read_lines
+import re
+import argparse
+
+# todo backreferences
+# todo -i
+
+def main():
+    pass
+
+def parse_exprs(exprs):
+    res = []
+    for arg in exprs:
+        if not arg.startswith("s"):
+            raise ValueError("Unexpected expression {}".format(arg))
+        sep = arg[1]
+        exp = arg.split(sep)
+        flags = ""
+        if len(exp) == 3: # allow unterminated regexp
+            s, subj, repl = exp
+        elif len(exp) == 4:
+            s, subj, repl, flags = exp
+        else:
+            raise ValueError("invalid expr {}".format(exp))
+        res.append((subj, repl, flags))
+    return res
+
+def main():
+    
+    one_expr = '-e' not in sys.argv[1:]
+
+    parser = argparse.ArgumentParser(description='replaces text')
+    if one_expr:
+        parser.add_argument('expr')
+    parser.add_argument('-e', action='append', help='expression')
+    parser.add_argument('path', nargs='*')
+    
+    args = parser.parse_args()
+
+    if one_expr:
+        exprs = parse_exprs([args.expr])
+    else:
+        exprs = parse_exprs(args.e)
+
+    #print(args); exit(0)
+
+    paths = glob_paths(args.path)
+    lines = read_lines(paths)
+
+    def replace(line):
+        for subj, repl, flags in exprs:
+            flags_ = re.IGNORECASE if 'i' in flags else 0
+            line = re.sub(subj, repl, line, flags=flags_)
+        return line
+
+    lines = map(replace, lines)
+    print_lines(lines)
+
+if __name__ == "__main__":
+    main()
```

## mugicli/pyseq.py

 * *Ordering differences only*

```diff
@@ -1,61 +1,61 @@
-import sys
-import re
-from .shared import eprint
-
-def print_help():
-    print("""Print numbers from FIRST to LAST with INCREMENT
-seq LAST
-seq FIRST LAST
-seq FIRST INCREMENT LAST
-""")
-
-def map_number(args):
-    if all([re.match('^[0-9]+$', item) is not None for item in args]):
-        return map(int, args), -1
-    prec = max([len(item.split('.')[1]) if '.' in item else -1 for item in args])
-    return map(float, args), prec
-
-def print_number(n, prec):
-    if prec > -1:
-        print(("{:." + str(int(prec)) + "f}").format(n))
-    else:
-        print(n)
-
-def main():
-    args = sys.argv[1:]
-
-    if '-h' in args or '--help' in args:
-        print_help()
-        return
-
-    first = 1
-    inc = 1
-    last = 0
-    prec = -1
-    if len(args) == 3:
-        (first, inc, last), prec = map_number(args)
-    elif len(args) == 2:
-        (first, last), prec = map_number(args)
-    elif len(args) == 1:
-        (last, ), prec = map_number(args)
-    else:
-        print_help()
-        return
-    
-    i = first
-
-    if inc == 0:
-        eprint('inc must be non-zero')
-        exit(1)
-
-    elif inc > 0:
-        while i <= last:
-            print_number(i, prec)
-            i += inc
-    else:
-        while i >= last:
-            print_number(i, prec)
-            i += inc
-
-if __name__ == "__main__":
+import sys
+import re
+from .shared import eprint
+
+def print_help():
+    print("""Print numbers from FIRST to LAST with INCREMENT
+seq LAST
+seq FIRST LAST
+seq FIRST INCREMENT LAST
+""")
+
+def map_number(args):
+    if all([re.match('^[0-9]+$', item) is not None for item in args]):
+        return map(int, args), -1
+    prec = max([len(item.split('.')[1]) if '.' in item else -1 for item in args])
+    return map(float, args), prec
+
+def print_number(n, prec):
+    if prec > -1:
+        print(("{:." + str(int(prec)) + "f}").format(n))
+    else:
+        print(n)
+
+def main():
+    args = sys.argv[1:]
+
+    if '-h' in args or '--help' in args:
+        print_help()
+        return
+
+    first = 1
+    inc = 1
+    last = 0
+    prec = -1
+    if len(args) == 3:
+        (first, inc, last), prec = map_number(args)
+    elif len(args) == 2:
+        (first, last), prec = map_number(args)
+    elif len(args) == 1:
+        (last, ), prec = map_number(args)
+    else:
+        print_help()
+        return
+    
+    i = first
+
+    if inc == 0:
+        eprint('inc must be non-zero')
+        exit(1)
+
+    elif inc > 0:
+        while i <= last:
+            print_number(i, prec)
+            i += inc
+    else:
+        while i >= last:
+            print_number(i, prec)
+            i += inc
+
+if __name__ == "__main__":
     main()
```

## mugicli/pysort.py

 * *Ordering differences only*

```diff
@@ -1,67 +1,67 @@
-import argparse
-import sys
-from .shared import eprint, glob_paths, read_lines, print_lines
-import random
-import re
-from functools import cmp_to_key
-
-NUM_RX = r'([-+]?(\d+(\.\d*)?|\.\d+)([eE][-+]?\d+)?)'
-
-def num_value(s):
-    m = re.search(NUM_RX, s)
-    if m:
-        return float(m.group(1))
-
-def cmp_numeric(s1, s2):
-    if s1 == s2:
-        return 0
-    v1 = num_value(s1)
-    v2 = num_value(s2)
-
-    #print(v1, v2)
-
-    if v1 is None and v2 is None:
-        return -1 if s1 < s2 else 1
-    if v1 is None:
-        return -1
-    if v2 is None:
-        return 1
-    if v1 == v2:
-        return -1 if s1 < s2 else 1
-    return -1 if v1 < v2 else 1
-    
-def main():
-    parser = argparse.ArgumentParser(description='sorts lines')
-    parser.add_argument('--numeric-sort', '-n', action='store_true')
-    parser.add_argument('--reverse', '-r', action='store_true')
-    parser.add_argument('--random-sort', '-R', action='store_true')
-    parser.add_argument('--unique', '-u', action='store_true')
-    parser.add_argument('path', nargs="*")
-
-    args = parser.parse_args()
-    paths = glob_paths(args.path)
-    lines = read_lines(paths)
-    
-    if args.random_sort:
-        lines = [(line, random.random()) for line in lines]
-        lines.sort(key=lambda item: item[1])
-        lines = [e[0] for e in lines]
-    elif args.numeric_sort:
-        lines.sort(key=cmp_to_key(cmp_numeric))
-    else:
-        lines.sort()
-
-    if args.unique:
-        res = [lines[0]]
-        for line in lines:
-            if line != res[-1]:
-                res.append(line)
-        lines = res
-
-    if args.reverse:
-        print_lines(reversed(lines))
-    else:
-        print_lines(lines)
-
-if __name__ == "__main__":
+import argparse
+import sys
+from .shared import eprint, glob_paths, read_lines, print_lines
+import random
+import re
+from functools import cmp_to_key
+
+NUM_RX = r'([-+]?(\d+(\.\d*)?|\.\d+)([eE][-+]?\d+)?)'
+
+def num_value(s):
+    m = re.search(NUM_RX, s)
+    if m:
+        return float(m.group(1))
+
+def cmp_numeric(s1, s2):
+    if s1 == s2:
+        return 0
+    v1 = num_value(s1)
+    v2 = num_value(s2)
+
+    #print(v1, v2)
+
+    if v1 is None and v2 is None:
+        return -1 if s1 < s2 else 1
+    if v1 is None:
+        return -1
+    if v2 is None:
+        return 1
+    if v1 == v2:
+        return -1 if s1 < s2 else 1
+    return -1 if v1 < v2 else 1
+    
+def main():
+    parser = argparse.ArgumentParser(description='sorts lines')
+    parser.add_argument('--numeric-sort', '-n', action='store_true')
+    parser.add_argument('--reverse', '-r', action='store_true')
+    parser.add_argument('--random-sort', '-R', action='store_true')
+    parser.add_argument('--unique', '-u', action='store_true')
+    parser.add_argument('path', nargs="*")
+
+    args = parser.parse_args()
+    paths = glob_paths(args.path)
+    lines = read_lines(paths)
+    
+    if args.random_sort:
+        lines = [(line, random.random()) for line in lines]
+        lines.sort(key=lambda item: item[1])
+        lines = [e[0] for e in lines]
+    elif args.numeric_sort:
+        lines.sort(key=cmp_to_key(cmp_numeric))
+    else:
+        lines.sort()
+
+    if args.unique:
+        res = [lines[0]]
+        for line in lines:
+            if line != res[-1]:
+                res.append(line)
+        lines = res
+
+    if args.reverse:
+        print_lines(reversed(lines))
+    else:
+        print_lines(lines)
+
+if __name__ == "__main__":
     main()
```

## mugicli/pytail.py

 * *Ordering differences only*

```diff
@@ -1,7 +1,7 @@
-from . import head_tail_main, T_TAIL
-
-def main():
-    head_tail_main(T_TAIL)
-    
-if __name__ == "__main__":
+from . import head_tail_main, T_TAIL
+
+def main():
+    head_tail_main(T_TAIL)
+    
+if __name__ == "__main__":
     main()
```

## mugicli/pytime.py

 * *Ordering differences only*

```diff
@@ -1,30 +1,30 @@
-import subprocess
-import time
-import sys
-from .shared import eprint, run
-import textwrap
-
-def print_help():
-    print(textwrap.dedent("""\
-    usage: pytime program [...args]
-
-    measures execution time of application
-    """))
-
-def main():
-    t1 = time.time()
-    
-    args = sys.argv[1:]
-
-    if args[0] in ['-h', '--help']:
-        print_help()
-        return
-
-    #print(args)
-    run(args)
-    
-    t2 = time.time()
-    eprint("{:.3f}s".format(t2 - t1))
-
-if __name__ == "__main__":
+import subprocess
+import time
+import sys
+from .shared import eprint, run
+import textwrap
+
+def print_help():
+    print(textwrap.dedent("""\
+    usage: pytime program [...args]
+
+    measures execution time of application
+    """))
+
+def main():
+    t1 = time.time()
+    
+    args = sys.argv[1:]
+
+    if args[0] in ['-h', '--help']:
+        print_help()
+        return
+
+    #print(args)
+    run(args)
+    
+    t2 = time.time()
+    eprint("{:.3f}s".format(t2 - t1))
+
+if __name__ == "__main__":
     main()
```

## mugicli/pytmp.py

 * *Ordering differences only*

```diff
@@ -1,66 +1,66 @@
-import argparse
-import sys
-import re
-import json
-import tempfile
-import os
-import shutil
-from .shared import print_bytes
-import textwrap
-
-# todo clean
-# todo env PYTMP_DIR
-
-def pytmp_path():
-    return os.path.join(os.path.expanduser('~'), '.pytmp')
-
-def write_pathmap(pathmap):
-    with open(pytmp_path(), 'w', encoding='utf-8') as f:
-        json.dump(pathmap, f, ensure_ascii=False, indent=1)
-
-def read_pathmap():
-    try:
-        with open(pytmp_path(), encoding='utf-8') as f:
-            return json.load(f)
-    except Exception as e:
-        return dict()
-
-def main():
-
-    epilog = textwrap.dedent("""\
-    examples:
-        pyecho -e 3\\n1\\n2 | pytmp -o foo
-        pytmp -i foo | pysort
-        pytmp -p foo | pyxargs pycat 
-    """)
-
-    parser = argparse.ArgumentParser(description='temporary file helper', epilog=epilog, formatter_class=argparse.RawTextHelpFormatter)
-    parser.add_argument('-p', '--print', nargs='+', help='print filenames')
-    parser.add_argument('-i', '--input', nargs='+', help='input data from file')
-    parser.add_argument('-o', '--output', help='output data to file')
-    parser.add_argument('--suffix', default='.tmp')
-
-    args = parser.parse_args()
-
-    pathmap = read_pathmap()
-
-    if args.output:
-        fd, path = tempfile.mkstemp(prefix=args.output + '-', suffix=args.suffix)
-        with open(path, 'wb') as f:
-            f.write(sys.stdin.buffer.read())
-        os.close(fd)
-        pathmap[args.output] = path
-        write_pathmap(pathmap)
-    elif args.input is not None:
-        for n in args.input:
-            path = pathmap[n]
-            with open(path, 'rb') as f:
-                print_bytes(f.read())
-
-    if args.print is not None:
-        for n in args.print:
-            path = pathmap[n]
-            print(path)
-
-if __name__ == "__main__":
+import argparse
+import sys
+import re
+import json
+import tempfile
+import os
+import shutil
+from .shared import print_bytes
+import textwrap
+
+# todo clean
+# todo env PYTMP_DIR
+
+def pytmp_path():
+    return os.path.join(os.path.expanduser('~'), '.pytmp')
+
+def write_pathmap(pathmap):
+    with open(pytmp_path(), 'w', encoding='utf-8') as f:
+        json.dump(pathmap, f, ensure_ascii=False, indent=1)
+
+def read_pathmap():
+    try:
+        with open(pytmp_path(), encoding='utf-8') as f:
+            return json.load(f)
+    except Exception as e:
+        return dict()
+
+def main():
+
+    epilog = textwrap.dedent("""\
+    examples:
+        pyecho -e 3\\n1\\n2 | pytmp -o foo
+        pytmp -i foo | pysort
+        pytmp -p foo | pyxargs pycat 
+    """)
+
+    parser = argparse.ArgumentParser(description='temporary file helper', epilog=epilog, formatter_class=argparse.RawTextHelpFormatter)
+    parser.add_argument('-p', '--print', nargs='+', help='print filenames')
+    parser.add_argument('-i', '--input', nargs='+', help='input data from file')
+    parser.add_argument('-o', '--output', help='output data to file')
+    parser.add_argument('--suffix', default='.tmp')
+
+    args = parser.parse_args()
+
+    pathmap = read_pathmap()
+
+    if args.output:
+        fd, path = tempfile.mkstemp(prefix=args.output + '-', suffix=args.suffix)
+        with open(path, 'wb') as f:
+            f.write(sys.stdin.buffer.read())
+        os.close(fd)
+        pathmap[args.output] = path
+        write_pathmap(pathmap)
+    elif args.input is not None:
+        for n in args.input:
+            path = pathmap[n]
+            with open(path, 'rb') as f:
+                print_bytes(f.read())
+
+    if args.print is not None:
+        for n in args.print:
+            path = pathmap[n]
+            print(path)
+
+if __name__ == "__main__":
     main()
```

## mugicli/pytouch.py

 * *Ordering differences only*

```diff
@@ -1,48 +1,48 @@
-import argparse
-from datetime import date
-import datetime
-import dateutil.parser
-import glob
-import os
-from .shared import eprint, has_magic
-from . import parse_time_arg
-
-def set_mtime(filename, mtime):
-    stat = os.stat(filename)
-    atime = stat.st_atime
-    os.utime(filename, times=(atime, mtime.timestamp()))
-
-def main():
-    parser = argparse.ArgumentParser(description='changes mtime to current time or specified time')
-    parser.add_argument('path', nargs='+', help='target path')
-    parser.add_argument('-d', help='datetime or relative time in format [+-]NUM[d|h|m|s] format')
-
-    args = parser.parse_args()
-
-    if args.d:
-        d = parse_time_arg(args.d)
-        if d is not None:
-            now = datetime.datetime.now()
-            mtime = now + datetime.timedelta(seconds=d)
-        else:
-            mtime = dateutil.parser.parse(args.d)
-    else:
-        mtime = datetime.datetime.now()
-
-    for path in args.path:
-        if has_magic(path):
-            paths = glob.glob(path)
-        else:
-            paths = [path]
-        for path_ in paths:
-            try:
-                if os.path.exists(path_):
-                    set_mtime(path_, mtime)
-                else:
-                    with open(path_, 'w') as f:
-                        pass
-            except Exception as e:
-                eprint(e)
-
-if __name__ == "__main__":
+import argparse
+from datetime import date
+import datetime
+import dateutil.parser
+import glob
+import os
+from .shared import eprint, has_magic
+from . import parse_time_arg
+
+def set_mtime(filename, mtime):
+    stat = os.stat(filename)
+    atime = stat.st_atime
+    os.utime(filename, times=(atime, mtime.timestamp()))
+
+def main():
+    parser = argparse.ArgumentParser(description='changes mtime to current time or specified time')
+    parser.add_argument('path', nargs='+', help='target path')
+    parser.add_argument('-d', help='datetime or relative time in format [+-]NUM[d|h|m|s] format')
+
+    args = parser.parse_args()
+
+    if args.d:
+        d = parse_time_arg(args.d)
+        if d is not None:
+            now = datetime.datetime.now()
+            mtime = now + datetime.timedelta(seconds=d)
+        else:
+            mtime = dateutil.parser.parse(args.d)
+    else:
+        mtime = datetime.datetime.now()
+
+    for path in args.path:
+        if has_magic(path):
+            paths = glob.glob(path)
+        else:
+            paths = [path]
+        for path_ in paths:
+            try:
+                if os.path.exists(path_):
+                    set_mtime(path_, mtime)
+                else:
+                    with open(path_, 'w') as f:
+                        pass
+            except Exception as e:
+                eprint(e)
+
+if __name__ == "__main__":
     main()
```

## mugicli/pyuniq.py

 * *Ordering differences only*

```diff
@@ -1,42 +1,42 @@
-import argparse
-from random import uniform
-from collections import defaultdict
-from .shared import glob_paths_files, read_lines, print_lines
-
-def main():
-    parser = argparse.ArgumentParser(description='prints unique or nonunique lines from sorted array of lines')
-    parser.add_argument('--count', '-c', action='store_true')
-    parser.add_argument('--repeated','-d',action='store_true')
-    parser.add_argument('--unique','-u',action='store_true')
-    parser.add_argument('path', nargs="*")
-
-    args = parser.parse_args()
-    paths = glob_paths_files(args.path)
-    lines = read_lines(paths)
-
-    stat = defaultdict(lambda: 0)
-    for line in lines:
-        stat[line] += 1
-    
-    if args.repeated:
-        lines_ = [line for line in lines if stat[line] > 1]
-    elif args.unique:
-        lines_ = [line for line in lines if stat[line] == 1]
-    else:
-        lines_ = lines
-
-    res = [lines_[0]]
-    for line in lines_:
-        if res[-1] != line:
-            res.append(line)
-
-    if args.count:
-        formatter = lambda line: "{:5d} {}".format(stat[line], line)
-    else:
-        formatter = lambda line: line
-
-    lines_ = [formatter(line) for line in res]
-    print_lines(lines_)
-
-if __name__ == "__main__":
+import argparse
+from random import uniform
+from collections import defaultdict
+from .shared import glob_paths_files, read_lines, print_lines
+
+def main():
+    parser = argparse.ArgumentParser(description='prints unique or nonunique lines from sorted array of lines')
+    parser.add_argument('--count', '-c', action='store_true')
+    parser.add_argument('--repeated','-d',action='store_true')
+    parser.add_argument('--unique','-u',action='store_true')
+    parser.add_argument('path', nargs="*")
+
+    args = parser.parse_args()
+    paths = glob_paths_files(args.path)
+    lines = read_lines(paths)
+
+    stat = defaultdict(lambda: 0)
+    for line in lines:
+        stat[line] += 1
+    
+    if args.repeated:
+        lines_ = [line for line in lines if stat[line] > 1]
+    elif args.unique:
+        lines_ = [line for line in lines if stat[line] == 1]
+    else:
+        lines_ = lines
+
+    res = [lines_[0]]
+    for line in lines_:
+        if res[-1] != line:
+            res.append(line)
+
+    if args.count:
+        formatter = lambda line: "{:5d} {}".format(stat[line], line)
+    else:
+        formatter = lambda line: line
+
+    lines_ = [formatter(line) for line in res]
+    print_lines(lines_)
+
+if __name__ == "__main__":
     main()
```

## mugicli/pywc.py

 * *Ordering differences only*

```diff
@@ -1,76 +1,76 @@
-import enum
-import fileinput
-import argparse
-import sys
-import re
-import math
-import glob
-from types import prepare_class
-from .shared import glob_paths, read_bytes
-
-def main():
-
-    description='calculates number or lines words, chars and bytes in files'
-    epilog='examples:\n  wc -l text.txt'
-
-    parser = argparse.ArgumentParser(epilog=epilog, description=description, formatter_class=argparse.RawTextHelpFormatter)
-
-    parser.add_argument('-l', action='store_true', help='print the newline counts')
-    parser.add_argument('-w', action='store_true', help='print the word counts')
-    parser.add_argument('-m', action='store_true', help='print the character counts')
-    parser.add_argument('-c', action='store_true', help='print the byte counts')
-    parser.add_argument('path', nargs="*")
-
-    args = parser.parse_args()
-
-    def count_lines(data, path, res):
-        text = ''
-        try:
-            text = data.decode('utf-8')
-        except Exception as e:
-            print(e)
-        c = len(data)
-        m = len(text)
-        w = len(re.split('\\s+',text.strip()))
-        l = len(text.split('\n'))
-        res.append((l, w, m, c, path))
-
-    res = []
-    stdin_mode = len(args.path) == 0
-
-    paths = glob_paths(args.path)
-
-    if stdin_mode:
-        data = sys.stdin.buffer.read()
-        count_lines(data, '', res)
-    else:
-        for path in paths:
-            count_lines(read_bytes(path), path, res)
-
-    lt = sum([e[0] for e in res])
-    wt = sum([e[1] for e in res])
-    mt = sum([e[2] for e in res])
-    ct = sum([e[3] for e in res])
-
-    lw = len(str(lt))
-    ww = len(str(wt))
-    mw = len(str(mt))
-    cw = len(str(ct))
-
-    fmt = " ".join(['{:' + str(lw) + 'd}' if args.l else ''] +
-        ['{:' + str(ww) + 'd}' if args.w else ''] +
-        ['{:' + str(mw) + 'd}' if args.m else ''] +
-        ['{:' + str(cw) + 'd}' if args.c else ''] +
-        ['{}'])
-
-    #print(fmt)
-
-    if len(res) > 1:
-        res.append((lt,wt,mt,ct,'total'))
-
-    for item in res:
-        cols = [v for v, en in zip(item, [args.l, args.w, args.m, args.c, True]) if en]
-        print(fmt.format(*cols))
-
-if __name__ == "__main__":
+import enum
+import fileinput
+import argparse
+import sys
+import re
+import math
+import glob
+from types import prepare_class
+from .shared import glob_paths, read_bytes
+
+def main():
+
+    description='calculates number or lines words, chars and bytes in files'
+    epilog='examples:\n  wc -l text.txt'
+
+    parser = argparse.ArgumentParser(epilog=epilog, description=description, formatter_class=argparse.RawTextHelpFormatter)
+
+    parser.add_argument('-l', action='store_true', help='print the newline counts')
+    parser.add_argument('-w', action='store_true', help='print the word counts')
+    parser.add_argument('-m', action='store_true', help='print the character counts')
+    parser.add_argument('-c', action='store_true', help='print the byte counts')
+    parser.add_argument('path', nargs="*")
+
+    args = parser.parse_args()
+
+    def count_lines(data, path, res):
+        text = ''
+        try:
+            text = data.decode('utf-8')
+        except Exception as e:
+            print(e)
+        c = len(data)
+        m = len(text)
+        w = len(re.split('\\s+',text.strip()))
+        l = len(text.split('\n'))
+        res.append((l, w, m, c, path))
+
+    res = []
+    stdin_mode = len(args.path) == 0
+
+    paths = glob_paths(args.path)
+
+    if stdin_mode:
+        data = sys.stdin.buffer.read()
+        count_lines(data, '', res)
+    else:
+        for path in paths:
+            count_lines(read_bytes(path), path, res)
+
+    lt = sum([e[0] for e in res])
+    wt = sum([e[1] for e in res])
+    mt = sum([e[2] for e in res])
+    ct = sum([e[3] for e in res])
+
+    lw = len(str(lt))
+    ww = len(str(wt))
+    mw = len(str(mt))
+    cw = len(str(ct))
+
+    fmt = " ".join(['{:' + str(lw) + 'd}' if args.l else ''] +
+        ['{:' + str(ww) + 'd}' if args.w else ''] +
+        ['{:' + str(mw) + 'd}' if args.m else ''] +
+        ['{:' + str(cw) + 'd}' if args.c else ''] +
+        ['{}'])
+
+    #print(fmt)
+
+    if len(res) > 1:
+        res.append((lt,wt,mt,ct,'total'))
+
+    for item in res:
+        cols = [v for v, en in zip(item, [args.l, args.w, args.m, args.c, True]) if en]
+        print(fmt.format(*cols))
+
+if __name__ == "__main__":
     main()
```

## mugicli/pyxargs.py

 * *Ordering differences only*

```diff
@@ -1,52 +1,52 @@
-import sys
-import re
-import subprocess
-from .shared import eprint, run, parse_args
-from . import read_stdin_text, chunks
-import textwrap
-
-def read_stdin_args():
-    text = read_stdin_text()
-    args = [line for line in [line.strip() for line in text.split('\n')] if line != '']
-    return args
-
-def is_int(s):
-    try:
-        int(s)
-        return True
-    except Exception as e:
-        pass
-    return False
-
-def print_help():
-    print(textwrap.dedent("""\
-    usage: pyxargs [-L NUM] [-I VAR] command [args...]
-
-    reads arguments from stdin and applies them to command
-
-    optional arguments:
-      -h --help  show this message and exit
-      -L NUM     split arguments to chunks of N args
-      -I VAR     replace VAR with arg (assumes -L 1)
-
-    """))
-
-def main():
-    opts, args1 = parse_args(['h'],['help'],['L','I'],[], sys.argv[1:])
-    if opts['h'] or opts['help']:
-        print_help()
-        return
-    args2 = read_stdin_args()
-
-    if opts['L'] is not None:
-        for args in chunks(args2, int(opts['n'])):
-            run(args1 + args)
-    elif opts['I'] is not None:
-        for arg in args2:
-            cmd = [a.replace(opts['I'], arg) for a in args1]
-            run(cmd)
-    else:
-        run(args1 + args2)
-
-if __name__ == "__main__":
+import sys
+import re
+import subprocess
+from .shared import eprint, run, parse_args
+from . import read_stdin_text, chunks
+import textwrap
+
+def read_stdin_args():
+    text = read_stdin_text()
+    args = [line for line in [line.strip() for line in text.split('\n')] if line != '']
+    return args
+
+def is_int(s):
+    try:
+        int(s)
+        return True
+    except Exception as e:
+        pass
+    return False
+
+def print_help():
+    print(textwrap.dedent("""\
+    usage: pyxargs [-L NUM] [-I VAR] command [args...]
+
+    reads arguments from stdin and applies them to command
+
+    optional arguments:
+      -h --help  show this message and exit
+      -L NUM     split arguments to chunks of N args
+      -I VAR     replace VAR with arg (assumes -L 1)
+
+    """))
+
+def main():
+    opts, args1 = parse_args(['h'],['help'],['L','I'],[], sys.argv[1:])
+    if opts['h'] or opts['help']:
+        print_help()
+        return
+    args2 = read_stdin_args()
+
+    if opts['L'] is not None:
+        for args in chunks(args2, int(opts['n'])):
+            run(args1 + args)
+    elif opts['I'] is not None:
+        for arg in args2:
+            cmd = [a.replace(opts['I'], arg) for a in args1]
+            run(cmd)
+    else:
+        run(args1 + args2)
+
+if __name__ == "__main__":
     main()
```

## mugicli/pyzip.py

```diff
@@ -1,98 +1,102 @@
-from ast import parse
-import os
-import argparse
-import zipfile
-from zipfile import ZIP_STORED, ZIP_DEFLATED, ZIP_BZIP2, ZIP_LZMA
-from .shared import print_utf8, glob_paths
-from . import read_file_text
-import sys
-
-def main():
-
-    COMPRESSION_METHODS = {
-        'deflate': ZIP_DEFLATED,
-        'd': ZIP_DEFLATED,
-        'lzma': ZIP_LZMA,
-        'l': ZIP_LZMA,
-        'bzip2': ZIP_BZIP2,
-        'b': ZIP_BZIP2,
-        'store': ZIP_STORED,
-        's': ZIP_STORED
-    }
-
-    parser = argparse.ArgumentParser(description='appends, extracts and list contents of zip archive')
-    parser.add_argument('command', choices=['a','x','l'], help='add extract list')
-    parser.add_argument('-o', '--output', help='output directory')
-    parser.add_argument('-m', choices=list(COMPRESSION_METHODS.keys()), help='compression method')
-    parser.add_argument('-l', type=int, help="compression level 0..9 for deflate (0 - best speed, 9 - best compression) 1..9 for bzip2, has no effect if method is store or lzma")
-    parser.add_argument('--base', help='base directory')
-    parser.add_argument('--dir', help='prepend directory to path')
-    parser.add_argument('--list', help='path to list of files')
-    parser.add_argument('-s', '--silent', action='store_true')
-    parser.add_argument('-v', '--verbose', action='store_true')
-    parser.add_argument('zip')
-    parser.add_argument('sources', nargs='*') # todo wildcards
-    args = parser.parse_args()
-
-    dst_base = args.output if args.output is not None else os.getcwd()
-
-    compresslevel = args.l
-
-    if args.verbose and args.silent:
-        print_utf8('choose one: verbose or silent')
-        exit(1)
-
-    verbose = args.verbose or not args.silent
-
-    if args.command == 'a':
-
-        if args.list is None:
-            paths = glob_paths(args.sources)
-        else:
-            lines = read_file_text(args.list).split('\n')
-            paths = [line.rstrip() for line in lines if line.rstrip() != '']
-
-        compression = COMPRESSION_METHODS[args.m] if args.m is not None else ZIP_DEFLATED
-
-        def add_file(zf, p, base):
-            relpath = os.path.relpath(p, base)
-            if args.dir:
-                relpath = os.path.join(args.dir, relpath)
-            if verbose:
-                print_utf8(p)
-            zf.write(p, relpath)
-
-        with zipfile.ZipFile(args.zip, 'a', compression=compression, compresslevel=compresslevel) as zf:
-            for path in paths:
-                if args.base is None:
-                    if os.path.isabs(path):
-                        base = os.path.dirname(path)
-                    else:
-                        base = os.getcwd()
-                else:
-                    base = args.base
-
-                if os.path.isfile(path):
-                    add_file(zf, path, base)
-                else:
-                    for root, dirs, files in os.walk(path):
-                        for f in files:
-                            p = os.path.join(root, f)
-                            add_file(zf, p, base)
-                        
-    if args.command == 'x':
-        with zipfile.ZipFile(args.zip) as zf:
-            for name in zf.namelist():
-                name_ = name.replace('/','\\')
-                if len(args.sources) == 0 or name in args.sources or name_ in args.sources:
-                    #dest = os.path.join(dst_base, name)
-                    print("extract {} to {}".format(name, dst_base))
-                    zf.extract(name, dst_base)
-                    
-    if args.command == 'l':
-        with zipfile.ZipFile(args.zip) as zf:
-            for name in zf.namelist():
-                print_utf8(name)
-
-if __name__ == "__main__":
+from ast import parse
+import os
+import argparse
+import zipfile
+from zipfile import ZIP_STORED, ZIP_DEFLATED, ZIP_BZIP2, ZIP_LZMA
+from .shared import print_utf8, glob_paths
+from . import read_file_text
+import sys
+
+# todo read from stdin
+# todo ouput to stdout
+
+def main():
+
+    COMPRESSION_METHODS = {
+        'deflate': ZIP_DEFLATED,
+        'd': ZIP_DEFLATED,
+        'lzma': ZIP_LZMA,
+        'l': ZIP_LZMA,
+        'bzip2': ZIP_BZIP2,
+        'b': ZIP_BZIP2,
+        'store': ZIP_STORED,
+        's': ZIP_STORED
+    }
+
+    parser = argparse.ArgumentParser(description='appends, extracts and list contents of zip archive')
+    parser.add_argument('command', choices=['a','x','l'], help='add extract list') # todo u - update
+    parser.add_argument('-o', '--output', help='output directory')
+    parser.add_argument('-m', choices=list(COMPRESSION_METHODS.keys()), help='compression method')
+    parser.add_argument('-l', type=int, help="compression level 0..9 for deflate (0 - best speed, 9 - best compression) 1..9 for bzip2, has no effect if method is store or lzma")
+    parser.add_argument('--base', help='base directory')
+    parser.add_argument('--dir', help='prepend directory to path')
+    parser.add_argument('--list', help='path to list of files')
+    parser.add_argument('-s', '--silent', action='store_true')
+    parser.add_argument('-v', '--verbose', action='store_true')
+    parser.add_argument('zip')
+    parser.add_argument('sources', nargs='*')
+    args = parser.parse_args()
+
+    dst_base = args.output if args.output is not None else os.getcwd()
+
+    compresslevel = args.l
+
+    if args.verbose and args.silent:
+        print_utf8('choose one: verbose or silent')
+        exit(1)
+
+    verbose = args.verbose or not args.silent
+
+    if args.command == 'a':
+        if args.list is None:
+            paths = glob_paths(args.sources)
+        else:
+            lines = read_file_text(args.list).split('\n')
+            paths = [line.rstrip() for line in lines if line.rstrip() != '']
+
+        compression = COMPRESSION_METHODS[args.m] if args.m is not None else ZIP_DEFLATED
+
+        def add_file(zf, p, base):
+            relpath = os.path.relpath(p, base)
+            if args.dir:
+                relpath = os.path.join(args.dir, relpath)
+            if verbose:
+                print_utf8(p)
+            zf.write(p, relpath)
+
+        with zipfile.ZipFile(args.zip, 'a', compression=compression, compresslevel=compresslevel) as zf:
+            for path in paths:
+                if args.base is None:
+                    if os.path.isabs(path):
+                        base = os.path.dirname(path)
+                    else:
+                        base = os.getcwd()
+                else:
+                    base = args.base
+
+                if os.path.isfile(path):
+                    add_file(zf, path, base)
+                else:
+                    for root, dirs, files in os.walk(path):
+                        for f in files:
+                            p = os.path.join(root, f)
+                            add_file(zf, p, base)
+                        
+    if args.command == 'x':
+        # todo extract globs and dirs, use --list
+        with zipfile.ZipFile(args.zip) as zf:
+            for name in zf.namelist():
+                name_ = name.replace('/','\\')
+                if len(args.sources) == 0 or name in args.sources or name_ in args.sources:
+                    #dest = os.path.join(dst_base, name)
+                    print("extract {} to {}".format(name, dst_base))
+                    zf.extract(name, dst_base)
+                    
+    if args.command == 'l':
+        # todo print size
+        with zipfile.ZipFile(args.zip) as zf:
+            for name in zf.namelist():
+                print_utf8(name)
+
+if __name__ == "__main__":
     main()
```

## mugicli/shared.py

 * *Ordering differences only*

```diff
@@ -1,191 +1,191 @@
-import glob
-import sys
-import io
-import subprocess
-import os
-import re
-
-NUM_RX = r'([-+]?(\d+(\.\d*)?|\.\d+)([eE][-+]?\d+)?)'
-
-def glob_paths(paths):
-    res = []
-    for path in paths:
-        if has_magic(path):
-            res += glob.glob(path)
-        else:
-            res.append(path)
-    return res
-
-def glob_paths(paths):
-    return _glob_paths_pred(paths, lambda path: True)
-
-def glob_paths_files(paths):
-    return _glob_paths_pred(paths, lambda path: os.path.isfile(path))
-
-def glob_paths_dirs(paths):
-    return _glob_paths_pred(paths, lambda path: os.path.isdir(path))
-
-def has_magic(path):
-    # brackets in path is ambigous
-    if os.path.exists(path):
-        return False
-    return glob.has_magic(path) # ok
-
-def _glob_paths_pred(paths, pred):
-    res = []
-    for path in paths:
-        if has_magic(path):
-            for item in glob.glob(path):
-                if pred(item):
-                    res.append(item)
-        else:
-            if pred(path):
-                res.append(path)
-    return res
-
-def glob_paths_dirs(paths):
-    res = []
-    for path in paths:
-        if has_magic(path):
-            for item in glob.glob(path):
-                if os.path.isdir(item):
-                    res.append(item)
-        else:
-            res.append(path)
-    return res
-
-def drop_last_empty_line(lines):
-    if lines[-1].strip() == "":
-        lines.pop()
-
-"""
-def print(arg, encoding='utf-8'):
-    if isinstance(arg, bytes):
-        print_bytes(arg)
-    elif isinstance(arg, list):
-        print_lines(arg, encoding)
-    elif isinstance(arg, str):
-        print_lines([arg], encoding)
-"""
-
-def print_bytes(bytes_):
-    sys.stdout.buffer.write(bytes_)
-
-def print_lines(lines, encoding='utf-8'):
-    for line in lines:
-        #sys.stdout.write(line)
-        print_bytes(line.encode(encoding))
-
-def eprint(*args, **kwargs):
-    print(*args, file=sys.stderr, **kwargs)
-
-def read_bytes(paths):
-    if isinstance(paths, list):
-        return _read_bytes_many(paths)
-    return _read_bytes_one(paths)
-
-def _read_bytes_one(path):
-    if path is None:
-        return sys.stdin.buffer.read()
-    with open(path, 'rb') as f:
-        return f.read()
-
-def _read_bytes_many(paths):
-    stdin_mode = len(paths) == 0
-    if stdin_mode:
-        return read_bytes(None)
-    else:
-        return b''.join([read_bytes(path) for path in paths])
-
-def split_to_lines(text):
-    lines = text.split('\n')
-    line = lines[-1]
-    lines = [line + '\n' for line in lines]
-    lines[-1] = line
-    return lines
-
-def read_lines(paths, encoding='utf-8', drop_last_empty_line_ = False):
-    if isinstance(paths, list):
-        return _read_lines_many(paths, encoding, drop_last_empty_line_)
-    return _read_lines_one(paths, encoding, drop_last_empty_line_)
-
-def line_reader(paths, from_stdin, encoding='utf-8', drop_last_empty_line_ = False):
-    if from_stdin:
-        for i, line in enumerate(_read_lines_one(None, encoding, drop_last_empty_line_)):
-            yield i, line, '-'
-    else:
-        for path in paths:
-            for i, line in enumerate(_read_lines_one(path, encoding, drop_last_empty_line_)):
-                yield i, line, path
-
-def _read_lines_many(paths, encoding='utf-8', drop_last_empty_line_ = False):
-    stdin_mode = len(paths) == 0
-    if stdin_mode:
-        return _read_lines_one(None, encoding, drop_last_empty_line_)
-    lines = []
-    for path in paths:
-        lines += _read_lines_one(path, encoding, drop_last_empty_line_)
-    return lines
-
-def _read_lines_one(path, encoding='utf-8', drop_last_empty_line_ = False):
-    bytes_ = read_bytes(path)
-    lines = split_to_lines(bytes_.decode(encoding))
-    if drop_last_empty_line_ and lines[-1] in ['\r', '']:
-        lines.pop()
-    return lines
-
-def read_lines_(paths, drop_last_empty_line_ = False):
-    lines = []
-
-    stdin_mode = len(paths) == 0
-
-    if stdin_mode:
-        lines = list(sys.stdin)
-        if drop_last_empty_line_:
-            drop_last_empty_line(lines)
-    else:
-        for path in paths:
-            with open(path, 'r', encoding='utf-8') as f:
-                lines_ = f.readlines()
-            if drop_last_empty_line_:
-                drop_last_empty_line(lines_)
-            lines += lines_
-
-    return lines
-
-def run(args, cwd = None):
-    shell = (args[0] in ['type', 'echo', 'copy']) or '|' in args
-    subprocess.run(args, shell=shell, cwd=cwd)
-
-
-def index_of_int(args):
-    for i, arg in enumerate(args):
-        if re.match('^-[0-9]+$', arg):
-            return i
-
-def parse_args(short, long, short_val, long_val, args):
-    opts = {k: False for k in short + long}
-    for n in short_val + long_val:
-        opts[n] = None
-    while len(args) > 0:
-        arg = args[0]
-        if arg.startswith('--') and arg[2:] in long:
-            opts[arg[2:]] = True
-        elif arg.startswith('--') and arg[2:] in long_val:
-            opts[arg[2:]] = args[1]
-            args.pop(0)
-        elif arg.startswith('-') and arg[1:] in short_val:
-            opts[arg[1:]] = args[1]
-            args.pop(0)
-        elif arg.startswith('-') and all([c in short for c in arg[1:]]):
-            for c in arg[1:]:
-                opts[c] = True
-        else:
-            return opts, args
-        args.pop(0)
-    return opts, args
-
-def print_utf8(s, end=b'\n'):
-    if not isinstance(end, bytes):
-        end = end.encode('utf-8')
-    sys.stdout.buffer.write(s.encode('utf-8') + end)
+import glob
+import sys
+import io
+import subprocess
+import os
+import re
+
+NUM_RX = r'([-+]?(\d+(\.\d*)?|\.\d+)([eE][-+]?\d+)?)'
+
+def glob_paths(paths):
+    res = []
+    for path in paths:
+        if has_magic(path):
+            res += glob.glob(path)
+        else:
+            res.append(path)
+    return res
+
+def glob_paths(paths):
+    return _glob_paths_pred(paths, lambda path: True)
+
+def glob_paths_files(paths):
+    return _glob_paths_pred(paths, lambda path: os.path.isfile(path))
+
+def glob_paths_dirs(paths):
+    return _glob_paths_pred(paths, lambda path: os.path.isdir(path))
+
+def has_magic(path):
+    # brackets in path is ambigous
+    if os.path.exists(path):
+        return False
+    return glob.has_magic(path) # ok
+
+def _glob_paths_pred(paths, pred):
+    res = []
+    for path in paths:
+        if has_magic(path):
+            for item in glob.glob(path):
+                if pred(item):
+                    res.append(item)
+        else:
+            if pred(path):
+                res.append(path)
+    return res
+
+def glob_paths_dirs(paths):
+    res = []
+    for path in paths:
+        if has_magic(path):
+            for item in glob.glob(path):
+                if os.path.isdir(item):
+                    res.append(item)
+        else:
+            res.append(path)
+    return res
+
+def drop_last_empty_line(lines):
+    if lines[-1].strip() == "":
+        lines.pop()
+
+"""
+def print(arg, encoding='utf-8'):
+    if isinstance(arg, bytes):
+        print_bytes(arg)
+    elif isinstance(arg, list):
+        print_lines(arg, encoding)
+    elif isinstance(arg, str):
+        print_lines([arg], encoding)
+"""
+
+def print_bytes(bytes_):
+    sys.stdout.buffer.write(bytes_)
+
+def print_lines(lines, encoding='utf-8'):
+    for line in lines:
+        #sys.stdout.write(line)
+        print_bytes(line.encode(encoding))
+
+def eprint(*args, **kwargs):
+    print(*args, file=sys.stderr, **kwargs)
+
+def read_bytes(paths):
+    if isinstance(paths, list):
+        return _read_bytes_many(paths)
+    return _read_bytes_one(paths)
+
+def _read_bytes_one(path):
+    if path is None:
+        return sys.stdin.buffer.read()
+    with open(path, 'rb') as f:
+        return f.read()
+
+def _read_bytes_many(paths):
+    stdin_mode = len(paths) == 0
+    if stdin_mode:
+        return read_bytes(None)
+    else:
+        return b''.join([read_bytes(path) for path in paths])
+
+def split_to_lines(text):
+    lines = text.split('\n')
+    line = lines[-1]
+    lines = [line + '\n' for line in lines]
+    lines[-1] = line
+    return lines
+
+def read_lines(paths, encoding='utf-8', drop_last_empty_line_ = False):
+    if isinstance(paths, list):
+        return _read_lines_many(paths, encoding, drop_last_empty_line_)
+    return _read_lines_one(paths, encoding, drop_last_empty_line_)
+
+def line_reader(paths, from_stdin, encoding='utf-8', drop_last_empty_line_ = False):
+    if from_stdin:
+        for i, line in enumerate(_read_lines_one(None, encoding, drop_last_empty_line_)):
+            yield i, line, '-'
+    else:
+        for path in paths:
+            for i, line in enumerate(_read_lines_one(path, encoding, drop_last_empty_line_)):
+                yield i, line, path
+
+def _read_lines_many(paths, encoding='utf-8', drop_last_empty_line_ = False):
+    stdin_mode = len(paths) == 0
+    if stdin_mode:
+        return _read_lines_one(None, encoding, drop_last_empty_line_)
+    lines = []
+    for path in paths:
+        lines += _read_lines_one(path, encoding, drop_last_empty_line_)
+    return lines
+
+def _read_lines_one(path, encoding='utf-8', drop_last_empty_line_ = False):
+    bytes_ = read_bytes(path)
+    lines = split_to_lines(bytes_.decode(encoding))
+    if drop_last_empty_line_ and lines[-1] in ['\r', '']:
+        lines.pop()
+    return lines
+
+def read_lines_(paths, drop_last_empty_line_ = False):
+    lines = []
+
+    stdin_mode = len(paths) == 0
+
+    if stdin_mode:
+        lines = list(sys.stdin)
+        if drop_last_empty_line_:
+            drop_last_empty_line(lines)
+    else:
+        for path in paths:
+            with open(path, 'r', encoding='utf-8') as f:
+                lines_ = f.readlines()
+            if drop_last_empty_line_:
+                drop_last_empty_line(lines_)
+            lines += lines_
+
+    return lines
+
+def run(args, cwd = None):
+    shell = (args[0] in ['type', 'echo', 'copy']) or '|' in args
+    subprocess.run(args, shell=shell, cwd=cwd)
+
+
+def index_of_int(args):
+    for i, arg in enumerate(args):
+        if re.match('^-[0-9]+$', arg):
+            return i
+
+def parse_args(short, long, short_val, long_val, args):
+    opts = {k: False for k in short + long}
+    for n in short_val + long_val:
+        opts[n] = None
+    while len(args) > 0:
+        arg = args[0]
+        if arg.startswith('--') and arg[2:] in long:
+            opts[arg[2:]] = True
+        elif arg.startswith('--') and arg[2:] in long_val:
+            opts[arg[2:]] = args[1]
+            args.pop(0)
+        elif arg.startswith('-') and arg[1:] in short_val:
+            opts[arg[1:]] = args[1]
+            args.pop(0)
+        elif arg.startswith('-') and all([c in short for c in arg[1:]]):
+            for c in arg[1:]:
+                opts[c] = True
+        else:
+            return opts, args
+        args.pop(0)
+    return opts, args
+
+def print_utf8(s, end=b'\n'):
+    if not isinstance(end, bytes):
+        end = end.encode('utf-8')
+    sys.stdout.buffer.write(s.encode('utf-8') + end)
```

## Comparing `mugicli-0.0.8.dist-info/METADATA` & `mugicli-0.0.9.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mugicli
-Version: 0.0.8
+Version: 0.0.9
 Summary: Shell utilities resembling coreutils and findutils, small extendable and windows-friendly
 Home-page: https://github.com/mugiseyebrows/mugi-cli
 Author: Stanislav Doronin
 Author-email: mugisbrows@gmail.com
 License: UNKNOWN
 Platform: UNKNOWN
 Description-Content-Type: text/markdown
@@ -440,14 +440,33 @@
   path        target path
 
 optional arguments:
   -h, --help  show this help message and exit
   -d D        datetime or relative time in format [+-]NUM[d|h|m|s] format
 
 ```
+## pytree
+```
+usage: pytree [-h] [-L LEVEL] [-i INCLUDE [INCLUDE ...]]
+                 [-e EXCLUDE [EXCLUDE ...]]
+                 path
+
+positional arguments:
+  path
+
+optional arguments:
+  -h, --help            show this help message and exit
+  -L LEVEL, --level LEVEL
+                        depth
+  -i INCLUDE [INCLUDE ...], --include INCLUDE [INCLUDE ...]
+                        include files globs
+  -e EXCLUDE [EXCLUDE ...], --exclude EXCLUDE [EXCLUDE ...]
+                        include files globs
+
+```
 ## pyuniq
 ```
 usage: pyuniq [-h] [--count] [--repeated] [--unique] [path ...]
 
 prints unique or nonunique lines from sorted array of lines
 
 positional arguments:
```

## Comparing `mugicli-0.0.8.dist-info/entry_points.txt` & `mugicli-0.0.9.dist-info/entry_points.txt`

 * *Files 2% similar despite different names*

```diff
@@ -22,14 +22,15 @@
 pysha512sum = mugicli.pysha512sum:main
 pysort = mugicli.pysort:main
 pystart = mugicli.pystart:main
 pytail = mugicli.pytail:main
 pytime = mugicli.pytime:main
 pytmp = mugicli.pytmp:main
 pytouch = mugicli.pytouch:main
+pytree = mugicli.pytree:main
 pyuniq = mugicli.pyuniq:main
 pyunix2dos = mugicli.pyunix2dos:main
 pywc = mugicli.pywc:main
 pyxargs = mugicli.pyxargs:main
 pyxxd = mugicli.pyxxd:main
 pyzip = mugicli.pyzip:main
```

## Comparing `mugicli-0.0.8.dist-info/RECORD` & `mugicli-0.0.9.dist-info/RECORD`

 * *Files 20% similar despite different names*

```diff
@@ -1,43 +1,43 @@
-mugicli/__init__.py,sha256=96O_0xovl8WY6X4LILNgcy8bCZ4jRPYjI_MxigKe13s,4405
-mugicli/headtail.py,sha256=1jkr-9gDMHR6uvupLGDhtT0jtDSVvx1zL_Y4glrSMBg,1334
-mugicli/pycat.py,sha256=0HfGcFJ7LjWcfVAyroZva5UnygcLFXw6Iaq5OpBCalA,629
-mugicli/pycol.py,sha256=UJlSemgDjbzch5tXg_ui5j1eRDj0RdJkGbBZOB-Me_w,825
+mugicli/__init__.py,sha256=r8ekeNBoKykqx6l8RIf9TIlahcUa1WYokBWuU34TfRE,7152
+mugicli/headtail.py,sha256=y_2ZtuyIx8yCEn9IlvmfupSEgKjHZ5yFR7SP8sQ3-NU,1378
+mugicli/pycat.py,sha256=MwJip4P5slYf-kBoIA5xv-fY_pnWHNsoLtDJdjzqsbQ,655
+mugicli/pycol.py,sha256=39Wv5sAtsAzSGPdVtnfJ5tAp-e3O5wphsB27YKjYe6c,850
 mugicli/pycwd.py,sha256=jzu7vGZPA9t_INxEbTpvxi7HD3TYcpQQ8d2OKw9ETxk,395
 mugicli/pydos2unix.py,sha256=zxZOiElIqjxAPc7u8o3rniZtDhez4HKxN9fzI26mdPo,127
-mugicli/pydu.py,sha256=TrJZ_TPTpEZvmlAxkXkWwHbqgGesqn-hiQvNk2tVs2Q,5304
-mugicli/pyecho.py,sha256=APyjc4fcvIMvjH_9QIvQUO453lTrK3uVxfHa3ZSvZEc,1960
-mugicli/pyextstat.py,sha256=vu44p_U4LlToFF0_vSETvOn14vRkgzfsGF6D5kd1-eQ,1457
-mugicli/pyfind.py,sha256=Z2i5v_rWw8O9U8jrBRcDghIWM3leHajJI4KfrjRndTA,24579
-mugicli/pygrep.py,sha256=Xor4lx-qufMuoG3DwH3DjDE9I46Iiwe0UKzL9-EkFMg,2196
-mugicli/pyhead.py,sha256=qYBFOF2jJLyx--M_uBYcBY6x7lEyNE1y1xX_ooURD_w,119
-mugicli/pyls.py,sha256=KeOFzVJXRjkVL9pkvkrYygo6qDOtn_CpAbFA9NHUXxg,870
+mugicli/pydu.py,sha256=zVhJkt7__v4DMOMPfcxoBDuDClkfm4bmka1ljAs7tc0,5500
+mugicli/pyecho.py,sha256=qLj4EqNbS7TOdz-YFHYXr-i2xg5nluT6PPwmd4WYW5o,2050
+mugicli/pyextstat.py,sha256=KO-s6Pxo6aIwsG0kXHBqzTD2wTyNG9ozyuBDEYgK7QM,1504
+mugicli/pyfind.py,sha256=HZ125iCXmjRnIIbQn-eP9VgagRPtp9fvvDE2iplENv8,23449
+mugicli/pygrep.py,sha256=lDc_mA9y_WTFcleRlBkc5cW0S-S_T0_Hw1Sh_pmhaE4,2265
+mugicli/pyhead.py,sha256=jGsOV8OKfK6uc9ohiABmKNYWor4_-Ky4vpmF9AJjtN4,125
+mugicli/pyls.py,sha256=LB5O3h82tegLiSqflP4DTSorzuI_GURezhUDMTcmMYg,2110
 mugicli/pymd5sum.py,sha256=ZjL4mmambWa3Hiissr5Phws-IdZc3iL4ItjGSnSP3bU,112
-mugicli/pymtime.py,sha256=bRzmHlK9fYD7OyEn6y7COMcG-xiKZ9vPpnZqtCXbWo4,712
-mugicli/pymtimestat.py,sha256=UfucsBQJKYWuqaVI1T6wwgkEcvCe-hrCuBbZoXN-xRM,4131
-mugicli/pypathjoin.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-mugicli/pysed.py,sha256=dOthZULwSg2mhN_cQNJPw1OhLPZcvASIkvTZ4OGBxQc,1487
-mugicli/pyseq.py,sha256=po1-FsTnpYuWBL5ms11FBXSSTAUDYELwMVT9YJUo3NI,1304
+mugicli/pymtime.py,sha256=F-eZIDFxPOCgzvivo7OOzFhCmcfrXUtRa2Is_AxRLA0,738
+mugicli/pymtimestat.py,sha256=ry8QThP7Xq6UfyoffouiKzcObitIWO6hoJbcmZ2FLBk,3779
+mugicli/pysed.py,sha256=MFS3mjDzU9nNcz2NQdunEAD05ZNLiyZcO2BgN7jRCgE,1548
+mugicli/pyseq.py,sha256=n2o3YpZTgWiyuHMjXRjmwLJkWEfgFpJ2wrsjD6WRjWU,1364
 mugicli/pysha1sum.py,sha256=cXGelAemKWe6NZ0JNpHp4668wyoDe1OTYJwj_6fGOPI,113
 mugicli/pysha224sum.py,sha256=Q3rMQZ8v8pDOQMwS35dnrSpsBhsmHATri8-teSzC7YI,115
 mugicli/pysha256sum.py,sha256=FnabX-baD-0V-B_LlEb_HVqdR1_X90TErN-hRLNWaDs,115
 mugicli/pysha384sum.py,sha256=bn9k-v8sL8VSWplhr_35fgOnBOR1PeIIqzbrzimDQpY,115
 mugicli/pysha512sum.py,sha256=m05BzvTU-XXBp3B4n2wv80ceivyNm4A8rcPSVGhMF18,115
-mugicli/pysort.py,sha256=XtrTzBllBXHsbFyVsAVgjO7jnsXg47qkZVX73HLNmZ4,1705
+mugicli/pysort.py,sha256=5egEGPPNfKpoFDnv085O43AWX-IjZfVooexyZdeaq3A,1771
 mugicli/pystart.py,sha256=SLMeqg8ThfPb_Od_LTTmSyviIHya82qk7ih0OxdHEvs,1129
-mugicli/pytail.py,sha256=Y63kl2aBV_Tw7SlxCstjCZMSos49N8Cr9XQPLOUo758,119
-mugicli/pytime.py,sha256=PseIuPKOGiIL-3Su9tN4m0LDd8NZGJYC8JBd5n-AG4Q,499
-mugicli/pytmp.py,sha256=p4qW8BYXnrQsy4Ye0xNhiaO1wGoFM4u51nq1er0wHvM,1818
-mugicli/pytouch.py,sha256=7MWJRqHti47Y6mqt9Pc331P83rJfD1_wwoYfKTqMX3M,1372
-mugicli/pyuniq.py,sha256=r5qG0y3pte7hDAmOk0fsLNzCH4DFd01H-3j7aR7VOA8,1233
+mugicli/pytail.py,sha256=NWZ2-l1x5ZcIo4h5fs_yI_wcA78HUDpeYE6aVKCjWgM,125
+mugicli/pytime.py,sha256=N7MLBhbZn12jT3Yr-fFSh2SQKQvSaFzTu7f1y_xGirs,528
+mugicli/pytmp.py,sha256=3SqAdfQcVvR8mB17iEDc3BaDV1vzIeoXyCQKoenw6AQ,1883
+mugicli/pytouch.py,sha256=E53GJMKJxCgAy-DT-2yVUkpyPz_7KXwyqcTD1Saa77c,1419
+mugicli/pytree.py,sha256=i0F0ElbgxwRCro1XmAaDQ60_oFHDrkBLYBhSLLBVUlU,4609
+mugicli/pyuniq.py,sha256=VPggxg7UU0PhX7DAJbRL6RrjytXyv9HMfo58jEsZ7oQ,1274
 mugicli/pyunix2dos.py,sha256=LEFTZ6QXaLfSYsYIPpU_DQtRVDzRvRpww8BDJohSLBg,125
-mugicli/pywc.py,sha256=VqKK3q-LuUn6vwohrQaItWk9TMjQmtCJBd5yzI5GDl8,2150
-mugicli/pyxargs.py,sha256=7sAggZKcFXqdDXgPMcdjVNizBpKjE-bLoFtTkegA9us,1274
+mugicli/pywc.py,sha256=bfIMSEJocSfk3AUfcUjdjC0lYRTNx-d-LozgcYL3jT4,2225
+mugicli/pyxargs.py,sha256=Ng3hDWxEy76379yJ20oCUpsMQqffDD-5oIprssMGR_4,1325
 mugicli/pyxxd.py,sha256=3r76Y8xsq_3u4l4cBrsWzUSe9xKGoe4O7q71zFJjW74,1595
-mugicli/pyzip.py,sha256=bA1MaM9ng69vX4nh2V3PYNwgl8YrZleSETOALS269HE,3665
-mugicli/shared.py,sha256=G2Vvep2QLJOu8MAXc2pq9jtok1Jcl6FG05WPlyymDtQ,5385
-mugicli-0.0.8.dist-info/LICENSE,sha256=QrNi96C96s38XhZgXFhalL2Sn4Do7bXYATW_qCVvxxU,1070
-mugicli-0.0.8.dist-info/METADATA,sha256=E1nWxUrLE_HhpgKHzkk51bJ5Vk6YABhlcNVS1ydJ7NA,12225
-mugicli-0.0.8.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
-mugicli-0.0.8.dist-info/entry_points.txt,sha256=A1Np83mo_mD2CWNEIPJFkcfSQWmUJQU73LMM3kFSkR0,1038
-mugicli-0.0.8.dist-info/top_level.txt,sha256=q4w9ormPXeARd6mSr_DPg_AUetI96MpgEu5iE6Anbm8,8
-mugicli-0.0.8.dist-info/RECORD,,
+mugicli/pyzip.py,sha256=C7VvFyKa0N_vZIsY71ijDftCiw92vZuDgPbv9qll2HI,3889
+mugicli/shared.py,sha256=05DYOAOn0gNFVNeOshBxwvNUUkSHOW9rJxUGVpPlhZY,5576
+mugicli-0.0.9.dist-info/LICENSE,sha256=gF3NFiEJEA4rpMYY0qxiE9w8f5RimwCGbv7j24l5Y48,1091
+mugicli-0.0.9.dist-info/METADATA,sha256=HIQDMVAC50fIN3Ud6aIyCcxVW_oYB8lyjs4dLZ0bWgI,12738
+mugicli-0.0.9.dist-info/WHEEL,sha256=S6zePDbUAjzMmpYOg2cHDxuYFWw7WiOXt6ogM6hIB5Q,92
+mugicli-0.0.9.dist-info/entry_points.txt,sha256=SkYIh3QimTmlTaQqdgNBx-Dre1BI8cG8gHY_IuTMJMc,1067
+mugicli-0.0.9.dist-info/top_level.txt,sha256=q4w9ormPXeARd6mSr_DPg_AUetI96MpgEu5iE6Anbm8,8
+mugicli-0.0.9.dist-info/RECORD,,
```

