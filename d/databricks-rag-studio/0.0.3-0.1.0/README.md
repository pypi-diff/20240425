# Comparing `tmp/databricks_rag_studio-0.0.3-py3-none-any.whl.zip` & `tmp/databricks_rag_studio-0.1.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,57 +1,57 @@
-Zip file size: 69742 bytes, number of entries: 55
+Zip file size: 71441 bytes, number of entries: 55
 -rw-r--r--  2.0 unx      344 b- defN 24-Apr-12 22:41 databricks/__init__.py
--rw-r--r--  2.0 unx      493 b- defN 24-Apr-16 04:05 databricks/rag/__init__.py
+-rw-r--r--  2.0 unx      493 b- defN 24-Apr-17 02:51 databricks/rag/__init__.py
 -rw-r--r--  2.0 unx     4294 b- defN 24-Apr-12 22:41 databricks/rag/configs.py
 -rw-r--r--  2.0 unx     1529 b- defN 24-Apr-12 22:41 databricks/rag/constants.py
 -rw-r--r--  2.0 unx    25475 b- defN 24-Apr-12 22:41 databricks/rag/entities.py
 -rw-r--r--  2.0 unx     7071 b- defN 24-Apr-12 22:41 databricks/rag/environments.py
 -rw-r--r--  2.0 unx      141 b- defN 24-Apr-12 22:41 databricks/rag/errors.py
--rw-r--r--  2.0 unx       62 b- defN 24-Apr-16 07:20 databricks/rag/version.py
+-rw-r--r--  2.0 unx       62 b- defN 24-Apr-23 22:19 databricks/rag/version.py
 -rw-r--r--  2.0 unx      476 b- defN 24-Apr-13 01:44 databricks/rag/evaluation/__init__.py
 -rw-r--r--  2.0 unx     5377 b- defN 24-Apr-13 01:44 databricks/rag/evaluation/offline.py
 -rw-r--r--  2.0 unx     4197 b- defN 24-Apr-13 01:44 databricks/rag/evaluation/online.py
 -rw-r--r--  2.0 unx      493 b- defN 24-Apr-12 22:41 databricks/rag/scoring/__init__.py
 -rw-r--r--  2.0 unx     3691 b- defN 24-Apr-12 22:41 databricks/rag/scoring/feedback.py
--rw-r--r--  2.0 unx    13365 b- defN 24-Apr-12 22:41 databricks/rag/scoring/langchain_tracer.py
--rw-r--r--  2.0 unx    12836 b- defN 24-Apr-13 01:44 databricks/rag/scoring/predictions.py
--rw-r--r--  2.0 unx     3196 b- defN 24-Apr-12 22:41 databricks/rag/scoring/schema_v2.py
+-rw-r--r--  2.0 unx    14954 b- defN 24-Apr-18 00:51 databricks/rag/scoring/langchain_tracer.py
+-rw-r--r--  2.0 unx    12893 b- defN 24-Apr-23 08:04 databricks/rag/scoring/predictions.py
+-rw-r--r--  2.0 unx     2771 b- defN 24-Apr-18 00:51 databricks/rag/scoring/schema_v2.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Apr-12 22:41 databricks/rag/studio/__init__.py
 -rw-r--r--  2.0 unx      392 b- defN 24-Apr-12 22:41 databricks/rag/studio/chain_logging.py
 -rw-r--r--  2.0 unx     1552 b- defN 24-Apr-12 22:41 databricks/rag/studio/configs.py
--rw-r--r--  2.0 unx     8398 b- defN 24-Apr-13 01:44 databricks/rag/unpacking/__init__.py
--rw-r--r--  2.0 unx    10140 b- defN 24-Apr-13 01:44 databricks/rag/unpacking/schemas.py
+-rw-r--r--  2.0 unx      440 b- defN 24-Apr-23 08:04 databricks/rag/unpacking/__init__.py
+-rw-r--r--  2.0 unx    10134 b- defN 24-Apr-19 07:04 databricks/rag/unpacking/schemas.py
+-rw-r--r--  2.0 unx     9564 b- defN 24-Apr-23 22:19 databricks/rag/unpacking/unpack.py
 -rw-r--r--  2.0 unx     1462 b- defN 24-Apr-12 22:41 databricks/rag/utils/__init__.py
 -rw-r--r--  2.0 unx     3736 b- defN 24-Apr-12 22:41 databricks/rag/utils/mlflow.py
 -rw-r--r--  2.0 unx     1147 b- defN 24-Apr-12 22:41 databricks/rag/utils/tables.py
 -rw-r--r--  2.0 unx     4964 b- defN 24-Apr-12 22:41 databricks/rag/utils/uc.py
--rw-r--r--  2.0 unx      620 b- defN 24-Apr-04 23:45 databricks/rag_studio/__init__.py
--rw-r--r--  2.0 unx    11155 b- defN 24-Apr-16 19:46 databricks/rag_studio/chain_logging.py
+-rw-r--r--  2.0 unx      789 b- defN 24-Apr-25 16:58 databricks/rag_studio/__init__.py
+-rw-r--r--  2.0 unx    11378 b- defN 24-Apr-25 16:58 databricks/rag_studio/chain_logging.py
 -rw-r--r--  2.0 unx    11727 b- defN 24-Apr-11 16:58 databricks/rag_studio/deployments.py
 -rw-r--r--  2.0 unx     1361 b- defN 24-Apr-11 16:58 databricks/rag_studio/feedback.py
--rw-r--r--  2.0 unx    12360 b- defN 24-Apr-10 16:50 databricks/rag_studio/permissions.py
--rw-r--r--  2.0 unx     5850 b- defN 24-Apr-16 18:16 databricks/rag_studio/reviews.py
--rw-r--r--  2.0 unx       62 b- defN 24-Apr-16 19:46 databricks/rag_studio/version.py
+-rw-r--r--  2.0 unx    19720 b- defN 24-Apr-23 15:23 databricks/rag_studio/permissions.py
+-rw-r--r--  2.0 unx     6805 b- defN 24-Apr-22 16:27 databricks/rag_studio/reviews.py
+-rw-r--r--  2.0 unx       62 b- defN 24-Apr-25 17:32 databricks/rag_studio/version.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Apr-04 23:45 databricks/rag_studio/client/__init__.py
--rw-r--r--  2.0 unx     3925 b- defN 24-Apr-04 23:45 databricks/rag_studio/client/rest_client.py
+-rw-r--r--  2.0 unx     4610 b- defN 24-Apr-22 16:27 databricks/rag_studio/client/rest_client.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Apr-04 23:45 databricks/rag_studio/sdk_utils/__init__.py
 -rw-r--r--  2.0 unx      664 b- defN 24-Apr-04 23:45 databricks/rag_studio/sdk_utils/deployments.py
--rw-r--r--  2.0 unx      545 b- defN 24-Apr-04 23:45 databricks/rag_studio/sdk_utils/entities.py
+-rw-r--r--  2.0 unx      600 b- defN 24-Apr-22 16:27 databricks/rag_studio/sdk_utils/entities.py
 -rw-r--r--  2.0 unx     1467 b- defN 24-Apr-04 23:45 databricks/rag_studio/sdk_utils/permissions_checker.py
--rw-r--r--  2.0 unx     2680 b- defN 24-Apr-16 18:16 databricks/rag_studio/sdk_utils/schemas.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Apr-04 23:45 databricks/rag_studio/utils/__init__.py
 -rw-r--r--  2.0 unx     2461 b- defN 24-Apr-04 23:45 databricks/rag_studio/utils/annotations.py
 -rw-r--r--  2.0 unx      664 b- defN 24-Apr-04 23:45 databricks/rag_studio/utils/mlflow_utils.py
 -rw-r--r--  2.0 unx     1274 b- defN 24-Apr-04 23:45 databricks/rag_studio/utils/rest_utils.py
 -rw-r--r--  2.0 unx      853 b- defN 24-Apr-04 23:45 databricks/rag_studio/utils/uc.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Apr-12 22:41 tests/evaluation/__init__.py
 -rw-r--r--  2.0 unx    21379 b- defN 24-Apr-13 01:44 tests/evaluation/test_offline.py
 -rw-r--r--  2.0 unx    17337 b- defN 24-Apr-13 01:44 tests/evaluation/test_online.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Apr-13 01:44 tests/unpacking/__init__.py
 -rw-r--r--  2.0 unx     1146 b- defN 24-Apr-13 01:44 tests/unpacking/eval_test_utils.py
--rw-r--r--  2.0 unx    18109 b- defN 24-Apr-13 01:44 tests/unpacking/test_unpacking.py
--rw-r--r--  2.0 unx     2413 b- defN 24-Apr-16 19:46 databricks_rag_studio-0.0.3.dist-info/LICENSE.md
--rw-r--r--  2.0 unx      768 b- defN 24-Apr-16 19:46 databricks_rag_studio-0.0.3.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-16 19:46 databricks_rag_studio-0.0.3.dist-info/WHEEL
--rw-r--r--  2.0 unx       11 b- defN 24-Apr-16 19:46 databricks_rag_studio-0.0.3.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     5006 b- defN 24-Apr-16 19:46 databricks_rag_studio-0.0.3.dist-info/RECORD
-55 files, 238760 bytes uncompressed, 61634 bytes compressed:  74.2%
+-rw-r--r--  2.0 unx    18061 b- defN 24-Apr-19 07:04 tests/unpacking/test_unpacking.py
+-rw-r--r--  2.0 unx     2413 b- defN 24-Apr-25 17:36 databricks_rag_studio-0.1.0.dist-info/LICENSE.md
+-rw-r--r--  2.0 unx      768 b- defN 24-Apr-25 17:36 databricks_rag_studio-0.1.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-25 17:36 databricks_rag_studio-0.1.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       11 b- defN 24-Apr-25 17:36 databricks_rag_studio-0.1.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     4997 b- defN 24-Apr-25 17:36 databricks_rag_studio-0.1.0.dist-info/RECORD
+55 files, 248291 bytes uncompressed, 63349 bytes compressed:  74.5%
```

## zipnote {}

```diff
@@ -57,14 +57,17 @@
 
 Filename: databricks/rag/unpacking/__init__.py
 Comment: 
 
 Filename: databricks/rag/unpacking/schemas.py
 Comment: 
 
+Filename: databricks/rag/unpacking/unpack.py
+Comment: 
+
 Filename: databricks/rag/utils/__init__.py
 Comment: 
 
 Filename: databricks/rag/utils/mlflow.py
 Comment: 
 
 Filename: databricks/rag/utils/tables.py
@@ -108,17 +111,14 @@
 
 Filename: databricks/rag_studio/sdk_utils/entities.py
 Comment: 
 
 Filename: databricks/rag_studio/sdk_utils/permissions_checker.py
 Comment: 
 
-Filename: databricks/rag_studio/sdk_utils/schemas.py
-Comment: 
-
 Filename: databricks/rag_studio/utils/__init__.py
 Comment: 
 
 Filename: databricks/rag_studio/utils/annotations.py
 Comment: 
 
 Filename: databricks/rag_studio/utils/mlflow_utils.py
@@ -144,23 +144,23 @@
 
 Filename: tests/unpacking/eval_test_utils.py
 Comment: 
 
 Filename: tests/unpacking/test_unpacking.py
 Comment: 
 
-Filename: databricks_rag_studio-0.0.3.dist-info/LICENSE.md
+Filename: databricks_rag_studio-0.1.0.dist-info/LICENSE.md
 Comment: 
 
-Filename: databricks_rag_studio-0.0.3.dist-info/METADATA
+Filename: databricks_rag_studio-0.1.0.dist-info/METADATA
 Comment: 
 
-Filename: databricks_rag_studio-0.0.3.dist-info/WHEEL
+Filename: databricks_rag_studio-0.1.0.dist-info/WHEEL
 Comment: 
 
-Filename: databricks_rag_studio-0.0.3.dist-info/top_level.txt
+Filename: databricks_rag_studio-0.1.0.dist-info/top_level.txt
 Comment: 
 
-Filename: databricks_rag_studio-0.0.3.dist-info/RECORD
+Filename: databricks_rag_studio-0.1.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## databricks/rag/version.py

```diff
@@ -1,2 +1,2 @@
 # Update this when publishing a new version
-VERSION = "0.0.3"
+VERSION = "0.1.0"
```

## databricks/rag/scoring/langchain_tracer.py

```diff
@@ -7,22 +7,26 @@
 from langchain_core.tracers.base import BaseTracer
 from langchain_core.tracers.schemas import Run
 from typing_extensions import override
 
 import databricks.rag.scoring.predictions as rag_predictions
 from databricks.rag import constants
 from databricks.rag.scoring.schema_v2 import (
+    MLFLOW_TRACE_SCHEMA_VERSION,
     Event,
     Span,
     SpanContext,
     SpanType,
-    Status,
     StatusCode,
 )
 
+MLFLOW_SPAN_INPUTS_KEY = "mlflow.spanInputs"
+MLFLOW_SPAN_OUTPUTS_KEY = "mlflow.spanOutputs"
+MLFLOW_SPAN_TYPE_KEY = "mlflow.spanType"
+
 COMPONENT_SPAN_TYPE_MAPPING = {
     "llm": SpanType.LLM,
     "retriever": SpanType.RETRIEVER,
     "tool": SpanType.TOOL,
     "agent": SpanType.AGENT,
     "chat_model": SpanType.LLM,
     "chain": SpanType.CHAIN,
@@ -44,22 +48,19 @@
     results = []
     for i, lc_run_event in enumerate(lc_run_events):
         event_time = lc_run_event.pop("time", None) or lc_run_event.pop(
             "timestamp", None
         )
         if event_time:
             name = lc_run_event.pop("name", None) or f"event_{i}"
-            if not isinstance(event_time, datetime):
-                if isinstance(event_time, str):
-                    event_time = datetime.fromisoformat(event_time)
-                elif isinstance(event_time, int):
-                    event_time = datetime.fromtimestamp(event_time)
-                else:
-                    # skip the conversion of this event
-                    continue
+            if isinstance(event_time, datetime):
+                event_time = convert_datetime_to_nanoseconds(event_time)
+            elif not isinstance(event_time, int):
+                # skip the conversion of this event
+                continue
             results.append(
                 Event(
                     name=name,
                     timestamp=event_time,
                     attributes=lc_run_event,
                 )
             )
@@ -167,48 +168,69 @@
         generations: List[List[Dict[str, Any]]] = outputs["generations"]
         if len(generations) > 0 and len(generations[0]) > 0:
             first_generation: Dict[str, Any] = generations[0][0]
             generated_text = first_generation.get("text", "")
     return {"generated_text": generated_text}
 
 
+def convert_datetime_to_nanoseconds(timestamp: Optional[datetime]):
+    if timestamp is None:
+        return
+    if isinstance(timestamp, datetime):
+        return int(timestamp.timestamp() * 1e9)
+    raise TypeError(f"Expecting timestamp to be datetime, got {type(timestamp)}")
+
+
+def convert_nanoseconds_to_datetime(timestamp: Optional[int]):
+    if timestamp is None:
+        return
+    if isinstance(timestamp, int):
+        return datetime.fromtimestamp(timestamp / 1e9)
+    raise TypeError(f"Expecting timestamp to be int, got {type(timestamp)}")
+
+
 def _convert_lc_run_to_span(
     run: Run,
-    status: Status,
+    status_code: StatusCode,
+    status_message="",
     span_type=None,
     input_convert_func=None,
     output_convert_func=None,
 ) -> Span:
     if callable(output_convert_func):
         outputs = output_convert_func(run.outputs)
     else:
         outputs = run.outputs
     if callable(input_convert_func):
         inputs = input_convert_func(run.inputs)
     else:
         inputs = run.inputs
     if span_type is None:
-        span_type = COMPONENT_SPAN_TYPE_MAPPING.get(
-            run.run_type, SpanType.UNKNOWN
-        ).value
+        span_type = COMPONENT_SPAN_TYPE_MAPPING.get(run.run_type, SpanType.UNKNOWN)
     if run.parent_run_id is not None:
         parent_span_id = str(run.parent_run_id)
     else:
         parent_span_id = None
+    attributes = run.extra
+    attributes.update(
+        {
+            MLFLOW_SPAN_INPUTS_KEY: inputs,
+            MLFLOW_SPAN_OUTPUTS_KEY: outputs,
+            MLFLOW_SPAN_TYPE_KEY: str(span_type),
+        }
+    )
     return Span(
         name=run.name,
         context=SpanContext(span_id=str(run.id)),
-        status=status,
-        span_type=span_type,
-        start_time=run.start_time,
-        end_time=run.end_time,
-        parent_span_id=parent_span_id,
-        inputs=inputs,
-        outputs=outputs,
-        attributes=run.extra,
+        parent_id=parent_span_id,
+        start_time=convert_datetime_to_nanoseconds(run.start_time),
+        end_time=convert_datetime_to_nanoseconds(run.end_time),
+        status_code=status_code,
+        status_message=status_message,
+        attributes=attributes,
         events=convert_lc_run_events_to_span_events(deepcopy(run.events)),
     )
 
 
 class DatabricksLangChainTracer(BaseTracer):
     """
     Callback to inject to LangChain to trace the execution of the model.
@@ -249,30 +271,31 @@
         - end_time: End time of the trace
     """
 
     def __init__(self, convert_inputs_outputs: bool = False):
         super().__init__()
         self.convert_inputs_outputs = convert_inputs_outputs
         self.trace = None
-        self._span_buffer = {}
+        self._span_buffer: Dict[str, Span] = {}
         self._lock = threading.Lock()
 
     @override
     def _persist_run(self, run: Run) -> None:
         """
         Persist the run to the trace.
         Only invoke once because this run has no parent run.
         Initialize the trace and update it at the end of the run.
         """
-        self.trace = {"mlflow.trace_schema.version": 2}
+        self.trace = {MLFLOW_TRACE_SCHEMA_VERSION: 2}
 
     def _convert_span_and_flush(
         self,
         run: Run,
-        status: Status,
+        status_code: StatusCode,
+        status_message="",
         span_type=None,
     ) -> None:
         """
         Convert the run to a span and flush it to the span buffer.
         If the run is the root run, update the trace with the span buffer.
         """
         input_convert_func = None
@@ -284,111 +307,132 @@
             elif COMPONENT_SPAN_TYPE_MAPPING.get(run.run_type) == SpanType.RETRIEVER:
                 output_convert_func = lc_retriever_outputs_convert_func
 
         # multiple components can run in parallel and invoke this method
         # at the same time. We add a lock here to make the tracer thread safe.
         with self._lock:
             span = _convert_lc_run_to_span(
-                run, status, span_type, input_convert_func, output_convert_func
+                run,
+                status_code,
+                status_message,
+                span_type,
+                input_convert_func,
+                output_convert_func,
             )
             self._span_buffer[str(run.id)] = span
         # current span is the root span
         if self.trace is not None:
-            # Preserve the correct order of spans
+            # Preserve the correct order of spans sorting by start_time ASC
             self.trace["spans"] = sorted(
                 self._span_buffer.values(), key=lambda span: span.start_time
             )
-            self.trace["start_timestamp"] = self._span_buffer[str(run.id)].start_time
-            self.trace["end_timestamp"] = self._span_buffer[str(run.id)].end_time
+            # Save trace start/end_timestamp as datetime, so when it converts to json
+            # it can be saved as isoformat, further compatible with TimestampType in table schema
+            self.trace["start_timestamp"] = convert_nanoseconds_to_datetime(
+                self._span_buffer[str(run.id)].start_time
+            )
+            self.trace["end_timestamp"] = convert_nanoseconds_to_datetime(
+                self._span_buffer[str(run.id)].end_time
+            )
 
     @override
     def _on_run_create(self, run: Run) -> None:
         """
         Process a run upon creation.
         This is invoked inside _start_trace for each on_*_start method.
         We convert the run to a span and flush it to the span buffer in case
         any exception is raised before on_*_end or on_*_error is invoked.
         """
         if str(run.id) in self._span_buffer:
             raise Exception(
                 f"Internal Error: _on_run_create called twice for the same run {run.id}"
             )
         self._convert_span_and_flush(
-            run, Status(StatusCode.ERROR, "Span not completed")
+            run=run, status_code=StatusCode.ERROR, status_message="Span not completed"
         )
 
     @override
     def _on_llm_end(self, run: Run) -> None:
         """Process the LLM Run."""
         if str(run.id) not in self._span_buffer:
             raise Exception("Internal Error: on_llm_end called without on_llm_start")
         self._convert_span_and_flush(
-            run,
-            Status(StatusCode.OK),
+            run=run,
+            status_code=StatusCode.OK,
         )
 
     @override
     def _on_llm_error(self, run: Run) -> None:
         """Process the LLM Run upon error."""
         if str(run.id) not in self._span_buffer:
             raise Exception("Internal Error: on_llm_error called without on_llm_start")
         self._convert_span_and_flush(
-            run,
-            Status(StatusCode.ERROR, run.error),
+            run=run,
+            status_code=StatusCode.ERROR,
+            status_message=run.error,
         )
 
     @override
     def _on_retriever_end(self, run: Run) -> None:
         """Process the Retriever Run."""
         if str(run.id) not in self._span_buffer:
             raise Exception(
                 "Internal Error: on_retriever_end called without on_retriever_start"
             )
         self._convert_span_and_flush(
-            run,
-            Status(StatusCode.OK),
+            run=run,
+            status_code=StatusCode.OK,
         )
 
     @override
     def _on_retriever_error(self, run: Run) -> None:
         """Process the Retriever Run upon error."""
         if str(run.id) not in self._span_buffer:
             raise Exception(
                 "Internal Error: on_retriever_error called without on_retriever_start"
             )
-        self._convert_span_and_flush(run, Status(StatusCode.ERROR, run.error))
+        self._convert_span_and_flush(
+            run=run, status_code=StatusCode.ERROR, status_message=run.error
+        )
 
     @override
     def _on_chain_end(self, run: Run) -> None:
         """Process the Chain Run."""
         if str(run.id) not in self._span_buffer:
             raise Exception(
                 "Internal Error: on_chain_end called without on_chain_start"
             )
-        self._convert_span_and_flush(run, Status(StatusCode.OK), SpanType.CHAIN)
+        self._convert_span_and_flush(
+            run=run, status_code=StatusCode.OK, span_type=SpanType.CHAIN
+        )
 
     @override
     def _on_chain_error(self, run: Run) -> None:
         """Process the Chain Run upon error."""
         if str(run.id) not in self._span_buffer:
             raise Exception(
                 "Internal Error: on_chain_error called without on_chain_start"
             )
         self._convert_span_and_flush(
-            run, Status(StatusCode.ERROR, run.error), SpanType.CHAIN
+            run=run,
+            status_code=StatusCode.ERROR,
+            status_message=run.error,
+            span_type=SpanType.CHAIN,
         )
 
     @override
     def _on_tool_end(self, run: Run) -> None:
         """Process the Tool Run."""
         if str(run.id) not in self._span_buffer:
             raise Exception("Internal Error: on_tool_end called without on_tool_start")
-        self._convert_span_and_flush(run, Status(StatusCode.OK))
+        self._convert_span_and_flush(run=run, status_code=StatusCode.OK)
 
     @override
     def _on_tool_error(self, run: Run) -> None:
         """Process the Tool Run upon error."""
         if str(run.id) not in self._span_buffer:
             raise Exception(
                 "Internal Error: on_tool_error called without on_tool_start"
             )
-        self._convert_span_and_flush(run, Status(StatusCode.ERROR, run.error))
+        self._convert_span_and_flush(
+            run=run, status_code=StatusCode.ERROR, status_message=run.error
+        )
```

## databricks/rag/scoring/predictions.py

```diff
@@ -1,7 +1,8 @@
+import os
 import json
 import uuid
 from dataclasses import asdict, dataclass, field
 from datetime import datetime
 from typing import Any, Dict, List, Optional, Sequence
 from uuid import UUID
 
@@ -10,16 +11,17 @@
 from langchain_core.outputs import LLMResult
 from mlflow.langchain import _LangChainModelWrapper
 
 import databricks
 from databricks.rag import constants
 from databricks.rag.scoring.langchain_tracer import DatabricksLangChainTracer
 from databricks.rag.scoring.schema_v2 import Span
-from databricks.rag.unpacking import _rag_trace_v2_enabled
 
+def _rag_trace_v2_enabled():
+    return os.environ.get("RAG_TRACE_V2_ENABLED", "false").lower() == "true"
 
 # Note: This function needs to be where here so it can be accessed in the prediction module easily.
 # The code below adds the schema as global variables to the module so that it can be accessed
 # during tracing and in the review UI.
 def set_vector_search_schema(
     primary_key: str,
     text_column: Optional[str] = "",
```

## databricks/rag/scoring/schema_v2.py

```diff
@@ -3,129 +3,112 @@
 import json
 import uuid
 from dataclasses import asdict, dataclass, field
 from datetime import datetime
 from enum import Enum
 from typing import Any, Dict, List, Optional
 
+MLFLOW_TRACE_SCHEMA_VERSION = "mlflow.trace_schema.version"
+
 
 class StatusCode(str, Enum):
     OK = "OK"
     ERROR = "ERROR"
 
     def __str__(self) -> str:
         return str(self.value)
 
 
-@dataclass
-class Status:
-    """
-    Status of the trace or span.
-    """
-
-    status_code: StatusCode
-    description: str = ""
-
-    def json(self) -> Dict[str, str]:
-        return {
-            "status_code": str(self.status_code),
-            "description": self.description,
-        }
-
-
 class SpanType(str, Enum):
     """
     Default enum of span types
     """
 
     LLM = "LLM"
     CHAIN = "CHAIN"
     AGENT = "AGENT"
     TOOL = "TOOL"
-    CHAT_MODEL = "CHAT_MODEL"
     RETRIEVER = "RETRIEVER"
     EMBEDDING = "EMBEDDING"
     RERANKER = "RERANKER"
     PARSER = "PARSER"
     UNKNOWN = "UNKNOWN"
 
     def __str__(self) -> str:
         return str(self.value)
 
 
 def _dump_dictionary(d: Optional[Dict[str, Any]]) -> Optional[str]:
     if d is None:
         return None
+    # dump the whole dictionary to string for easier loading
     return json.dumps(d, cls=CustomEncoder)
 
 
 @dataclass
 class Span:
     """
     Span object.
     """
 
     name: str
     context: SpanContext
-    status: Status
-    span_type: str = SpanType.UNKNOWN.value
-    start_time: Optional[datetime] = None
-    end_time: Optional[datetime] = None
-    parent_span_id: Optional[str] = None
-    inputs: Optional[Dict[str, Any]] = None
-    outputs: Optional[Dict[str, Any]] = None
+    parent_id: Optional[str] = None
+    start_time: Optional[int] = None
+    end_time: Optional[int] = None
+    status_code: StatusCode = StatusCode.OK
+    status_message: str = ""
     attributes: Optional[Dict[str, Any]] = None
     events: Optional[List[Event]] = None
 
     def json(self) -> Dict[str, Any]:
         return {
             "name": self.name,
             "context": asdict(self.context),
-            "status": self.status.json(),
-            "span_type": str(self.span_type),
-            "start_time": self.start_time.isoformat() if self.start_time else None,
-            "end_time": self.end_time.isoformat() if self.end_time else None,
-            "parent_span_id": self.parent_span_id,
-            "inputs": _dump_dictionary(self.inputs),
-            "outputs": _dump_dictionary(self.outputs),
+            "parent_id": self.parent_id,
+            "start_time": self.start_time,
+            "end_time": self.end_time,
+            "status_code": str(self.status_code),
+            "status_message": self.status_message,
             "attributes": _dump_dictionary(self.attributes),
             "events": (
                 [event.json() for event in self.events] if self.events else None
             ),
         }
 
 
 @dataclass
 class SpanContext:
-    request_id: str = ""
     span_id: str = field(default_factory=lambda: str(uuid.uuid4()))
+    trace_id: str = ""
 
 
 @dataclass
 class Event:
     name: str
-    timestamp: datetime
+    timestamp: int
     attributes: Optional[Dict[str, Any]] = None
 
     def json(self):
         return {
             "name": self.name,
-            "timestamp": self.timestamp.isoformat(),
+            "timestamp": self.timestamp,
             "attributes": _dump_dictionary(self.attributes),
         }
 
 
 class CustomEncoder(json.JSONEncoder):
     """
     Custom encoder to handle json serialization.
     """
 
     def default(self, o):
+        # convert datetime to string format by default
         if isinstance(o, datetime):
             return o.isoformat()
         if isinstance(o, uuid.UUID):
             return str(o)
         try:
             return super().default(o)
-        # temp solution to avoid error in serialization
+        # convert object direct to string to avoid error in serialization
         except TypeError:
             return str(o)
```

## databricks/rag/unpacking/__init__.py

```diff
@@ -1,220 +1,11 @@
-import os
-from typing import Tuple
+"""
+NOTE: Code in this package will be deployed in the scoring server of the RAG Studio app.
+It is imperative that we keep the dependencies and imports of this package to a minimum
+in order to reduce the size of the model image being served by the endpoint.
 
-from databricks.rag.unpacking.schemas import (
-    ASSESSMENT_PROTO_SCHEMA,
-    CHOICES_SCHEMA,
-    MESSAGES_SCHEMA,
-    MLFLOW_TRACE_SCHEMA_VERSION,
-    RETRIEVAL_ASSESSMENT_TABLE_SCHEMA,
-    TEXT_ASSESSMENT_TABLE_SCHEMA,
-    TRACE_SCHEMA,
-    TRACE_V2_SCHEMA,
-)
-from pyspark.sql import DataFrame
-from pyspark.sql import functions as F
-from pyspark.sql import types as T
+Functionality for unpacking payloads generated by RAG endpoints.
+"""
 
+from databricks.rag.unpacking.unpack import unpack_and_split_payloads
 
-def _rag_trace_v2_enabled():
-    return os.environ.get("RAG_TRACE_V2_ENABLED", "false").lower() == "true"
-
-
-def _generate_request_logs_old(df: DataFrame) -> DataFrame:
-    request_payloads = df.filter(
-        F.expr(
-            f"response:databricks_output.trace['{MLFLOW_TRACE_SCHEMA_VERSION}'] IS NULL"
-        )
-    )
-    return (
-        request_payloads.withColumn(
-            "request",
-            F.struct(
-                F.col("databricks_request_id").alias("request_id"),
-                F.expr("request:databricks_options.conversation_id").alias(
-                    "conversation_id"
-                ),
-                F.col("timestamp"),
-                F.from_json(F.expr("request:messages"), MESSAGES_SCHEMA).alias(
-                    "messages"
-                ),
-                F.element_at(
-                    F.from_json(F.expr("request:messages"), MESSAGES_SCHEMA), -1
-                )
-                .getItem("content")
-                .alias("last_input"),
-            ),
-        )
-        .withColumn(
-            "trace",
-            F.from_json(F.expr("response:databricks_output.trace"), TRACE_SCHEMA),
-        )
-        .withColumn(
-            "output",
-            F.struct(
-                F.from_json(F.expr("response:choices"), CHOICES_SCHEMA).alias("choices")
-            ),
-        )
-        .select("request", "trace", "output")
-    )
-
-
-def _generate_request_logs_v2(df: DataFrame) -> DataFrame:
-    return (
-        df.withColumn(
-            "request",
-            F.struct(
-                F.col("databricks_request_id").alias("request_id"),
-                F.expr("request:databricks_options.conversation_id").alias(
-                    "conversation_id"
-                ),
-                F.col("timestamp"),
-                F.from_json(F.expr("request:messages"), MESSAGES_SCHEMA).alias(
-                    "messages"
-                ),
-                F.element_at(
-                    F.from_json(F.expr("request:messages"), MESSAGES_SCHEMA), -1
-                )
-                .getItem("content")
-                .alias("last_input"),
-            ),
-        )
-        .withColumn(
-            "trace",
-            F.from_json(F.expr("response:databricks_output.trace"), TRACE_V2_SCHEMA),
-        )
-        .withColumn(
-            "output",
-            F.struct(
-                F.from_json(F.expr("response:choices"), CHOICES_SCHEMA).alias("choices")
-            ),
-        )
-        .select("request", "trace", "output")
-    )
-
-
-def _generate_assessment_logs(payload_df: DataFrame) -> DataFrame:
-    assessment_payloads = payload_df.filter(F.expr("response:choices IS NULL"))
-    assessment_logs = (
-        assessment_payloads.withColumn(
-            "assessments",
-            F.explode(
-                F.from_json(
-                    F.expr("request:dataframe_records"), ASSESSMENT_PROTO_SCHEMA
-                )
-            ),
-        )
-        .withColumn(
-            "text_assessments",
-            # Transform the list of text assessments into a list of assessment structs (with empty
-            # retrieval assessments) so we can concatenate them before exploding.
-            # The ordering of the structs must match exactly to concatenate them.
-            F.transform(
-                F.col("assessments.text_assessments"),
-                lambda ta: F.struct(
-                    # Transform the proto ratings map (which only has a boolean value)
-                    # to the table ratings map (which has bool_value and double_value).
-                    F.struct(
-                        ta.step_id,
-                        F.transform_values(
-                            ta.ratings,
-                            lambda _, rating_val: F.struct(
-                                rating_val.value.alias("bool_value"),
-                                F.lit(None).cast(T.DoubleType()).alias("double_value"),
-                                rating_val.rationale,
-                            ),
-                        ).alias("ratings"),
-                        ta.free_text_comment,
-                        ta.suggested_output,
-                    ).alias("text_assessment"),
-                    F.lit(None)
-                    .cast(RETRIEVAL_ASSESSMENT_TABLE_SCHEMA)
-                    .alias("retrieval_assessment"),
-                ),
-            ),
-        )
-        .withColumn(
-            "retrieval_assessments",
-            # Transform the list of retrieval assessments into a list of assessment structs (with empty
-            # text assessments) so we can concatenate them before exploding.
-            # The ordering of the structs must match exactly to concatenate them.
-            F.transform(
-                F.col("assessments.retrieval_assessments"),
-                lambda ra: F.struct(
-                    F.lit(None)
-                    .cast(TEXT_ASSESSMENT_TABLE_SCHEMA)
-                    .alias("text_assessment"),
-                    # Transform the proto ratings map (which only has a boolean value)
-                    # to the table ratings map (which has bool_value and double_value).
-                    F.struct(
-                        ra.position,
-                        ra.step_id,
-                        F.transform_values(
-                            ra.ratings,
-                            lambda _, rating_val: F.struct(
-                                rating_val.value.alias("bool_value"),
-                                F.lit(None).cast(T.DoubleType()).alias("double_value"),
-                                rating_val.rationale,
-                            ),
-                        ).alias("ratings"),
-                        ra.free_text_comment,
-                    ).alias("retrieval_assessment"),
-                ),
-            ),
-        )
-        .withColumn(
-            "all_assessments",
-            F.explode(
-                F.concat(
-                    # Coalesce with an empty array to handle cases where only one of
-                    # text_assessments or retrieval_assessments were passed.
-                    F.coalesce(F.col("text_assessments"), F.array()),
-                    F.coalesce(F.col("retrieval_assessments"), F.array()),
-                )
-            ),
-        )
-        .select(
-            "assessments.request_id",
-            F.coalesce(
-                F.col("all_assessments.text_assessment.step_id"),
-                F.col("all_assessments.retrieval_assessment.step_id"),
-            ).alias("step_id"),
-            "assessments.source",
-            "timestamp",
-            "all_assessments.text_assessment",
-            "all_assessments.retrieval_assessment",
-        )
-    )
-    return assessment_logs
-
-
-def _generate_request_logs(payload_df: DataFrame) -> DataFrame:
-    request_payloads = payload_df.filter(F.expr("response:choices IS NOT NULL"))
-    request_payloads_v2 = request_payloads.filter(
-        F.expr(f"response:databricks_output.trace['{MLFLOW_TRACE_SCHEMA_VERSION}']==2")
-    )
-
-    if _rag_trace_v2_enabled() and not request_payloads_v2.isEmpty():
-        return _generate_request_logs_v2(request_payloads_v2)
-
-    return _generate_request_logs_old(request_payloads)
-
-
-def unpack_and_split_payloads(payload_df: DataFrame) -> Tuple[DataFrame, DataFrame]:
-    """
-    Unpacks the request and assessment payloads from the given DataFrame
-    and splits them into separate request log and assessment log DataFrames.
-    :param payload_df: A DataFrame containing payloads to unpack and split
-    :return: A tuple containing (request logs DataFrame, assessment logs DataFrame)
-    """
-    payloads = payload_df.filter(
-        F.col("status_code") == "200"
-    ).withColumn(  # Ignore error requests
-        "timestamp", (F.col("timestamp_ms") / 1000).cast("timestamp")
-    )
-
-    # Split the payloads into requests and assessments based on the payload structure
-    request_logs = _generate_request_logs(payloads)
-    assessment_logs = _generate_assessment_logs(payloads)
-
-    return request_logs, assessment_logs
+__all__ = ["unpack_and_split_payloads"]
```

## databricks/rag/unpacking/schemas.py

```diff
@@ -6,15 +6,14 @@
 APP_VERSION_ID = "app_version_id"
 START_TIMESTAMP = "start_timestamp"
 END_TIMESTAMP = "end_timestamp"
 IS_TRUNCATED = "is_truncated"
 CHUNKS = "chunks"
 MLFLOW_TRACE_SCHEMA_VERSION = "mlflow.trace_schema.version"
 
-
 ######################################################################
 # Request log schema definitions
 ######################################################################
 
 # Format of the conversation following the OpenAI messages format.
 MESSAGE_SCHEMA = T.StructType(
     [
@@ -96,47 +95,38 @@
         ),
     ]
 )
 
 ######################################################################
 # V2 trace schema definitions
 ######################################################################
-STATUS_SCHEMA = T.StructType(
-    [
-        T.StructField("status_code", T.StringType(), False),
-        T.StructField("description", T.StringType(), True),
-    ]
-)
-
 SPAN_CONTEXT_SCHEMA = T.StructType(
     [
-        T.StructField("request_id", T.StringType(), False),
         T.StructField("span_id", T.StringType(), False),
+        T.StructField("trace_id", T.StringType(), True),
     ]
 )
 
 EVENT_SCHEMA = T.StructType(
     [
         T.StructField("name", T.StringType(), False),
-        T.StructField("timestamp", T.TimestampType(), False),
+        T.StructField("timestamp", T.LongType(), False),
         T.StructField("attributes", T.StringType(), True),
     ]
 )
 
 SPAN_SCHEMA = T.StructType(
     [
         T.StructField("name", T.StringType(), False),
         T.StructField("context", SPAN_CONTEXT_SCHEMA, False),
-        T.StructField("span_type", T.StringType(), False),
-        T.StructField("start_time", T.TimestampType(), True),
-        T.StructField("end_time", T.TimestampType(), True),
-        T.StructField("status", STATUS_SCHEMA, False),
-        T.StructField("parent_span_id", T.StringType(), True),
-        T.StructField("inputs", T.StringType(), True),
-        T.StructField("outputs", T.StringType(), True),
+        T.StructField("parent_id", T.StringType(), True),
+        T.StructField("start_time", T.LongType(), False),
+        T.StructField("end_time", T.LongType(), True),
+        T.StructField("status_code", T.StringType(), False),
+        T.StructField("status_message", T.StringType(), False),
         T.StructField("attributes", T.StringType(), True),
         T.StructField("events", T.ArrayType(EVENT_SCHEMA), True),
     ]
 )
 
 # Schema of the "trace" field in the final request logs table.
 TRACE_V2_SCHEMA = T.StructType(
@@ -149,20 +139,25 @@
         T.StructField("spans", T.ArrayType(SPAN_SCHEMA)),
     ]
 )
 
 # Full schema of the final request logs table.
 REQUEST_LOG_V2_SCHEMA = T.StructType(
     [
+        T.StructField("request_id", T.StringType()),
+        T.StructField("timestamp", T.TimestampType()),
+        T.StructField("app_version_id", T.StringType()),
+        T.StructField("last_request_input", T.StringType()),
+        T.StructField("response_output", T.StringType()),
         T.StructField("request", REQUEST_SCHEMA),
-        T.StructField("trace", TRACE_V2_SCHEMA),
         T.StructField(
             "output",
             T.StructType([T.StructField("choices", CHOICES_SCHEMA)]),
         ),
+        T.StructField("trace", TRACE_V2_SCHEMA),
     ]
 )
 
 ######################################################################
 # Assessment log schema definitions
 ######################################################################
 
@@ -224,15 +219,14 @@
             T.StructField(
                 "retrieval_assessments", T.ArrayType(RETRIEVAL_ASSESSMENT_PROTO_SCHEMA)
             ),
         ]
     )
 )
 
-
 ##################### Table schema definitions #######################
 RATING_VALUE_TABLE_SCHEMA = T.StructType(
     [
         T.StructField("bool_value", T.BooleanType()),
         T.StructField("double_value", T.DoubleType()),
         T.StructField("rationale", T.StringType()),
     ]
```

## databricks/rag_studio/__init__.py

```diff
@@ -1,21 +1,28 @@
 from databricks.rag_studio.chain_logging import log_model
 from databricks.rag_studio.deployments import (
     deploy_model,
     get_deployments,
     list_deployments,
 )
-from databricks.rag_studio.permissions import set_permissions
-from databricks.rag_studio.reviews import enable_trace_reviews
+from databricks.rag_studio.permissions import set_permissions, get_permissions
+from databricks.rag_studio.reviews import (
+    enable_trace_reviews,
+    set_review_instructions,
+    get_review_instructions,
+)
 from databricks.rag_studio.version import VERSION as __version__
 from databricks.rag_studio.sdk_utils.entities import PermissionLevel
 
 __all__ = [
     "log_model",
     "deploy_model",
     "get_deployments",
     "list_deployments",
     "set_permissions",
+    "get_permissions",
     "enable_trace_reviews",
+    "set_review_instructions",
+    "get_review_instructions",
     "__version__",
     "PermissionLevel",
 ]
```

## databricks/rag_studio/chain_logging.py

```diff
@@ -8,15 +8,15 @@
 from contextlib import contextmanager
 from mlflow.models import ModelSignature
 from mlflow.models.model import ModelInfo
 from mlflow.types import DataType
 from mlflow.types.schema import Schema, ColSpec, Object, Array, Property
 from databricks.sdk import WorkspaceClient
 from databricks.sdk.service.workspace import ExportFormat
-from databricks.rag.version import VERSION
+from databricks.rag.version import VERSION as RAG_SERVING_VERSION
 
 
 def _is_in_comment(line, start):
     """
     Check if the code at the index "start" of the line is in a comment.
 
     Limitations: This function does not handle multi-line comments, and the # symbol could be in a
@@ -237,19 +237,25 @@
                 "config.yml", yaml.dump(config), "w"
             )
         else:
             raise ValueError(
                 f"Invalid argument type for config {config}. Must be a file path or a dictionary"
             )
 
-    if not os.path.exists(code_path) or not isinstance(code_path, str):
-        raise ValueError(f"Chain file {code_path} does not exist")
+    if not isinstance(code_path, str):
+        raise ValueError(f"Chain file {code_path} does not exist.")
+
+    chain_path = os.path.abspath(code_path)
+    if not os.path.exists(chain_path):
+        raise ValueError(
+            f"Specified chain file {code_path} resolved to full path {chain_path} does not exist."
+        )
 
     with _start_run_or_reuse_active_run():
-        desired_chain_path = _get_code(code_path)
+        desired_chain_path = _get_code(chain_path)
         input_example = {
             "messages": [
                 {
                     "role": "user",
                     "content": "What is Retrieval-augmented Generation?",
                 }
             ]
@@ -288,14 +294,14 @@
             artifact_path="chain",
             pip_requirements=[
                 f"mlflow=={mlflow.__version__}",
                 f"langchain=={langchain.__version__}",
                 f"langchain-core=={langchain_core.__version__}",
                 f"langchain-community=={langchain_community.__version__}",
                 f"databricks-vectorsearch=={databricks.vector_search.__version__}",
-                f"https://ml-team-public-read.s3.us-west-2.amazonaws.com/wheels/rag-serving/uqr082kj-3c87-40b1-b04c-bb1977254aa3/databricks_rag_serving-{VERSION}-py3-none-any.whl",
+                f"https://ml-team-public-read.s3.us-west-2.amazonaws.com/wheels/rag-serving/uqr082kj-3c87-40b1-b04c-bb1977254aa3/databricks_rag_serving-{RAG_SERVING_VERSION}-py3-none-any.whl",
             ],
             signature=signature,
             input_example=input_example,
             example_no_conversion=True,
             code_paths=[config_path] if config_path else [],
         )
```

## databricks/rag_studio/permissions.py

```diff
@@ -1,7 +1,8 @@
+from dataclasses import dataclass
 import re
 
 from typing import List, Optional, Tuple
 from databricks.rag_studio.sdk_utils.entities import PermissionLevel
 from databricks.rag_studio.sdk_utils.deployments import _get_deployments
 from databricks.rag_studio.client.rest_client import (
     get_review_artifacts as rest_get_review_artifacts,
@@ -19,14 +20,38 @@
     ServingEndpointPermissions,
 )
 from databricks.sdk.service.workspace import (
     WorkspaceObjectPermissionLevel,
     WorkspaceObjectPermissions,
     WorkspaceObjectAccessControlRequest,
 )
+from mlflow import get_experiment
+
+_MLFLOW_EXPERIMENT_TYPE_TAG = "mlflow.experimentType"
+_MLFLOW_EXPERIMENT_TYPE_VALUE = "MLFLOW_EXPERIMENT"
+_NOTEBOOK_EXPERIMENT_TYPE_VALUE = "NOTEBOOK"
+
+
+@dataclass
+class UserPermissionInfo:
+    user_type: str
+    user_name: str
+    permission_level: PermissionLevel
+
+    def _to_dict(self):
+        return {
+            self.user_type: self.user_name,
+            "permission_level": self.permission_level.value,
+        }
+
+    def to_experiment_permissions_object(self):
+        return WorkspaceObjectAccessControlRequest.from_dict(self._to_dict())
+
+    def to_serving_endpoint_permissions_object(self):
+        return ServingEndpointAccessControlRequest.from_dict(self._to_dict())
 
 
 def _get_run_ids_from_artifact_uris(artifact_uris: List[str]) -> List[str]:
     return [
         re.search(r"runs:/(.*?)/.*", artifact_id).group(1)
         for artifact_id in artifact_uris
     ]
@@ -71,20 +96,25 @@
     permissions = _call_workspace_api(
         w.serving_endpoints.get_permissions, {"serving_endpoint_id": endpoint_id}
     )
     return permissions
 
 
 # Get permissions on a given experiment
-# TODO: Handle a normal experiment as well (ML-39642)
-def _get_permissions_on_experiment(experiment_id: str) -> WorkspaceObjectPermissions:
+def _get_permissions_on_experiment(
+    experiment_id: str,
+    experiment_type: str,
+) -> WorkspaceObjectPermissions:
     w = WorkspaceClient()
     permissions = _call_workspace_api(
         w.workspace.get_permissions,
-        {"workspace_object_type": "notebooks", "workspace_object_id": experiment_id},
+        {
+            "workspace_object_type": experiment_type,
+            "workspace_object_id": experiment_id,
+        },
     )
     return permissions
 
 
 # Given a Permissions Object, and a list of users returns new permissions without the users
 def _remove_users_from_permissions_list(permissions, users):
     user_set = set(users)
@@ -92,23 +122,28 @@
     modified_acls = list(filter(lambda acl: acl.user_name not in user_set, acls))
     # No Changes as the user has no permissions on the endpoint
     if len(modified_acls) == len(acls):
         return None
     new_permissions = []
     for acl in modified_acls:
         for permission in acl.all_permissions:
-            user = ()
             # "user_name", "group_name" and "service_principal_name" are all keywords used by the permission API later
             if acl.user_name is not None:
-                user = ("user_name", acl.user_name)
+                user_type = "user_name"
+                user_name = acl.user_name
             elif acl.group_name is not None:
-                user = ("group_name", acl.group_name)
+                user_type = "group_name"
+                user_name = acl.group_name
             else:
-                user = ("service_principal_name", acl.service_principal_name)
-            new_permissions.append((user, permission.permission_level))
+                user_type = "service_principal_name"
+                user_name = acl.service_principal_name
+
+            new_permissions.append(
+                UserPermissionInfo(user_type, user_name, permission.permission_level)
+            )
     return new_permissions
 
 
 # For a given a chain model name get all logged trace artifacts and return the corresponding experiment IDs
 def _get_experiment_ids_from_trace_artifacts(model_name: str) -> List[str]:
     ml_artifacts = rest_get_review_artifacts(model_name)
     experiment_ids = _get_experiment_ids(
@@ -117,61 +152,49 @@
     return experiment_ids
 
 
 # Sets permissions on an endoint for the list of users
 # Permissions is of type [((User_type, username), PermissionLevel)]
 def _set_permissions_on_endpoint(
     endpoint_id: str,
-    permissions: List[Tuple[Tuple[str, str], ServingEndpointPermissionLevel]],
+    permissions: List[UserPermissionInfo],
 ):
     if permissions is None:
         return
     acls = []
-    for users, permission_level in permissions:
-        user_type, user = users
-        acls.append(
-            ServingEndpointAccessControlRequest.from_dict(
-                {user_type: user, "permission_level": permission_level.value}
-            )
-        )
-    # NOTE: THIS SHOULD ONLY BE CALLED ONCE
-    # This endpoint performs a complete overwrite and should not be called more than once
+    for permission in permissions:
+        acls.append(permission.to_serving_endpoint_permissions_object())
+    # NOTE: this function will overwrite all permissions for the endpoint
     w = WorkspaceClient()
     _call_workspace_api(
         w.serving_endpoints.set_permissions,
         {
             "serving_endpoint_id": endpoint_id,
             "access_control_list": acls,
         },
     )
 
 
 # Sets permission on experiment
-# Permissions is of type [((User_type, username), PermissionLevel)]
 def _set_permissions_on_experiment(
     experiment_id: str,
-    permissions: List[Tuple[Tuple[str, str], ServingEndpointPermissionLevel]],
+    experiment_type: str,
+    permissions: List[UserPermissionInfo],
 ):
     if permissions is None:
         return
     acls = []
-    for users, permission_level in permissions:
-        user_type, user = users
-        acls.append(
-            WorkspaceObjectAccessControlRequest.from_dict(
-                {user_type: user, "permission_level": permission_level.value}
-            )
-        )
-    # NOTE: THIS SHOULD ONLY BE CALLED ONCE
-    # This endpoint performs a complete overwrite and should not be called more than once
+    for permission in permissions:
+        acls.append(permission.to_experiment_permissions_object())
+    # NOTE: this function will overwrite all permissions for the experiment
     w = WorkspaceClient()
     _call_workspace_api(
         w.workspace.set_permissions,
         {
-            "workspace_object_type": "notebooks",
+            "workspace_object_type": experiment_type,
             "workspace_object_id": experiment_id,
             "access_control_list": acls,
         },
     )
 
 
 # Update Permissions on Endpoint
@@ -191,26 +214,27 @@
                 )
                 for user in users
             ],
         },
     )
 
 
-# Update Permissions on Experiment
 def _update_permissions_on_experiment(
-    experiment_ids: str,
+    experiment_ids: List[str],
     users: List[str],
+    experiment_type: str,
     permission_level: Optional[WorkspaceObjectPermissionLevel] = None,
 ):
+    # NOTE: all experiments must be of the same type (notebooks vs mlflow experiments)
     w = WorkspaceClient()
     for experiment_id in experiment_ids:
         _call_workspace_api(
             w.workspace.update_permissions,
             {
-                "workspace_object_type": "notebooks",
+                "workspace_object_type": experiment_type,
                 "workspace_object_id": experiment_id,
                 "access_control_list": [
                     WorkspaceObjectAccessControlRequest(
                         user_name=user,
                         permission_level=permission_level,
                     )
                     for user in users
@@ -236,26 +260,42 @@
     permissions = _get_permissions_on_endpoint(endpoint_id)
     # Filter permissions list such that users in `clear_users` do not have any permissions.
     new_permissions = _remove_users_from_permissions_list(permissions, clear_users)
     # Re sets the permissions for the remaining users
     _set_permissions_on_endpoint(endpoint_id, new_permissions)
 
 
-def _clear_permissions_for_user_experiments(
-    experiment_ids: List[str], clear_users: List[str]
+def _clear_permission_for_experiments(
+    experiment_ids: List[str], clear_users: List[str], experiment_type: str
 ):
+    # NOTE: all experiments must be of the same type (notebooks vs mlflow experiments)
     for experiment_id in experiment_ids:
         # Retrieves all the permissions in the experiment. Returned list is permission level mapping for all users
-        experiment_permissions = _get_permissions_on_experiment(experiment_id)
+        experiment_permissions = _get_permissions_on_experiment(
+            experiment_id, experiment_type
+        )
         # Filter permissions list such that users in `clear_users` do not have any permissions.
         new_permissions = _remove_users_from_permissions_list(
             experiment_permissions, clear_users
         )
         # Re sets the permisssions for the remaining users
-        _set_permissions_on_experiment(experiment_id, new_permissions)
+        _set_permissions_on_experiment(experiment_id, experiment_type, new_permissions)
+
+
+def _filter_experiments_by_type(experiment_ids: List[str]):
+    mlflow_experiment_ids = []
+    notebook_experiment_ids = []
+    for experiment_id in experiment_ids:
+        experiment = get_experiment(experiment_id)
+        experiment_type = experiment.tags.get(_MLFLOW_EXPERIMENT_TYPE_TAG)
+        if experiment_type == _NOTEBOOK_EXPERIMENT_TYPE_VALUE:
+            notebook_experiment_ids.append(experiment_id)
+        elif experiment_type == _MLFLOW_EXPERIMENT_TYPE_VALUE:
+            mlflow_experiment_ids.append(experiment_id)
+    return notebook_experiment_ids, mlflow_experiment_ids
 
 
 def set_permissions(
     model_name: str,
     users: List[str],
     permission_level: PermissionLevel,
 ):
@@ -296,24 +336,178 @@
         elif permission_level == PermissionLevel.CAN_MANAGE:
             _update_permissions_on_endpoint(
                 endpoint_id, users, ServingEndpointPermissionLevel.CAN_MANAGE
             )
 
     # Set permissions on Experiments if necessary
     experiment_ids = _get_experiment_ids_from_trace_artifacts(model_name)
+
+    # filter experiments into notebook and mlflow experiments
+    # NOTE: we will eventually remove notebook experiment handling.
+    notebook_experiment_ids, mlflow_experiment_ids = _filter_experiments_by_type(
+        experiment_ids
+    )
+
     if permission_level == PermissionLevel.NO_PERMISSIONS:
-        _clear_permissions_for_user_experiments(experiment_ids, users)
+        _clear_permission_for_experiments(notebook_experiment_ids, users, "notebooks")
+        _clear_permission_for_experiments(mlflow_experiment_ids, users, "experiments")
     elif permission_level == PermissionLevel.CAN_VIEW:
         # If the user previously had any permissions on the experiment delete them
-        _clear_permissions_for_user_experiments(experiment_ids, users)
+        _clear_permission_for_experiments(notebook_experiment_ids, users, "notebooks")
+        _clear_permission_for_experiments(mlflow_experiment_ids, users, "experiments")
     elif permission_level == PermissionLevel.CAN_QUERY:
         # If the user previously had any permissions on the experiment delete them
-        _clear_permissions_for_user_experiments(experiment_ids, users)
+        _clear_permission_for_experiments(notebook_experiment_ids, users, "notebooks")
+        _clear_permission_for_experiments(mlflow_experiment_ids, users, "experiments")
     elif permission_level == PermissionLevel.CAN_REVIEW:
         _update_permissions_on_experiment(
-            experiment_ids, users, WorkspaceObjectPermissionLevel.CAN_READ
+            notebook_experiment_ids,
+            users,
+            "notebooks",
+            WorkspaceObjectPermissionLevel.CAN_READ,
+        )
+        _update_permissions_on_experiment(
+            mlflow_experiment_ids,
+            users,
+            "experiments",
+            WorkspaceObjectPermissionLevel.CAN_READ,
         )
     elif permission_level == PermissionLevel.CAN_MANAGE:
         # If the user previously had any permissions on the experiment delete them
         _update_permissions_on_experiment(
-            experiment_ids, users, WorkspaceObjectPermissionLevel.CAN_READ
+            notebook_experiment_ids,
+            users,
+            "notebooks",
+            WorkspaceObjectPermissionLevel.CAN_MANAGE,
+        )
+        _update_permissions_on_experiment(
+            mlflow_experiment_ids,
+            users,
+            "experiments",
+            WorkspaceObjectPermissionLevel.CAN_MANAGE,
         )
+
+
+# Constants for permission mappings for comparison
+WORKSPACE_PERMISSION_LEVEL_MAPPING = {
+    WorkspaceObjectPermissionLevel.CAN_READ: 0,
+    WorkspaceObjectPermissionLevel.CAN_RUN: 1,
+    WorkspaceObjectPermissionLevel.CAN_EDIT: 2,
+    WorkspaceObjectPermissionLevel.CAN_MANAGE: 3,
+}
+
+SERVING_ENDPOINT_PERMISSION_LEVEL_MAPPING = {
+    ServingEndpointPermissionLevel.CAN_VIEW: 0,
+    ServingEndpointPermissionLevel.CAN_QUERY: 1,
+    ServingEndpointPermissionLevel.CAN_MANAGE: 2,
+}
+
+
+def _aggregate_permissions(ids, get_permissions_func, permission_mapping):
+    """Aggregate minimum permissions given multiple ids, maintaining usage of specific getters. Returns mapping of user name to the user's minimum permission as a numerical constant.
+    - ids: list of ids to aggregate permissions over
+    - get_permissions_func: takes in an id and returns permissions for that id
+    - permission_mapping: dict mapping permission level to a numerical constant
+    """
+    min_permissions = {}
+    for item_id in ids:
+        permissions = get_permissions_func(item_id)
+        for acl in permissions.access_control_list:
+            current_perm = min_permissions.get(acl.user_name, float("inf"))
+            user_permissions = [
+                permission_mapping.get(p.permission_level, float("inf"))
+                for p in acl.all_permissions
+            ]
+            min_permissions[acl.user_name] = min(current_perm, *user_permissions)
+    return min_permissions
+
+
+def _derive_combined_permission_level(endpoint_perm, experiment_perm):
+    """Derive a combined permission level from endpoint and experiment permissions.
+    NO_PERMISSIONS -> no permission on endpoints
+    CAN_VIEW -> ServingEndpointPermissionLevel.CAN_VIEW on endpoints
+    CAN_QUERY -> ServingEndpointPermissionLevel.CAN_QUERY on endpoints
+    CAN_REVIEW -> ServingEndpointPermissionLevel.CAN_QUERY (or higher) on endpoints and WorkspaceObjectPermissionLevel.CAN_READ (or higher) on experiments
+    CAN_MANAGE -> ServingEndpointPermissionLevel.CAN_MANAGE (or higher) on endpoints and WorkspaceObjectPermissionLevel.CAN_READ (or higher) on experiments
+    """
+
+    if (
+        endpoint_perm
+        == SERVING_ENDPOINT_PERMISSION_LEVEL_MAPPING[
+            ServingEndpointPermissionLevel.CAN_MANAGE
+        ]
+        and experiment_perm
+        >= WORKSPACE_PERMISSION_LEVEL_MAPPING[WorkspaceObjectPermissionLevel.CAN_READ]
+    ):
+        return PermissionLevel.CAN_MANAGE
+    if (
+        endpoint_perm
+        >= SERVING_ENDPOINT_PERMISSION_LEVEL_MAPPING[
+            ServingEndpointPermissionLevel.CAN_QUERY
+        ]
+        and experiment_perm
+        >= WORKSPACE_PERMISSION_LEVEL_MAPPING[WorkspaceObjectPermissionLevel.CAN_READ]
+    ):
+        return PermissionLevel.CAN_REVIEW
+    if (
+        endpoint_perm
+        == SERVING_ENDPOINT_PERMISSION_LEVEL_MAPPING[
+            ServingEndpointPermissionLevel.CAN_QUERY
+        ]
+    ):
+        return PermissionLevel.CAN_QUERY
+    if (
+        endpoint_perm
+        == SERVING_ENDPOINT_PERMISSION_LEVEL_MAPPING[
+            ServingEndpointPermissionLevel.CAN_VIEW
+        ]
+    ):
+        return PermissionLevel.CAN_VIEW
+    return PermissionLevel.NO_PERMISSIONS
+
+
+def get_permissions(model_name: str) -> List[Tuple[str, PermissionLevel]]:
+    """Compute combined minimum permissions for endpoints and experiments associated with a model."""
+    # Fetch endpoints and experiments
+    endpoint_ids = _get_endpoint_id_for_deployed_model(model_name)
+    experiment_ids = _get_experiment_ids_from_trace_artifacts(model_name)
+    notebook_ids, mlflow_ids = _filter_experiments_by_type(experiment_ids)
+
+    # Get minimum permissions for each type
+    min_endpoint_permissions = _aggregate_permissions(
+        endpoint_ids,
+        _get_permissions_on_endpoint,
+        SERVING_ENDPOINT_PERMISSION_LEVEL_MAPPING,
+    )
+    min_notebook_permissions = _aggregate_permissions(
+        notebook_ids,
+        lambda x: _get_permissions_on_experiment(x, "notebooks"),
+        WORKSPACE_PERMISSION_LEVEL_MAPPING,
+    )
+    min_mlflow_permissions = _aggregate_permissions(
+        mlflow_ids,
+        lambda x: _get_permissions_on_experiment(x, "experiments"),
+        WORKSPACE_PERMISSION_LEVEL_MAPPING,
+    )
+
+    # Combine notebook and MLflow experiment permissions
+    min_experiment_permissions = {}
+    for user, perm in {**min_notebook_permissions, **min_mlflow_permissions}.items():
+        min_experiment_permissions[user] = min(
+            min_experiment_permissions.get(user, float("inf")), perm
+        )
+
+    # Combine and evaluate overall permissions
+    combined_permissions = {}
+    all_users = set(min_endpoint_permissions.keys()).union(
+        min_experiment_permissions.keys()
+    )
+    for user in all_users:
+        endpoint_perm_level = min_endpoint_permissions.get(user, -1)
+        experiment_perm_level = min_experiment_permissions.get(user, -1)
+
+        # Derive combined permission level
+        combined_permissions[user] = _derive_combined_permission_level(
+            endpoint_perm_level, experiment_perm_level
+        )
+
+    return list(combined_permissions.items())
```

## databricks/rag_studio/reviews.py

```diff
@@ -2,70 +2,23 @@
 import mlflow
 from databricks.rag_studio.sdk_utils.permissions_checker import (
     _check_manage_permissions_on_deployment,
 )
 from databricks.rag_studio.client.rest_client import (
     get_chain_deployments as rest_get_chain_deployments,
     create_review_artifacts as rest_create_review_artifacts,
+    set_review_instructions as rest_set_review_instructions,
+    get_review_instructions as rest_get_review_instructions,
 )
 from databricks.sdk import WorkspaceClient
+from databricks.rag.unpacking import unpack_and_split_payloads
 
 _TRACES_FILE_PATH = "traces.json"
 
 
-def _convert_inference_table_to_tracing_schema(request_payloads):
-    """
-    Convert the inference table to the schema required for tracing
-    """
-    from pyspark.sql import functions as F
-    from databricks.rag_studio.sdk_utils.schemas import (
-        MESSAGES_SCHEMA,
-        CHOICES_SCHEMA,
-        TRACE_SCHEMA,
-    )
-
-    changed_request_payloads = request_payloads.filter(
-        F.expr("response:choices IS NOT NULL")
-    ).withColumn(  # Ignore error requests
-        "timestamp", (F.col("timestamp_ms") / 1000).cast("timestamp")
-    )
-
-    return (
-        changed_request_payloads.withColumn(
-            "request",
-            F.struct(
-                F.col("databricks_request_id").alias("request_id"),
-                F.expr("request:databricks_options.conversation_id").alias(
-                    "conversation_id"
-                ),
-                F.col("timestamp"),
-                F.from_json(F.expr("request:messages"), MESSAGES_SCHEMA).alias(
-                    "messages"
-                ),
-                F.element_at(
-                    F.from_json(F.expr("request:messages"), MESSAGES_SCHEMA), -1
-                )
-                .getItem("content")
-                .alias("last_input"),
-            ),
-        )
-        .withColumn(
-            "trace",
-            F.from_json(F.expr("response:databricks_output.trace"), TRACE_SCHEMA),
-        )
-        .withColumn(
-            "output",
-            F.struct(
-                F.from_json(F.expr("response:choices"), CHOICES_SCHEMA).alias("choices")
-            ),
-        )
-        .select("request", "trace", "output")
-    )
-
-
 def _get_table_name(auto_capture_config):
     catalog_name = auto_capture_config.catalog_name
     schema_name = auto_capture_config.schema_name
     table_name = auto_capture_config.state.payload_table.name
     return f"`{catalog_name}`.`{schema_name}`.`{table_name}`"
 
 
@@ -90,14 +43,31 @@
             f"The provided {model_name} doesn't have any inference table configured. "
             "Please update the endpoint to capture payloads to an inference table"
         )
 
     return _get_table_name(auto_capture_config)
 
 
+def _generate_review_experiment_name(model_name):
+    w = WorkspaceClient()
+    current_user = w.current_user.me().user_name
+    return f"/Users/{current_user}/rag_studio_reviews_{model_name}"
+
+
+def _check_manage_permissions_for_chain_deployments(model_name, chain_deployments):
+    for deployment in chain_deployments:
+        _check_manage_permissions_on_deployment(deployment)
+    
+    if len(chain_deployments) == 0:
+        raise ValueError(
+            f"The provided {model_name} has never been deployed. "
+            "Please deploy the model first using deploy_chain API"
+        )
+
+
 def enable_trace_reviews(
     model_name: str, request_ids: Optional[List[str]] = None
 ) -> str:
     """
     Enable the reviewer UI to collect feedback on the conversations from the endpoint inference log.
 
     :param model_name: The name of the UC Registered Model to use when
@@ -116,24 +86,16 @@
     enable_trace_reviews(
         model_name="catalog.schema.chain_model",
         request_ids=["490cf09b-6da6-474f-bc35-ee5ca688ff8", "a4d37810-5cd0-4cbd-aa25-e5ceaf6a448"],
     )
     ```
     """
     chain_deployments = rest_get_chain_deployments(model_name)
-    _ = [
-        _check_manage_permissions_on_deployment(deployment)
-        for deployment in chain_deployments
-    ]
+    _check_manage_permissions_for_chain_deployments(model_name, chain_deployments)
 
-    if len(chain_deployments) == 0:
-        raise ValueError(
-            f"The provided {model_name} has never been deployed. "
-            "Please deploy the model first using deploy_chain API"
-        )
     chain_deployment = chain_deployments[-1]
     serving_endpoint_name = chain_deployment.endpoint_name
     table_full_name = _get_inference_table_from_serving(
         model_name, serving_endpoint_name
     )
 
     if request_ids:
@@ -144,20 +106,77 @@
         sql_query = f"SELECT * FROM {table_full_name}"
 
     from pyspark.sql import SparkSession
 
     spark = SparkSession.builder.getOrCreate()
     try:
         spark_df = spark.sql(sql_query)
-        converted_spark_df = _convert_inference_table_to_tracing_schema(spark_df)
+        converted_spark_df, _ = unpack_and_split_payloads(spark_df)
         df = converted_spark_df.toPandas()
     except Exception as e:
         raise ValueError(
             f"Failed to fetch the data from the table {table_full_name}. Error: {str(e)}"
         ) from e
 
-    with mlflow.start_run() as model_run:
+    review_experiment_name = _generate_review_experiment_name(model_name)
+    # get or create the review experiment
+    review_experiment = mlflow.get_experiment_by_name(review_experiment_name)
+    if review_experiment:
+        review_experiment_id = review_experiment.experiment_id
+    else:
+        review_experiment_id = mlflow.create_experiment(review_experiment_name)
+
+    with mlflow.start_run(experiment_id=review_experiment_id) as model_run:
         mlflow.log_table(data=df, artifact_file=_TRACES_FILE_PATH)
         artifact_uri = f"runs:/{model_run.info.run_id}/{_TRACES_FILE_PATH}"
         rest_create_review_artifacts(model_name, artifacts=[artifact_uri])
 
     return chain_deployment.rag_app_url
+
+
+def set_review_instructions(model_name: str, instructions: str) -> None:
+    """
+    Set the instructions for the review UI.
+
+    :param model_name: The name of the UC Registered Model to use when
+                registering the chain as a UC Model Version.
+                Example: catalog.schema.model_name
+    :param instructions: Instructions for the reviewer UI in markdown format
+
+    Example:
+    ```
+    from databricks.rag_studio import set_review_instructions
+
+    set_review_instructions(
+        model_name="catalog.schema.chain_model",
+        instructions="Please provide feedback on the conversations based on your knowledge of UC."
+    )
+    ```
+    """
+    chain_deployments = rest_get_chain_deployments(model_name)
+    _check_manage_permissions_for_chain_deployments(model_name, chain_deployments)
+
+    rest_set_review_instructions(model_name, instructions)
+
+
+def get_review_instructions(model_name: str) -> str:
+    """
+    Get the instructions for the review UI.
+
+    :param model_name: The name of the UC Registered Model to use when
+                registering the chain as a UC Model Version.
+                Example: catalog.schema.model_name
+
+    :return: Instructions for the reviewer UI in markdown format
+
+    Example:
+    ```
+    from databricks.rag_studio import get_review_instructions
+
+    instructions = get_review_instructions(model_name="catalog.schema.chain_model")
+    print(instructions)
+    ```
+    """
+    chain_deployments = rest_get_chain_deployments(model_name)
+    _check_manage_permissions_for_chain_deployments(model_name, chain_deployments)
+
+    return rest_get_review_instructions(model_name)
```

## databricks/rag_studio/version.py

```diff
@@ -1,2 +1,2 @@
 # Update this when publishing a new version
-VERSION = "0.0.3"
+VERSION = "0.1.0"
```

## databricks/rag_studio/client/rest_client.py

```diff
@@ -1,10 +1,10 @@
 from typing import List, Optional
 from databricks.rag_studio.utils.rest_utils import call_endpoint
-from databricks.rag_studio.sdk_utils.entities import Deployment, Artifacts
+from databricks.rag_studio.sdk_utils.entities import Deployment, Artifacts, Instructions
 
 
 def _construct_chain_deployment(chain_deployment: dict) -> Deployment:
     # ToDo (ML-39446): Use automatic proto to py object conversion
     # Do not surface error to user if the backend return missing fields
     return Deployment(
         model_name=chain_deployment.get("model_name", None),
@@ -107,7 +107,31 @@
         method="GET",
         route=f"chains/{model_name}/artifacts",
         json_body=request_body,
     )
     if "artifacts" not in response:
         return Artifacts(artifact_uris=[])
     return Artifacts(artifact_uris=response["artifacts"])
+
+
+def set_review_instructions(model_name: str, instructions: str):
+    request_body = {
+        "model_name": model_name,
+        "instructions": instructions,
+    }
+    call_endpoint(
+        method="POST",
+        route=f"chains/{model_name}/instructions",
+        json_body=request_body,
+    )
+
+
+def get_review_instructions(model_name: str) -> Instructions:
+    request_body = {"model_name": model_name}
+    response = call_endpoint(
+        method="GET",
+        route=f"chains/{model_name}/instructions",
+        json_body=request_body,
+    )
+    if "instructions" not in response:
+        return Instructions(None)
+    return Instructions(response["instructions"])
```

## databricks/rag_studio/sdk_utils/entities.py

```diff
@@ -17,13 +17,18 @@
 
 @dataclass
 class Artifacts:
     # List of artifact uris of the format `runs:/<run_id>/<artifact_path>`
     artifact_uris: List[str]
 
 
+@dataclass
+class Instructions:
+    instructions: str
+
+
 class PermissionLevel(Enum):
     NO_PERMISSIONS = 1
     CAN_VIEW = 2
     CAN_QUERY = 3
     CAN_REVIEW = 4
     CAN_MANAGE = 5
```

## tests/unpacking/test_unpacking.py

```diff
@@ -1,18 +1,19 @@
 import datetime
+import json
+
 import pandas as pd
 import pytest
-from pyspark.sql import types as T
-
 from databricks.rag.unpacking import unpack_and_split_payloads
 from databricks.rag.unpacking.schemas import (
     ASSESSMENT_LOG_SCHEMA,
     REQUEST_LOG_SCHEMA,
     REQUEST_LOG_V2_SCHEMA,
 )
+from pyspark.sql import types as T
 
 from .eval_test_utils import schemas_equal
 
 _INFERENCE_TABLE_PAYLOD_SCHEMA = T.StructType(
     [
         T.StructField("client_request_id", T.StringType()),
         T.StructField("databricks_request_id", T.StringType()),
@@ -319,86 +320,114 @@
         == "too mean"
     )
     assert assessment_log_values["retrieval_assessment"] is None
 
 
 @pytest.fixture()
 def sample_rag_response_v2():
-    return """
+    trace = {
+        "mlflow.trace_schema.version": 2,
+        "spans": [
             {
-              "object": "chat.completion",
-              "created": 1705451212,
-              "choices": [
-                {
-                  "index": 0,
-                  "message": {"role": "assistant", "content": "MLflow is amazing!"}
-                }
-              ],
-              "id": "12345",
-              "databricks_output" : {
-                "trace": {
-                  "app_version_id": "avi123",
-                  "mlflow.trace_schema.version": 2,
-                  "start_timestamp": "2024-01-03T19:51:10.686454",
-                  "end_timestamp": "2024-01-03T19:51:24.932795",
-                  "is_truncated": false,
-                  "spans": [
+                "name": "LLMChain",
+                "context": {
+                    "span_id": "ec0d493e-f07a-4ea6-9ea3-c25995baf9e6",
+                    "trace_id": "",
+                },
+                "parent_id": None,
+                "start_time": 1713229821507930112,
+                "end_time": 1713229821511368960,
+                "status_code": "OK",
+                "status_message": "",
+                "attributes": json.dumps(
+                    {
+                        "mlflow.spanInputs": {"product": "MLflow"},
+                        "mlflow.spanOutputs": {"text": "test"},
+                        "mlflow.spanType": "CHAIN",
+                    }
+                ),
+                "events": [
                     {
-                      "name": "RetrievalQA",
-                      "context": {"request_id": "", "span_id": "1c04bf28-8c29-42b1-9530-c8836f692806"},
-                      "status": {"status_code": "OK", "description": ""},
-                      "span_type": "CHAIN",
-                      "start_time": "2024-03-21T11:14:00.655056+00:00",
-                      "end_time": "2024-03-21T11:14:02.901672+00:00",
-                      "parent_span_id": null,
-                      "inputs": "{'query': 'What did the president say about Ketanji Brown Jackson'}",
-                      "outputs": "{'result': 'Nothing in these pieces of context mentions her.'}",
-                      "attributes": "{}",
-                      "events": [
-                        {"name": "start", "timestamp": "2024-03-21T11:14:00.655056+00:00", "attributes": "{}"},
-                        {"name": "end", "timestamp": "2024-03-21T11:14:02.901672+00:00", "attributes": "{}"}
-                      ]
+                        "name": "start",
+                        "timestamp": 1713229821507930112,
+                        "attributes": "{}",
                     },
                     {
-                      "name": "Retriever",
-                      "context": {"request_id": "", "span_id": "be08fa85-ac18-4ce4-b7e7-7bad0ef8b004"},
-                      "status": {"status_code": "OK", "description": ""},
-                      "span_type": "RETRIEVER",
-                      "start_time": "2024-03-21T11:14:00.657256+00:00",
-                      "end_time": "2024-03-21T11:14:00.657639+00:00",
-                      "parent_span_id": "1c04bf28-8c29-42b1-9530-c8836f692806",
-                      "inputs": "{'query': 'What did the president say about Ketanji Brown Jackson'}",
-                      "outputs": "{'chunks': [{'chunk_id': null, 'doc_uri': null, 'content': 'And I will keep doing everything in my power'}]}",
-                      "attributes": "{}",
-                      "events": [
-                        {"name": "start", "timestamp": "2024-03-21T11:14:00.657256+00:00", "attributes": "{}"},
-                        {"name": "end", "timestamp": "2024-03-21T11:14:00.657639+00:00", "attributes": "{}"}
-                      ]
+                        "name": "end",
+                        "timestamp": 1713229821511368960,
+                        "attributes": "{}",
                     },
+                ],
+            },
+            {
+                "name": "OpenAI",
+                "context": {
+                    "span_id": "cb8124ef-3938-41fb-8559-1ab63087f93e",
+                    "trace_id": "",
+                },
+                "parent_id": "ec0d493e-f07a-4ea6-9ea3-c25995baf9e6",
+                "start_time": 1713229821508729856,
+                "end_time": 1713229821511215872,
+                "status_code": "OK",
+                "status_message": "",
+                "attributes": json.dumps(
                     {
-                      "name": "AzureOpenAI",
-                      "context": {"request_id": "", "span_id": "88b17f8b-03bf-4bcf-941d-702fca938c20"},
-                      "status": {"status_code": "OK", "description": ""},
-                      "span_type": "LLM",
-                      "start_time": "2024-03-21T11:14:00.671217+00:00",
-                      "end_time": "2024-03-21T11:14:02.901256+00:00",
-                      "parent_span_id": "e19ea05e-df4f-449f-a0f7-461f6327456b",
-                      "inputs": "{'prompt': 'Use the following pieces of context to answer the question at the end.Answer:'}",
-                      "outputs": "{'generated_text': 'Nothing in these pieces of context mentions her. '}",
-                      "attributes": "{'invocation_params': {'deployment_name': 'gpt-35-turbo', 'model_name': 'gpt-3.5-turbo-instruct', 'temperature': 0.7, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'max_tokens': 256, '_type': 'azure', 'stop': null}, 'options': {'stop': null}, 'batch_size': 1}",
-                      "events": [
-                        {"name": "start", "timestamp": "2024-03-21T11:14:00.671217+00:00", "attributes": "{}"},
-                        {"name": "end", "timestamp": "2024-03-21T11:14:02.901256+00:00", "attributes": "{}"}
-                      ]
+                        "invocation_params": {
+                            "model_name": "gpt-3.5-turbo-instruct",
+                            "temperature": 0.9,
+                            "top_p": 1,
+                            "frequency_penalty": 0,
+                            "presence_penalty": 0,
+                            "n": 1,
+                            "logit_bias": {},
+                            "max_tokens": 256,
+                            "_type": "openai",
+                            "stop": None,
+                        },
+                        "options": {"stop": None},
+                        "batch_size": 1,
+                        "mlflow.spanInputs": {
+                            "prompt": "What is a good name for a company that makes MLflow?"
+                        },
+                        "mlflow.spanOutputs": {"generated_text": "test"},
+                        "mlflow.spanType": "LLM",
                     }
-                  ]
-                }
-              }
+                ),
+                "events": [
+                    {
+                        "name": "start",
+                        "timestamp": 1713229821508729856,
+                        "attributes": "{}",
+                    },
+                    {
+                        "name": "end",
+                        "timestamp": 1713229821511215872,
+                        "attributes": "{}",
+                    },
+                ],
+            },
+        ],
+        "start_timestamp": "2024-04-16T01:10:21.507930",
+        "end_timestamp": "2024-04-16T01:10:21.511369",
+        "app_version_id": "avi123",
+        "is_truncated": False,
+    }
+    response = {
+        "object": "chat.completion",
+        "created": 1705451212,
+        "choices": [
+            {
+                "index": 0,
+                "message": {"role": "assistant", "content": "MLflow is amazing!"},
             }
-            """
+        ],
+        "id": "12345",
+        "databricks_output": {"trace": trace},
+    }
+    return json.dumps(response)
 
 
 @pytest.mark.edge_spark
 def test_unpack_and_split_payloads_trace_v2(
     spark, sample_requests, sample_rag_response_v2, monkeypatch
 ):
     monkeypatch.setenv("RAG_TRACE_V2_ENABLED", "true")
@@ -424,24 +453,36 @@
     ), f"expected {expected_request_log_count} rows, got {request_log_count}"
     assert (
         assessment_log_count == expected_assessment_log_count
     ), f"expected {expected_assessment_log_count} rows, got {assessment_log_count}"
 
     # Spot check a few values in the request log
     request_log_values = request_log.collect()[0].asDict()
-    assert request_log_values["request"]["last_input"] == "Is mlflow good?"
-    assert (
-        request_log_values["trace"]["spans"][0]["inputs"]
-        == "{'query': 'What did the president say about Ketanji Brown Jackson'}"
+    attributes = request_log_values["trace"]["spans"][0]["attributes"]
+    assert attributes == json.dumps(
+        {
+            "mlflow.spanInputs": {"product": "MLflow"},
+            "mlflow.spanOutputs": {"text": "test"},
+            "mlflow.spanType": "CHAIN",
+        }
     )
+
+    assert (request_log_values["request_id"]) == "12345"
+    assert (request_log_values["timestamp"]) == datetime.datetime(2021, 1, 1, 0, 0)
+    assert (request_log_values["app_version_id"]) == "avi123"
+    assert (request_log_values["last_request_input"]) == "Is mlflow good?"
+    assert request_log_values["response_output"] == "MLflow is amazing!"
+
+    assert request_log_values["request"]["last_input"] == "Is mlflow good?"
     assert (
         request_log_values["output"]["choices"][0]["message"]["content"]
         == "MLflow is amazing!"
     )
 
     # Spot check a few values in the assessment log
     assessment_log_values = assessment_log.collect()[0].asDict()
+    assert assessment_log_values["request_id"] == "24680"
     assert (
         assessment_log_values["text_assessment"]["ratings"]["harmful"]["rationale"]
         == "too mean"
     )
     assert assessment_log_values["retrieval_assessment"] is None
```

## Comparing `databricks_rag_studio-0.0.3.dist-info/LICENSE.md` & `databricks_rag_studio-0.1.0.dist-info/LICENSE.md`

 * *Files identical despite different names*

## Comparing `databricks_rag_studio-0.0.3.dist-info/METADATA` & `databricks_rag_studio-0.1.0.dist-info/METADATA`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: databricks-rag-studio
-Version: 0.0.3
+Version: 0.1.0
 Summary: Databricks RAG Studio Library
 Home-page: UNKNOWN
 Author: Databricks
 Author-email: feedback@databricks.com
 License: Databricks Proprietary License
 Platform: UNKNOWN
 Classifier: Development Status :: 3 - Alpha
```

## Comparing `databricks_rag_studio-0.0.3.dist-info/RECORD` & `databricks_rag_studio-0.1.0.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,55 +1,55 @@
 databricks/__init__.py,sha256=j-IgZWAzatWTaAwHNfNT_pjqdzh-OexfmCHO2n_SkGw,344
 databricks/rag/__init__.py,sha256=0bLojzVP6lZuxyR3GYfLqdxY8000pUUXGcLqxUHXoaU,493
 databricks/rag/configs.py,sha256=DjPnSuY1tEZtMo8-SH1O4aF6AOPqJzcNIQCnD_LrWYw,4294
 databricks/rag/constants.py,sha256=tdL23KSCxf-bVqIsy9sgvV2cmH9Hc-p_OdHdPeTO4iQ,1529
 databricks/rag/entities.py,sha256=B3_3RFkENX2D2IbrJsLHEz1aTf3xiD2rOs4FzsbQeO8,25475
 databricks/rag/environments.py,sha256=TxVV8rHLnvN1VnaslbzwZ8r-RzaWNU1EShiWhvo7y58,7071
 databricks/rag/errors.py,sha256=4e-k6V2ocf7vLVRoYKJEav2Wb8qoyibQ6CtUmMDoQws,141
-databricks/rag/version.py,sha256=4dzhbPMylGSHvxm4DsL5IU6S3WjoNtd5HQ-X3HK0IO8,62
+databricks/rag/version.py,sha256=_8WVo47jnL1eRC9hL4gl2rE93zZe-dP29fd06ynDbYo,62
 databricks/rag/evaluation/__init__.py,sha256=LV-p9PElk4lFXoJaoWEeNlxwCTF_a7RnqJRiCCDEufE,476
 databricks/rag/evaluation/offline.py,sha256=jmwfA3_S_WKJfY4EWGfJvNgoKV2UyqsU1lXY8HrHT4A,5377
 databricks/rag/evaluation/online.py,sha256=KFQr4fmmkuktyIVkwDUyK_6xeWn8DOTxFCLoGnL5Q7g,4197
 databricks/rag/scoring/__init__.py,sha256=bTG4wyY3pFmDniQPXCZzI-_d2IVc92AV-Msvvcwic38,493
 databricks/rag/scoring/feedback.py,sha256=yO-0yMKpwPo8kvlESO0AkXAvIEqJcPjbXvFBRaqWzI0,3691
-databricks/rag/scoring/langchain_tracer.py,sha256=oOUyeejiYAWyNb5CjPLA5pVWYRHwZFyhmN-FL8HtBjo,13365
-databricks/rag/scoring/predictions.py,sha256=Z6uVflLfjiNuWB7QiRIEDXACDDrowcc5hQ78PUnfTw0,12836
-databricks/rag/scoring/schema_v2.py,sha256=wnD7l1XIT8rMChkk58YoF4y1qMLdpouM_fdgGyWhaUY,3196
+databricks/rag/scoring/langchain_tracer.py,sha256=s3oVKx00HJn0xwr0LcPt5Ej5Cx77rm3C4p8OVFZYAYY,14954
+databricks/rag/scoring/predictions.py,sha256=y2OUSV8Vo0KAm5iN6liXI1NhMO19k6_KeqbdBKN5y38,12893
+databricks/rag/scoring/schema_v2.py,sha256=GMIBGI_DrvVucqk8ILcGWaXWzDXusCR1-HYNy9kd-Wg,2771
 databricks/rag/studio/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/rag/studio/chain_logging.py,sha256=9kKWmHvcIokA-zwZ3mqzio4NVwS-jsh7bxjfR6zSJ2w,392
 databricks/rag/studio/configs.py,sha256=S9D-oBpGhatMhPLwHZ9YYw_Nq2Kqyfvi9j4bjporthE,1552
-databricks/rag/unpacking/__init__.py,sha256=xnSPvJTgl5XCljix0KquuOq7je3CFsd2wVbYEPIJ6do,8398
-databricks/rag/unpacking/schemas.py,sha256=eHaUGkMtC51khljHW_layjt5ml6Nmya2JvFGPRQRCc8,10140
+databricks/rag/unpacking/__init__.py,sha256=ZU5uyLJQmdlA8wd2pZfcS3maDukRrDszc65N5N8lqfo,440
+databricks/rag/unpacking/schemas.py,sha256=qALnkJ_9bKkgn2-W2erXt4F4lzQa0wtsayyvgqWTk5M,10134
+databricks/rag/unpacking/unpack.py,sha256=oaFCkAmOYBEcJfUblRhvy7MwRTxnuTgBZFe6o46ZhUg,9564
 databricks/rag/utils/__init__.py,sha256=VLSTpz1nnzptnuZChP5uPvr-CvGrUm6bRbybCzztkt4,1462
 databricks/rag/utils/mlflow.py,sha256=Na1B_-9CSl-VTSn4LvrAL7XWha5fM1Zhlqv_q9jsdq0,3736
 databricks/rag/utils/tables.py,sha256=yO23-fv1c9lkk_oBqOvcZg30eKIJZ_isVek4SLdF_U4,1147
 databricks/rag/utils/uc.py,sha256=jlNQWxqzJqVh34GfA-hOAfrljfejFWPZx3Z_8bhoxg8,4964
-databricks/rag_studio/__init__.py,sha256=aFK9W4cnxiv2IKhwkT5Dv4eH1g5H0iQPM_ogsBO0KFM,620
-databricks/rag_studio/chain_logging.py,sha256=bBE4na05wG4JKTOhJ5oAFQ2BpZf1dYG_6vUXn3dkL74,11155
+databricks/rag_studio/__init__.py,sha256=7ctzmnPL49HCMzWaLYoCvNGrbnvFGozFAykBAGpaDzY,789
+databricks/rag_studio/chain_logging.py,sha256=HwVPLJLc4Ii2a6MS7WYQ23OUxCU5gAP7iQsyrZkiciA,11378
 databricks/rag_studio/deployments.py,sha256=5LGMc7KPDNQx5uP_puUvMcapjtT_IlTCqQr-seacndI,11727
 databricks/rag_studio/feedback.py,sha256=vPCoYpVF4iptcFW7X9mS5bTm0Fx8erp2zKl0RqgGAuo,1361
-databricks/rag_studio/permissions.py,sha256=-0Baz8a079sJlunSBDeUUaoE5po49re6Wv7HTPqpkL8,12360
-databricks/rag_studio/reviews.py,sha256=7v9t_JPvtEx6gGhkmJhqow4mm1rfX4HtPq4qXAjPWHc,5850
-databricks/rag_studio/version.py,sha256=4dzhbPMylGSHvxm4DsL5IU6S3WjoNtd5HQ-X3HK0IO8,62
+databricks/rag_studio/permissions.py,sha256=K970SDs24ZtHo6wO_Dl4kOff-KbKZAvQCTTaQlwCgls,19720
+databricks/rag_studio/reviews.py,sha256=_TnjNX-nL5QeMqqtdZqvT0tgLvIje2OX9AD7NYpNSwo,6805
+databricks/rag_studio/version.py,sha256=_8WVo47jnL1eRC9hL4gl2rE93zZe-dP29fd06ynDbYo,62
 databricks/rag_studio/client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-databricks/rag_studio/client/rest_client.py,sha256=HpmmmmyclKhFfRwyzZThmP3TmtIggruR4EYWyRzSFQU,3925
+databricks/rag_studio/client/rest_client.py,sha256=SIJc71IrVzKxfNT2tWAkp3r8vEXgcBSLozugf7TEMNk,4610
 databricks/rag_studio/sdk_utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/rag_studio/sdk_utils/deployments.py,sha256=JuBAueN4DJH_rt_NwG-WMORtQwx74_IEgF1P58COD3g,664
-databricks/rag_studio/sdk_utils/entities.py,sha256=WreNJrmLYizp_jTt16jRT19dWULmHzkdUzyC0ujrcdw,545
+databricks/rag_studio/sdk_utils/entities.py,sha256=rHs1qOOBabABMTDJHFdvTr-xWeCoaCQHwwpReCCGDPw,600
 databricks/rag_studio/sdk_utils/permissions_checker.py,sha256=bJ_FVMEq1WOmZ0aopDR2lFk94aOzjykZ1mkKcrb8kwA,1467
-databricks/rag_studio/sdk_utils/schemas.py,sha256=kTjUTwq-cd9J49LFP-6rkSDWE_8pOhd2JPxbeQBC0eE,2680
 databricks/rag_studio/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/rag_studio/utils/annotations.py,sha256=fDk_BkjMsl5efL6-S2rY6iN-3EbeQu59bRLhfLUND-A,2461
 databricks/rag_studio/utils/mlflow_utils.py,sha256=_7SIyGr5t7cbODsExNgJ0jCeoT9y1rZNZTn4xNMVL5o,664
 databricks/rag_studio/utils/rest_utils.py,sha256=MXyweSCtPxchYFdqX5UfSEoYFRXwtOVBg8GyIBiUWMo,1274
 databricks/rag_studio/utils/uc.py,sha256=9FDoIlGDmtRnF8lHgt3pe_IhUN3xrlBTyxC8u8JZ05U,853
 tests/evaluation/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/evaluation/test_offline.py,sha256=dicoKjwIuXnQGMQSMfFxfOiJcxmPRrP-kbzrT_pDaMk,21379
 tests/evaluation/test_online.py,sha256=mv5QUuno0qSCQiaXr_KnH99MgR_TvLK3Kd_Hs4KpK8U,17337
 tests/unpacking/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/unpacking/eval_test_utils.py,sha256=pJ1MweIyhgqbjoyrD982WkxuuGNKXpb_GvU1nzGdAvY,1146
-tests/unpacking/test_unpacking.py,sha256=E9lMIwtY0MfhNfeIuUwYWOGXffQm2Uib9b2Cex1P0OU,18109
-databricks_rag_studio-0.0.3.dist-info/LICENSE.md,sha256=CoBQ-MOKxP6qCzsTaVYEegZnHIeoGhyp-NLFIUwtAFI,2413
-databricks_rag_studio-0.0.3.dist-info/METADATA,sha256=zlfm7hEqTGUito96TPJtSB7BhdYS6_8fYKXFOjD4Fl0,768
-databricks_rag_studio-0.0.3.dist-info/WHEEL,sha256=ewwEueio1C2XeHTvT17n8dZUJgOvyCWCt0WVNLClP9o,92
-databricks_rag_studio-0.0.3.dist-info/top_level.txt,sha256=7kRdatoSgU0EUurRQJ_3F1Nv4EOSHWAr6ng25tJOJKU,11
-databricks_rag_studio-0.0.3.dist-info/RECORD,,
+tests/unpacking/test_unpacking.py,sha256=0jhfjm2eWhyhmopXBSgTpBCrOd9bW7y7EQeBiJYH1LA,18061
+databricks_rag_studio-0.1.0.dist-info/LICENSE.md,sha256=CoBQ-MOKxP6qCzsTaVYEegZnHIeoGhyp-NLFIUwtAFI,2413
+databricks_rag_studio-0.1.0.dist-info/METADATA,sha256=1RXqmbTKaZLVMtVRwfKdqmZFTH8Jrb8XHnP5AsOqIRc,768
+databricks_rag_studio-0.1.0.dist-info/WHEEL,sha256=ewwEueio1C2XeHTvT17n8dZUJgOvyCWCt0WVNLClP9o,92
+databricks_rag_studio-0.1.0.dist-info/top_level.txt,sha256=7kRdatoSgU0EUurRQJ_3F1Nv4EOSHWAr6ng25tJOJKU,11
+databricks_rag_studio-0.1.0.dist-info/RECORD,,
```

